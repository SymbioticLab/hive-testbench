18/06/26 03:24:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/06/26 03:24:22 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/06/26 03:24:22 INFO metastore.ObjectStore: ObjectStore, initialize called
18/06/26 03:24:22 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/06/26 03:24:22 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/06/26 03:24:24 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/06/26 03:24:25 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/06/26 03:24:25 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/06/26 03:24:25 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/06/26 03:24:25 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/06/26 03:24:25 INFO DataNucleus.Query: Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
18/06/26 03:24:25 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/06/26 03:24:25 INFO metastore.ObjectStore: Initialized ObjectStore
18/06/26 03:24:26 INFO metastore.HiveMetaStore: Added admin role in metastore
18/06/26 03:24:26 INFO metastore.HiveMetaStore: Added public role in metastore
18/06/26 03:24:26 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
18/06/26 03:24:26 INFO metastore.HiveMetaStore: 0: get_all_databases
18/06/26 03:24:26 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_all_databases	
18/06/26 03:24:26 INFO metastore.HiveMetaStore: 0: get_functions: db=default pat=*
18/06/26 03:24:26 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/06/26 03:24:26 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/06/26 03:24:26 INFO metastore.HiveMetaStore: 0: get_functions: db=tpcds_text_2 pat=*
18/06/26 03:24:26 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_functions: db=tpcds_text_2 pat=*	
18/06/26 03:24:26 INFO session.SessionState: Created local directory: /tmp/e57bb393-368c-40df-a6b5-a03958b0141a_resources
18/06/26 03:24:27 INFO session.SessionState: Created HDFS directory: /tmp/hive/wentingt/e57bb393-368c-40df-a6b5-a03958b0141a
18/06/26 03:24:27 INFO session.SessionState: Created local directory: /tmp/wentingt/e57bb393-368c-40df-a6b5-a03958b0141a
18/06/26 03:24:27 INFO session.SessionState: Created HDFS directory: /tmp/hive/wentingt/e57bb393-368c-40df-a6b5-a03958b0141a/_tmp_space.db
18/06/26 03:24:27 INFO spark.SparkContext: Running Spark version 2.4.0-SNAPSHOT
18/06/26 03:24:27 INFO spark.SparkContext: Submitted application: SparkSQL::10.0.1.253
18/06/26 03:24:27 INFO spark.SecurityManager: Changing view acls to: wentingt
18/06/26 03:24:27 INFO spark.SecurityManager: Changing modify acls to: wentingt
18/06/26 03:24:27 INFO spark.SecurityManager: Changing view acls groups to: 
18/06/26 03:24:27 INFO spark.SecurityManager: Changing modify acls groups to: 
18/06/26 03:24:27 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wentingt); groups with view permissions: Set(); users  with modify permissions: Set(wentingt); groups with modify permissions: Set()
18/06/26 03:24:27 INFO util.Utils: Successfully started service 'sparkDriver' on port 46019.
18/06/26 03:24:27 INFO spark.SparkEnv: Registering MapOutputTracker
18/06/26 03:24:27 INFO spark.SparkEnv: Registering BlockManagerMaster
18/06/26 03:24:27 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/06/26 03:24:27 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/06/26 03:24:27 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-1ead7e73-6fee-4758-9151-b61287e5c5bd
18/06/26 03:24:27 INFO memory.MemoryStore: MemoryStore started with capacity 408.9 MB
18/06/26 03:24:27 INFO spark.SparkEnv: Registering OutputCommitCoordinator
18/06/26 03:24:28 INFO util.log: Logging initialized @7209ms
18/06/26 03:24:28 INFO server.Server: jetty-9.3.z-SNAPSHOT
18/06/26 03:24:28 INFO server.Server: Started @7273ms
18/06/26 03:24:28 INFO server.AbstractConnector: Started ServerConnector@64dc86c6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
18/06/26 03:24:28 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4217bce6{/jobs,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5873f3f0{/jobs/json,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@684372d0{/jobs/job,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@41f964f9{/jobs/job/json,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@652e345{/stages,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7574d4ad{/stages/json,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7bede4ea{/stages/stage,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@33627576{/stages/stage/json,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@27bc1d44{/stages/pool,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1af677f8{/stages/pool/json,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a55fb81{/storage,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a3cf878{/storage/json,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1d2d8846{/storage/rdd,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@34cd65ac{/storage/rdd/json,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@61911947{/environment,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c53c235{/environment/json,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2dcd0e41{/executors,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7272ee51{/executors/json,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1b409a79{/executors/threadDump,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5940b14e{/executors/threadDump/json,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1cba0321{/static,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3271ec2a{/,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@52bba91a{/api,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@13004dd8{/jobs/job/kill,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4fc6e776{/stages/stage/kill,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://dc1master-lan1:4040
18/06/26 03:24:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 0
18/06/26 03:24:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:28 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://dc1master-lan1:7077...
18/06/26 03:24:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 0
18/06/26 03:24:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:28 INFO client.TransportClientFactory: Successfully created connection to dc1master-lan1/10.0.1.253:7077 after 47 ms (0 ms spent in bootstraps)
18/06/26 03:24:28 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20180626032428-0069
18/06/26 03:24:28 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20180626032428-0069/0 on worker-20180626004527-10.0.1.2-38332 (10.0.1.2:38332) with 10 core(s)
18/06/26 03:24:28 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20180626032428-0069/0 on hostPort 10.0.1.2:38332 with 10 core(s), 2.0 GB RAM
18/06/26 03:24:28 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20180626032428-0069/1 on worker-20180626004527-10.0.1.1-34053 (10.0.1.1:34053) with 10 core(s)
18/06/26 03:24:28 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20180626032428-0069/1 on hostPort 10.0.1.1:34053 with 10 core(s), 2.0 GB RAM
18/06/26 03:24:28 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32913.
18/06/26 03:24:28 INFO netty.NettyBlockTransferService: Server created on dc1master-lan1:32913
18/06/26 03:24:28 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/06/26 03:24:28 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20180626032428-0069/0 is now RUNNING
18/06/26 03:24:28 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20180626032428-0069/1 is now RUNNING
18/06/26 03:24:28 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, dc1master-lan1, 32913, None)
18/06/26 03:24:28 INFO storage.BlockManagerMasterEndpoint: Registering block manager dc1master-lan1:32913 with 408.9 MB RAM, BlockManagerId(driver, dc1master-lan1, 32913, None)
18/06/26 03:24:28 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, dc1master-lan1, 32913, None)
18/06/26 03:24:28 INFO storage.BlockManager: external shuffle service port = 7337
18/06/26 03:24:28 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, dc1master-lan1, 32913, None)
18/06/26 03:24:28 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3611153f{/metrics/json,null,AVAILABLE,@Spark}
18/06/26 03:24:28 INFO scheduler.EventLoggingListener: Logging events to hdfs://dc1master:9000/user/wentingt/spark-logs/app-20180626032428-0069
18/06/26 03:24:28 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
18/06/26 03:24:29 INFO internal.SharedState: loading hive config file: file:/users/wentingt/spark-terra/conf/hive-site.xml
18/06/26 03:24:29 INFO internal.SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir ('/user/hive/warehouse').
18/06/26 03:24:29 INFO internal.SharedState: Warehouse path is '/user/hive/warehouse'.
18/06/26 03:24:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@517fbf62{/SQL,null,AVAILABLE,@Spark}
18/06/26 03:24:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65db548{/SQL/json,null,AVAILABLE,@Spark}
18/06/26 03:24:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@298263fa{/SQL/execution,null,AVAILABLE,@Spark}
18/06/26 03:24:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@466fedfa{/SQL/execution/json,null,AVAILABLE,@Spark}
18/06/26 03:24:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a6f6cac{/static/sql,null,AVAILABLE,@Spark}
18/06/26 03:24:29 INFO hive.HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/06/26 03:24:29 INFO client.HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is /user/hive/warehouse
18/06/26 03:24:29 INFO metastore.HiveMetaStore: 0: get_database: default
18/06/26 03:24:29 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: default	
18/06/26 03:24:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 0
18/06/26 03:24:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 0
18/06/26 03:24:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:29 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/06/26 03:24:29 INFO metastore.HiveMetaStore: 0: get_database: global_temp
18/06/26 03:24:29 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/06/26 03:24:29 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/06/26 03:24:29 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:29 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=store_sales
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=store_sales	
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 0
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 0
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:30 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.1.2:52552) with ID 0
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:30 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.1.1:34004) with ID 1
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:30 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.1.2:46588 with 912.3 MB RAM, BlockManagerId(0, 10.0.1.2, 46588, None)
18/06/26 03:24:30 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.1.1:32861 with 912.3 MB RAM, BlockManagerId(1, 10.0.1.1, 32861, None)
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=store_returns
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=store_returns	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=date_dim
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=date_dim	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=store
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=store	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=item
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=item	
18/06/26 03:24:30 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=promotion
18/06/26 03:24:30 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=promotion	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=catalog_sales
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=catalog_sales	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=catalog_returns
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=catalog_returns	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=date_dim
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=date_dim	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=catalog_page
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=catalog_page	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=item
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=item	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=promotion
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=promotion	
18/06/26 03:24:31 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:31 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:31 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:31 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=web_sales
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=web_sales	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=web_returns
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=web_returns	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=date_dim
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=date_dim	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=web_site
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=web_site	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=item
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=item	
18/06/26 03:24:31 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=promotion
18/06/26 03:24:31 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=promotion	
18/06/26 03:24:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:32 WARN util.Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
18/06/26 03:24:33 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:33 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:33 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:33 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:34 INFO codegen.CodeGenerator: Code generated in 239.27881 ms
18/06/26 03:24:34 INFO codegen.CodeGenerator: Code generated in 35.192433 ms
18/06/26 03:24:34 INFO codegen.CodeGenerator: Code generated in 38.019518 ms
18/06/26 03:24:34 INFO codegen.CodeGenerator: Code generated in 38.790614 ms
18/06/26 03:24:34 INFO codegen.CodeGenerator: Code generated in 38.927894 ms
18/06/26 03:24:34 INFO codegen.CodeGenerator: Code generated in 39.144725 ms
18/06/26 03:24:34 INFO codegen.CodeGenerator: Code generated in 39.58738 ms
18/06/26 03:24:34 INFO codegen.CodeGenerator: Code generated in 44.360738 ms
18/06/26 03:24:34 INFO codegen.CodeGenerator: Code generated in 44.257749 ms
18/06/26 03:24:34 INFO codegen.CodeGenerator: Code generated in 62.285899 ms
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 291.3 KB, free 406.6 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 290.9 KB, free 406.6 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 290.5 KB, free 406.6 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 291.1 KB, free 406.6 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 291.2 KB, free 406.6 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 291.2 KB, free 406.6 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 290.9 KB, free 406.6 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 291.4 KB, free 406.6 MB)
18/06/26 03:24:34 INFO spark.ContextCleaner: Cleaned accumulator 1
18/06/26 03:24:34 INFO spark.ContextCleaner: Cleaned accumulator 4
18/06/26 03:24:34 INFO spark.ContextCleaner: Cleaned accumulator 3
18/06/26 03:24:34 INFO spark.ContextCleaner: Cleaned accumulator 2
18/06/26 03:24:34 INFO spark.ContextCleaner: Cleaned accumulator 11
18/06/26 03:24:34 INFO spark.ContextCleaner: Cleaned accumulator 9
18/06/26 03:24:34 INFO spark.ContextCleaner: Cleaned accumulator 10
18/06/26 03:24:34 INFO spark.ContextCleaner: Cleaned accumulator 5
18/06/26 03:24:34 INFO spark.ContextCleaner: Cleaned accumulator 0
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.1 KB, free 406.4 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 25.0 KB, free 406.4 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.9 KB, free 406.4 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.8 KB, free 406.4 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.9 KB, free 406.4 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 25.1 KB, free 406.4 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.0 KB, free 406.4 MB)
18/06/26 03:24:34 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 25.0 KB, free 406.4 MB)
18/06/26 03:24:34 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on dc1master-lan1:32913 (size: 24.8 KB, free: 408.9 MB)
18/06/26 03:24:34 INFO spark.SparkContext: Created broadcast 5 from 
18/06/26 03:24:34 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on dc1master-lan1:32913 (size: 25.0 KB, free: 408.9 MB)
18/06/26 03:24:34 INFO spark.SparkContext: Created broadcast 6 from 
18/06/26 03:24:34 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on dc1master-lan1:32913 (size: 25.0 KB, free: 408.8 MB)
18/06/26 03:24:34 INFO spark.SparkContext: Created broadcast 4 from 
18/06/26 03:24:34 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on dc1master-lan1:32913 (size: 24.9 KB, free: 408.8 MB)
18/06/26 03:24:34 INFO spark.SparkContext: Created broadcast 0 from 
18/06/26 03:24:34 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on dc1master-lan1:32913 (size: 24.9 KB, free: 408.8 MB)
18/06/26 03:24:34 INFO spark.SparkContext: Created broadcast 3 from 
18/06/26 03:24:34 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on dc1master-lan1:32913 (size: 25.0 KB, free: 408.8 MB)
18/06/26 03:24:34 INFO spark.SparkContext: Created broadcast 1 from 
18/06/26 03:24:34 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on dc1master-lan1:32913 (size: 25.1 KB, free: 408.7 MB)
18/06/26 03:24:34 INFO spark.SparkContext: Created broadcast 2 from 
18/06/26 03:24:34 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on dc1master-lan1:32913 (size: 25.1 KB, free: 408.7 MB)
18/06/26 03:24:34 INFO spark.SparkContext: Created broadcast 7 from 
18/06/26 03:24:35 INFO codegen.CodeGenerator: Code generated in 100.112386 ms
18/06/26 03:24:35 INFO codegen.CodeGenerator: Code generated in 34.216569 ms
18/06/26 03:24:35 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:35 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:35 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:35 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:35 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:35 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:35 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:35 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:35 INFO spark.SparkContext: Starting job: run at ThreadPoolExecutor.java:1142
18/06/26 03:24:35 INFO spark.SparkContext: Starting job: run at ThreadPoolExecutor.java:1142
18/06/26 03:24:35 INFO spark.SparkContext: Starting job: run at ThreadPoolExecutor.java:1142
18/06/26 03:24:35 INFO spark.SparkContext: Starting job: run at ThreadPoolExecutor.java:1142
18/06/26 03:24:35 INFO spark.SparkContext: Starting job: run at ThreadPoolExecutor.java:1142
18/06/26 03:24:35 INFO spark.SparkContext: Starting job: run at ThreadPoolExecutor.java:1142
18/06/26 03:24:35 INFO spark.SparkContext: Starting job: run at ThreadPoolExecutor.java:1142
18/06/26 03:24:35 INFO spark.SparkContext: Starting job: run at ThreadPoolExecutor.java:1142
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Got job 0 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (run at ThreadPoolExecutor.java:1142)
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Missing parents: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[44] at run at ThreadPoolExecutor.java:1142), which has no missing parents
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.8 KB, free 406.4 MB)
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.0 KB, free 406.4 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on dc1master-lan1:32913 (size: 6.0 KB, free: 408.7 MB)
18/06/26 03:24:35 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[44] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Got job 3 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (run at ThreadPoolExecutor.java:1142)
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Missing parents: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[42] at run at ThreadPoolExecutor.java:1142), which has no missing parents
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.9 KB, free 406.4 MB)
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.0 KB, free 406.4 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on dc1master-lan1:32913 (size: 6.0 KB, free: 408.7 MB)
18/06/26 03:24:35 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[42] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 10.0.1.2, executor 0, partition 0, ANY, 7911 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 10.0.1.1, executor 1, partition 1, ANY, 7911 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Got job 6 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (run at ThreadPoolExecutor.java:1142)
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Missing parents: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[46] at run at ThreadPoolExecutor.java:1142), which has no missing parents
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 11.8 KB, free 406.4 MB)
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.0 KB, free 406.4 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on dc1master-lan1:32913 (size: 6.0 KB, free: 408.7 MB)
18/06/26 03:24:35 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[46] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, 10.0.1.1, executor 1, partition 0, ANY, 7912 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, 10.0.1.2, executor 0, partition 1, ANY, 7912 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Got job 2 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (run at ThreadPoolExecutor.java:1142)
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Missing parents: List()
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, 10.0.1.2, executor 0, partition 0, ANY, 7916 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 10.0.1.1, executor 1, partition 1, ANY, 7916 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[41] at run at ThreadPoolExecutor.java:1142), which has no missing parents
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 12.2 KB, free 406.4 MB)
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.1 KB, free 406.4 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on dc1master-lan1:32913 (size: 6.1 KB, free: 408.7 MB)
18/06/26 03:24:35 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[41] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Got job 1 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (run at ThreadPoolExecutor.java:1142)
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Missing parents: List()
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, 10.0.1.1, executor 1, partition 0, ANY, 7915 bytes)
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[43] at run at ThreadPoolExecutor.java:1142), which has no missing parents
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, 10.0.1.2, executor 0, partition 1, ANY, 7915 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 12.9 KB, free 406.3 MB)
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.2 KB, free 406.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on dc1master-lan1:32913 (size: 6.2 KB, free: 408.7 MB)
18/06/26 03:24:35 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[43] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Got job 5 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (run at ThreadPoolExecutor.java:1142)
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Missing parents: List()
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, 10.0.1.2, executor 0, partition 0, ANY, 7922 bytes)
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[47] at run at ThreadPoolExecutor.java:1142), which has no missing parents
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 9, 10.0.1.1, executor 1, partition 1, ANY, 7922 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 12.7 KB, free 406.3 MB)
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.1 KB, free 406.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on dc1master-lan1:32913 (size: 6.1 KB, free: 408.7 MB)
18/06/26 03:24:35 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[47] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Got job 7 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (run at ThreadPoolExecutor.java:1142)
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Missing parents: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[40] at run at ThreadPoolExecutor.java:1142), which has no missing parents
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 10, 10.0.1.1, executor 1, partition 0, ANY, 7918 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 5.0 (TID 11, 10.0.1.2, executor 0, partition 1, ANY, 7918 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 11.8 KB, free 406.3 MB)
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.9 KB, free 406.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on dc1master-lan1:32913 (size: 5.9 KB, free: 408.7 MB)
18/06/26 03:24:35 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[40] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: Adding task set 6.0 with 2 tasks
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Got job 4 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Final stage: ResultStage 7 (run at ThreadPoolExecutor.java:1142)
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Missing parents: List()
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[45] at run at ThreadPoolExecutor.java:1142), which has no missing parents
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, 10.0.1.2, executor 0, partition 0, ANY, 7915 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, 10.0.1.1, executor 1, partition 1, ANY, 7915 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 11.1 KB, free 406.3 MB)
18/06/26 03:24:35 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.7 KB, free 406.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on dc1master-lan1:32913 (size: 5.7 KB, free: 408.7 MB)
18/06/26 03:24:35 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:35 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[45] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: Adding task set 7.0 with 2 tasks
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 14, 10.0.1.1, executor 1, partition 0, ANY, 7919 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 7.0 (TID 15, 10.0.1.2, executor 0, partition 1, ANY, 7919 bytes)
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 0
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 0
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 1
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 1
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 2
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 2
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 3
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 3
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 4
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 4
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 5
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 5
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 6
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 6
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 7
18/06/26 03:24:35 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 7
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.1.2:46588 (size: 6.0 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.1.1:32861 (size: 6.2 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.1.2:46588 (size: 6.1 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.1.2:46588 (size: 6.2 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.1.2:46588 (size: 6.1 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.1.1:32861 (size: 6.0 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.1.2:46588 (size: 6.0 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.1.1:32861 (size: 6.0 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.1.1:32861 (size: 5.7 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.1.2:46588 (size: 5.7 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.1.1:32861 (size: 6.0 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.1.2:46588 (size: 6.0 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.1.2:46588 (size: 5.9 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.1.1:32861 (size: 5.9 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.2:46588 (size: 24.9 KB, free: 912.2 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.1.1:32861 (size: 6.1 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.1.1:32861 (size: 6.1 KB, free: 912.3 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 912.2 MB)
18/06/26 03:24:35 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.1.2:46588 (size: 24.9 KB, free: 912.2 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 912.2 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 912.2 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 912.2 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 912.2 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.1:32861 (size: 24.9 KB, free: 912.2 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.1.2:46588 (size: 25.1 KB, free: 912.1 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.1.2:46588 (size: 25.1 KB, free: 912.1 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 912.1 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.1.2:46588 (size: 24.8 KB, free: 912.1 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.1.1:32861 (size: 24.9 KB, free: 912.1 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.1.1:32861 (size: 24.8 KB, free: 912.1 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 912.1 MB)
18/06/26 03:24:36 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 912.1 MB)
18/06/26 03:24:36 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:36 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:36 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:36 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 2241 ms on 10.0.1.2 (executor 0) (1/2)
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 2322 ms on 10.0.1.2 (executor 0) (1/2)
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 2319 ms on 10.0.1.2 (executor 0) (1/2)
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 2347 ms on 10.0.1.1 (executor 1) (2/2)
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.DAGScheduler: ResultStage 6 (run at ThreadPoolExecutor.java:1142) finished in 2.390 s
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 2426 ms on 10.0.1.1 (executor 1) (2/2)
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 2425 ms on 10.0.1.1 (executor 1) (2/2)
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/06/26 03:24:37 INFO scheduler.DAGScheduler: ResultStage 1 (run at ThreadPoolExecutor.java:1142) finished in 2.467 s
18/06/26 03:24:37 INFO scheduler.DAGScheduler: Job 3 finished: run at ThreadPoolExecutor.java:1142, took 2.566535 s
18/06/26 03:24:37 INFO scheduler.DAGScheduler: Job 7 finished: run at ThreadPoolExecutor.java:1142, took 2.566370 s
18/06/26 03:24:37 INFO scheduler.DAGScheduler: ResultStage 2 (run at ThreadPoolExecutor.java:1142) finished in 2.442 s
18/06/26 03:24:37 INFO scheduler.DAGScheduler: Job 6 finished: run at ThreadPoolExecutor.java:1142, took 2.567362 s
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 7.0 (TID 15) in 2361 ms on 10.0.1.2 (executor 0) (1/2)
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2501 ms on 10.0.1.2 (executor 0) (1/2)
18/06/26 03:24:37 INFO codegen.CodeGenerator: Code generated in 13.288209 ms
18/06/26 03:24:37 INFO codegen.CodeGenerator: Code generated in 13.842554 ms
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 1024.2 KB, free 404.3 MB)
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 1024.3 KB, free 404.3 MB)
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 575.0 B, free 404.3 MB)
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 713.0 B, free 404.3 MB)
18/06/26 03:24:37 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on dc1master-lan1:32913 (size: 575.0 B, free: 408.7 MB)
18/06/26 03:24:37 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on dc1master-lan1:32913 (size: 713.0 B, free: 408.7 MB)
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 1026.5 KB, free 403.3 MB)
18/06/26 03:24:37 INFO spark.SparkContext: Created broadcast 17 from run at ThreadPoolExecutor.java:1142
18/06/26 03:24:37 INFO spark.SparkContext: Created broadcast 16 from run at ThreadPoolExecutor.java:1142
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.8 KB, free 403.3 MB)
18/06/26 03:24:37 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on dc1master-lan1:32913 (size: 3.8 KB, free: 408.7 MB)
18/06/26 03:24:37 INFO spark.SparkContext: Created broadcast 18 from run at ThreadPoolExecutor.java:1142
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 2491 ms on 10.0.1.2 (executor 0) (1/2)
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 14) in 2439 ms on 10.0.1.1 (executor 1) (2/2)
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/06/26 03:24:37 INFO scheduler.DAGScheduler: ResultStage 7 (run at ThreadPoolExecutor.java:1142) finished in 2.448 s
18/06/26 03:24:37 INFO scheduler.DAGScheduler: Job 4 finished: run at ThreadPoolExecutor.java:1142, took 2.656851 s
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 1115.6 KB, free 402.2 MB)
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 166.0 KB, free 402.0 MB)
18/06/26 03:24:37 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on dc1master-lan1:32913 (size: 166.0 KB, free: 408.5 MB)
18/06/26 03:24:37 INFO spark.SparkContext: Created broadcast 19 from run at ThreadPoolExecutor.java:1142
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2591 ms on 10.0.1.1 (executor 1) (2/2)
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/06/26 03:24:37 INFO scheduler.DAGScheduler: ResultStage 0 (run at ThreadPoolExecutor.java:1142) finished in 2.657 s
18/06/26 03:24:37 INFO scheduler.DAGScheduler: Job 0 finished: run at ThreadPoolExecutor.java:1142, took 2.712909 s
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 1088.0 KB, free 401.0 MB)
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.0 KB, free 400.9 MB)
18/06/26 03:24:37 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on dc1master-lan1:32913 (size: 24.0 KB, free: 408.5 MB)
18/06/26 03:24:37 INFO spark.SparkContext: Created broadcast 20 from run at ThreadPoolExecutor.java:1142
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:37 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 2596 ms on 10.0.1.1 (executor 1) (2/2)
18/06/26 03:24:37 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/06/26 03:24:37 INFO scheduler.DAGScheduler: ResultStage 3 (run at ThreadPoolExecutor.java:1142) finished in 2.605 s
18/06/26 03:24:37 INFO scheduler.DAGScheduler: Job 2 finished: run at ThreadPoolExecutor.java:1142, took 2.744234 s
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 1024.3 KB, free 399.9 MB)
18/06/26 03:24:37 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 546.0 B, free 399.9 MB)
18/06/26 03:24:37 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on dc1master-lan1:32913 (size: 546.0 B, free: 408.5 MB)
18/06/26 03:24:37 INFO spark.SparkContext: Created broadcast 21 from run at ThreadPoolExecutor.java:1142
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Added taskresult_11 in memory on 10.0.1.2:46588 (size: 1476.1 KB, free: 910.6 MB)
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:38 INFO client.TransportClientFactory: Successfully created connection to /10.0.1.2:46588 after 3 ms (0 ms spent in bootstraps)
18/06/26 03:24:38 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 5.0 (TID 11) in 2689 ms on 10.0.1.2 (executor 0) (1/2)
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Removed taskresult_11 on 10.0.1.2:46588 in memory (size: 1476.1 KB, free: 912.1 MB)
18/06/26 03:24:38 INFO codegen.CodeGenerator: Code generated in 86.783876 ms
18/06/26 03:24:38 INFO codegen.CodeGenerator: Code generated in 13.248013 ms
18/06/26 03:24:38 INFO codegen.CodeGenerator: Code generated in 10.611898 ms
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Added taskresult_10 in memory on 10.0.1.1:32861 (size: 1479.5 KB, free: 910.6 MB)
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:38 INFO client.TransportClientFactory: Successfully created connection to /10.0.1.1:32861 after 2 ms (0 ms spent in bootstraps)
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 320
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 332
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Added taskresult_8 in memory on 10.0.1.2:46588 (size: 2.9 MB, free: 909.2 MB)
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.1.2:46588 in memory (size: 5.7 KB, free: 909.2 MB)
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on dc1master-lan1:32913 in memory (size: 5.7 KB, free: 408.5 MB)
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.1.1:32861 in memory (size: 5.7 KB, free: 910.6 MB)
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 326
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 336
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 194
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 321
18/06/26 03:24:38 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 291.2 KB, free 399.7 MB)
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 198
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 318
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 201
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 209
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 196
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 330
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 203
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 329
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 335
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 193
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on dc1master-lan1:32913 in memory (size: 6.0 KB, free: 408.5 MB)
18/06/26 03:24:38 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 10) in 2830 ms on 10.0.1.1 (executor 1) (2/2)
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/06/26 03:24:38 INFO scheduler.DAGScheduler: ResultStage 5 (run at ThreadPoolExecutor.java:1142) finished in 2.838 s
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.1.1:32861 in memory (size: 6.0 KB, free: 910.6 MB)
18/06/26 03:24:38 INFO scheduler.DAGScheduler: Job 5 finished: run at ThreadPoolExecutor.java:1142, took 2.996266 s
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.1.2:46588 in memory (size: 6.0 KB, free: 909.2 MB)
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Removed taskresult_10 on 10.0.1.1:32861 in memory (size: 1479.5 KB, free: 912.1 MB)
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 323
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 331
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 192
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 195
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 200
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 210
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 216
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 339
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 338
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 197
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 327
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 204
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 340
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 208
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 215
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 205
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 325
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 337
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 214
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 212
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 211
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 334
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 213
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 199
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 317
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 202
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 206
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 341
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 333
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 324
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 322
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 328
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 207
18/06/26 03:24:38 INFO spark.ContextCleaner: Cleaned accumulator 319
18/06/26 03:24:38 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 25.1 KB, free 399.7 MB)
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on dc1master-lan1:32913 (size: 25.1 KB, free: 408.5 MB)
18/06/26 03:24:38 INFO spark.SparkContext: Created broadcast 22 from 
18/06/26 03:24:38 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 2856 ms on 10.0.1.2 (executor 0) (1/2)
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Removed taskresult_8 on 10.0.1.2:46588 in memory (size: 2.9 MB, free: 912.1 MB)
18/06/26 03:24:38 INFO codegen.CodeGenerator: Code generated in 10.420782 ms
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:38 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:38 INFO codegen.CodeGenerator: Code generated in 14.93224 ms
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Added taskresult_9 in memory on 10.0.1.1:32861 (size: 2.9 MB, free: 909.2 MB)
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:38 INFO codegen.CodeGenerator: Code generated in 13.717486 ms
18/06/26 03:24:38 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 291.0 KB, free 399.4 MB)
18/06/26 03:24:38 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 25.0 KB, free 399.4 MB)
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on dc1master-lan1:32913 (size: 25.0 KB, free: 408.4 MB)
18/06/26 03:24:38 INFO spark.SparkContext: Created broadcast 23 from 
18/06/26 03:24:38 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 9) in 3006 ms on 10.0.1.1 (executor 1) (2/2)
18/06/26 03:24:38 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/06/26 03:24:38 INFO scheduler.DAGScheduler: ResultStage 4 (run at ThreadPoolExecutor.java:1142) finished in 3.013 s
18/06/26 03:24:38 INFO scheduler.DAGScheduler: Job 1 finished: run at ThreadPoolExecutor.java:1142, took 3.162334 s
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Removed taskresult_9 on 10.0.1.1:32861 in memory (size: 2.9 MB, free: 912.1 MB)
18/06/26 03:24:38 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:38 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 19.0 MB, free 380.4 MB)
18/06/26 03:24:38 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 39.0 MB, free 341.4 MB)
18/06/26 03:24:38 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.4 MB, free 337.9 MB)
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on dc1master-lan1:32913 (size: 3.4 MB, free: 405.0 MB)
18/06/26 03:24:38 INFO spark.SparkContext: Created broadcast 24 from run at ThreadPoolExecutor.java:1142
18/06/26 03:24:38 INFO codegen.CodeGenerator: Code generated in 52.873776 ms
18/06/26 03:24:38 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 4.0 MB, free 333.9 MB)
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on dc1master-lan1:32913 (size: 4.0 MB, free: 401.0 MB)
18/06/26 03:24:38 INFO memory.MemoryStore: Block broadcast_25_piece1 stored as bytes in memory (estimated size 2.9 MB, free 331.0 MB)
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Added broadcast_25_piece1 in memory on dc1master-lan1:32913 (size: 2.9 MB, free: 398.1 MB)
18/06/26 03:24:38 INFO spark.SparkContext: Created broadcast 25 from run at ThreadPoolExecutor.java:1142
18/06/26 03:24:38 INFO codegen.CodeGenerator: Code generated in 63.579633 ms
18/06/26 03:24:38 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 291.8 KB, free 330.8 MB)
18/06/26 03:24:38 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 25.2 KB, free 330.7 MB)
18/06/26 03:24:38 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on dc1master-lan1:32913 (size: 25.2 KB, free: 398.1 MB)
18/06/26 03:24:38 INFO spark.SparkContext: Created broadcast 26 from 
18/06/26 03:24:38 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:38 INFO codegen.CodeGenerator: Code generated in 16.529891 ms
18/06/26 03:24:39 INFO codegen.CodeGenerator: Code generated in 56.152007 ms
18/06/26 03:24:39 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 291.7 KB, free 330.5 MB)
18/06/26 03:24:39 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 25.2 KB, free 330.4 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on dc1master-lan1:32913 (size: 25.2 KB, free: 398.1 MB)
18/06/26 03:24:39 INFO spark.SparkContext: Created broadcast 27 from 
18/06/26 03:24:39 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 03:24:39 INFO spark.SparkContext: Starting job: processCmd at CliDriver.java:376
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Registering RDD 61 (processCmd at CliDriver.java:376)
18/06/26 03:24:39 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerShuffle id:1
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Registering RDD 53 (processCmd at CliDriver.java:376)
18/06/26 03:24:39 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerShuffle id:0
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Registering RDD 66 (processCmd at CliDriver.java:376)
18/06/26 03:24:39 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerShuffle id:2
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Registering RDD 82 (processCmd at CliDriver.java:376)
18/06/26 03:24:39 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerShuffle id:4
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Registering RDD 74 (processCmd at CliDriver.java:376)
18/06/26 03:24:39 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerShuffle id:3
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Registering RDD 87 (processCmd at CliDriver.java:376)
18/06/26 03:24:39 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerShuffle id:5
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Got job 8 (processCmd at CliDriver.java:376) with 4 output partitions
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (processCmd at CliDriver.java:376)
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 13)
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[61] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:24:39 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 13.7 KB, free 330.4 MB)
18/06/26 03:24:39 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 6.7 KB, free 330.4 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on dc1master-lan1:32913 (size: 6.7 KB, free: 398.1 MB)
18/06/26 03:24:39 INFO spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[61] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: Adding task set 8.0 with 2 tasks
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[53] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 16, 10.0.1.1, executor 1, partition 0, ANY, 7909 bytes)
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 8.0 (TID 17, 10.0.1.2, executor 0, partition 1, ANY, 7909 bytes)
18/06/26 03:24:39 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 15.0 KB, free 330.4 MB)
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:24:39 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 7.1 KB, free 330.4 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on dc1master-lan1:32913 (size: 7.1 KB, free: 398.1 MB)
18/06/26 03:24:39 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[53] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: Adding task set 9.0 with 6 tasks
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[82] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 18, 10.0.1.1, executor 1, partition 0, ANY, 7907 bytes)
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 9.0 (TID 19, 10.0.1.2, executor 0, partition 1, ANY, 7907 bytes)
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 9.0 (TID 20, 10.0.1.1, executor 1, partition 2, ANY, 7907 bytes)
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 9.0 (TID 21, 10.0.1.2, executor 0, partition 3, ANY, 7907 bytes)
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 9.0 (TID 22, 10.0.1.1, executor 1, partition 4, ANY, 7907 bytes)
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 9.0 (TID 23, 10.0.1.2, executor 0, partition 5, ANY, 7907 bytes)
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 6
18/06/26 03:24:39 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 84.6 KB, free 330.3 MB)
18/06/26 03:24:39 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 33.3 KB, free 330.3 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on dc1master-lan1:32913 (size: 33.3 KB, free: 398.0 MB)
18/06/26 03:24:39 INFO spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[82] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2))
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: Adding task set 11.0 with 3 tasks
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[74] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 24, 10.0.1.1, executor 1, partition 0, ANY, 7905 bytes)
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 11.0 (TID 25, 10.0.1.2, executor 0, partition 1, ANY, 7905 bytes)
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 11.0 (TID 26, 10.0.1.1, executor 1, partition 2, ANY, 7905 bytes)
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 3
18/06/26 03:24:39 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 83.1 KB, free 330.2 MB)
18/06/26 03:24:39 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 32.9 KB, free 330.2 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on dc1master-lan1:32913 (size: 32.9 KB, free: 398.0 MB)
18/06/26 03:24:39 INFO spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:39 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[74] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: Adding task set 12.0 with 5 tasks
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 8
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 8
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, 10.0.1.2, executor 0, partition 0, ANY, 7909 bytes)
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 12.0 (TID 28, 10.0.1.1, executor 1, partition 1, ANY, 7909 bytes)
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 12.0 (TID 29, 10.0.1.2, executor 0, partition 2, ANY, 7909 bytes)
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 12.0 (TID 30, 10.0.1.1, executor 1, partition 3, ANY, 7909 bytes)
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:24:39 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 12.0 (TID 31, 10.0.1.2, executor 0, partition 4, ANY, 7909 bytes)
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:39 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 5
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.1.1:32861 (size: 7.1 KB, free: 912.1 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.1.1:32861 (size: 6.7 KB, free: 912.1 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.1.2:46588 (size: 7.1 KB, free: 912.1 MB)
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.1.1:32861 (size: 33.3 KB, free: 912.0 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.1.2:46588 (size: 32.9 KB, free: 912.0 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.1.1:32861 (size: 32.9 KB, free: 912.0 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.1.2:46588 (size: 6.7 KB, free: 912.0 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 912.0 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.1.2:46588 (size: 33.3 KB, free: 912.0 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 912.0 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 911.9 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.1.2:46588 (size: 25.1 KB, free: 911.9 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.1.2:46588 (size: 25.2 KB, free: 911.9 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.1.2:46588 (size: 25.2 KB, free: 911.9 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.1.1:32861 (size: 25.2 KB, free: 911.9 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.1.1:32861 (size: 25.2 KB, free: 911.9 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_25_piece1 in memory on 10.0.1.2:46588 (size: 2.9 MB, free: 909.0 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.1.2:46588 (size: 4.0 MB, free: 905.0 MB)
18/06/26 03:24:39 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.1.1:32861 (size: 4.0 MB, free: 907.9 MB)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_25_piece1 in memory on 10.0.1.1:32861 (size: 2.9 MB, free: 905.0 MB)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.1.2:46588 (size: 3.4 MB, free: 901.6 MB)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.1.1:32861 (size: 3.4 MB, free: 901.6 MB)
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.1.2:46588 (size: 546.0 B, free: 901.6 MB)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.1.2:46588 (size: 166.0 KB, free: 901.4 MB)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.1.2:46588 (size: 713.0 B, free: 901.4 MB)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.1.2:46588 (size: 24.0 KB, free: 901.4 MB)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.1.2:46588 (size: 3.8 KB, free: 901.4 MB)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.1.1:32861 (size: 546.0 B, free: 901.6 MB)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.1.1:32861 (size: 166.0 KB, free: 901.4 MB)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.1.1:32861 (size: 713.0 B, free: 901.4 MB)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.1.1:32861 (size: 24.0 KB, free: 901.4 MB)
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:40 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 8.0 (TID 17) in 1241 ms on 10.0.1.2 (executor 0) (1/2)
18/06/26 03:24:40 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.1.1:32861 (size: 3.8 KB, free: 901.4 MB)
18/06/26 03:24:40 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:24:40 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:24:40 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:40 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 16) in 1297 ms on 10.0.1.1 (executor 1) (2/2)
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/06/26 03:24:40 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:24:40 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/2b/shuffle_1_0_0.data
18/06/26 03:24:40 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0f/shuffle_1_0_0.index
18/06/26 03:24:40 INFO scheduler.DAGScheduler: ShuffleMapStage 8 (processCmd at CliDriver.java:376) finished in 1.308 s
18/06/26 03:24:40 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:24:40 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 12, ShuffleMapStage 9, ShuffleMapStage 11)
18/06/26 03:24:40 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:24:40 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:40 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 11.0 (TID 26) in 1794 ms on 10.0.1.1 (executor 1) (1/3)
18/06/26 03:24:40 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:24:40 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/3a/shuffle_4_2_0.data
18/06/26 03:24:40 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_4_2_0.index
18/06/26 03:24:41 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:41 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:41 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:41 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:41 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 12.0 (TID 31) in 2056 ms on 10.0.1.2 (executor 0) (1/5)
18/06/26 03:24:41 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:24:41 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/1b/shuffle_3_4_0.data
18/06/26 03:24:41 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/37/shuffle_3_4_0.index
18/06/26 03:24:41 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:41 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:41 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:41 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 12.0 (TID 29) in 3166 ms on 10.0.1.2 (executor 0) (2/5)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/19/shuffle_3_2_0.data
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_3_2_0.index
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 11.0 (TID 25) in 3196 ms on 10.0.1.2 (executor 0) (2/3)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/27/shuffle_4_1_0.data
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_4_1_0.index
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 3262 ms on 10.0.1.2 (executor 0) (3/5)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/17/shuffle_3_0_0.data
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_3_0_0.index
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 12.0 (TID 30) in 3273 ms on 10.0.1.1 (executor 1) (4/5)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/06/shuffle_3_3_0.data
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_3_3_0.index
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 9.0 (TID 23) in 3354 ms on 10.0.1.2 (executor 0) (1/6)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/27/shuffle_0_5_0.data
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_0_5_0.index
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 24) in 3379 ms on 10.0.1.1 (executor 1) (3/3)
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_4_0_0.data
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_4_0_0.index
18/06/26 03:24:42 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (processCmd at CliDriver.java:376) finished in 3.386 s
18/06/26 03:24:42 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:24:42 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 12, ShuffleMapStage 9)
18/06/26 03:24:42 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:24:42 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:42 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 12.0 (TID 28) in 3386 ms on 10.0.1.1 (executor 1) (5/5)
18/06/26 03:24:42 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/08/shuffle_3_1_0.data
18/06/26 03:24:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_3_1_0.index
18/06/26 03:24:42 INFO scheduler.DAGScheduler: ShuffleMapStage 12 (processCmd at CliDriver.java:376) finished in 3.396 s
18/06/26 03:24:42 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:24:42 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 9)
18/06/26 03:24:42 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:24:42 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 9.0 (TID 21) in 3813 ms on 10.0.1.2 (executor 0) (2/6)
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/29/shuffle_0_3_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_0_3_0.index
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 9.0 (TID 19) in 3820 ms on 10.0.1.2 (executor 0) (3/6)
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/15/shuffle_0_1_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_0_1_0.index
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 9.0 (TID 22) in 3860 ms on 10.0.1.1 (executor 1) (4/6)
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_0_4_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_4_0.index
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 9.0 (TID 20) in 3908 ms on 10.0.1.1 (executor 1) (5/6)
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/36/shuffle_0_2_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_0_2_0.index
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 18) in 3960 ms on 10.0.1.1 (executor 1) (6/6)
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_0_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/30/shuffle_0_0_0.index
18/06/26 03:24:43 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (processCmd at CliDriver.java:376) finished in 3.966 s
18/06/26 03:24:43 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:24:43 INFO scheduler.DAGScheduler: running: Set()
18/06/26 03:24:43 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:24:43 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:24:43 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[66] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6712089
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6712089
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6740957
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6740957
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6713052
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6713052
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5650567
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5650567
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6784375
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6784375
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742882
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742882
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6714987
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6714987
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6704143
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6704143
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6707345
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6707345
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5647636
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5647636
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6769123
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6769123
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720557
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720557
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6709715
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6709715
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6710875
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6710875
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6748485
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6748485
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5651565
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5651565
18/06/26 03:24:43 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 81.7 KB, free 330.1 MB)
18/06/26 03:24:43 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 32.1 KB, free 330.0 MB)
18/06/26 03:24:43 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on dc1master-lan1:32913 (size: 32.1 KB, free: 398.0 MB)
18/06/26 03:24:43 INFO spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1074
18/06/26 03:24:43 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[66] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: Adding task set 10.0 with 4 tasks
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 32, 10.0.1.1, executor 1, partition 0, NODE_LOCAL, 8075 bytes)
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:24:43 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 10.0 (TID 33, 10.0.1.2, executor 0, partition 1, NODE_LOCAL, 8075 bytes)
18/06/26 03:24:43 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 10.0 (TID 34, 10.0.1.1, executor 1, partition 2, NODE_LOCAL, 8075 bytes)
18/06/26 03:24:43 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 10.0 (TID 35, 10.0.1.2, executor 0, partition 3, NODE_LOCAL, 8075 bytes)
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:24:43 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:24:43 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.1.1:32861 (size: 32.1 KB, free: 901.4 MB)
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:24:43 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.1.2:46588 (size: 32.1 KB, free: 901.4 MB)
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6784375
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6784375
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6784375
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6784375
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6769123
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6769123
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742882
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742882
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742882
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742882
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720557
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720557
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6712089
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6712089
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6712089
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6712089
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6714987
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6714987
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6712089
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6712089
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6714987
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6714987
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6709715
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6709715
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6740957
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6740957
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6740957
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6740957
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6704143
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6704143
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6740957
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6740957
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6704143
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6704143
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6710875
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6710875
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6713052
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6713052
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6713052
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6713052
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6707345
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6707345
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6713052
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6713052
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6707345
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6707345
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6748485
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6748485
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5650567
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5650567
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5650567
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5650567
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5647636
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5647636
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5650567
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5650567
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5647636
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5647636
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5651565
18/06/26 03:24:43 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5651565
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.1, 1 -> 10.0.1.2, 2 -> 10.0.1.1, 3 -> 10.0.1.2, 4 -> 10.0.1.1, 5 -> 10.0.1.2)
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.1, 1 -> 10.0.1.2, 2 -> 10.0.1.1, 3 -> 10.0.1.2)
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_2_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_0_3_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 5_0_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 5
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_0_5_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 5_2_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 5
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_0_5_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_0_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_0_1_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_0_1_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_0_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_0_3_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 4_1_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_4_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_0_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 6796083
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6764532
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/15/shuffle_0_1_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6738128
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/30/shuffle_0_0_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 2_3_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_0_2_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_0_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 20344990
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6769123
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/15/shuffle_0_1_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 13458961
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6742882
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 2_1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/36/shuffle_0_2_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 6742152
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6712089
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/29/shuffle_0_3_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6723039
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 5_0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 5
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/27/shuffle_0_5_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 5655515
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 4_1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_0_4_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 6711026
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6713052
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/29/shuffle_0_3_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 13463996
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6704143
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 2_3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/36/shuffle_0_2_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 20169228
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6709715
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 4_3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_0_4_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 20131423
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6748485
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 5_2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 5
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/27/shuffle_0_5_0.data
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 11306082
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 5647636
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 4_3_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 4
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_4_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/30/shuffle_0_0_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ filename: 2_1_redundant
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_0_2_0.index
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:24:43 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:24:43 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:43 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:43 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:43 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:43 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:44 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:44 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:44 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:44 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:44 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:44 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:44 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:44 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:44 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:44 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:44 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:44 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:45 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:45 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:45 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:45 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:45 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:45 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:45 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:45 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:45 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:45 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:45 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:45 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:46 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:46 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:46 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:46 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:46 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:46 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:46 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:46 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:46 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:46 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:46 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:46 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:46 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:46 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:46 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:46 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:47 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:47 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:47 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:47 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:47 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:47 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:47 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:47 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:47 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:47 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:47 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:47 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:47 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:47 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:47 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:47 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:48 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:48 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:48 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:48 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:48 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:48 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:48 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:48 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:48 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:48 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:48 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:48 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:49 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:49 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:49 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:49 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:49 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:49 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:49 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:49 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:49 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:49 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:49 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:49 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:49 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:49 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:49 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:49 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:50 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:50 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:50 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:50 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:50 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:50 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:50 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:50 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:50 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:50 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:50 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:50 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:51 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:51 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:51 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:51 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:51 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:51 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:51 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:51 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:51 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:51 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:51 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:51 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:51 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:51 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:51 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:51 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:52 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:52 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:52 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:52 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:52 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:52 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:52 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:52 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:52 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:52 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:52 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:52 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:52 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:52 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:52 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:52 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:53 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:53 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:53 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:53 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:53 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:53 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:53 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:53 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:53 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:53 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:53 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:53 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:54 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:54 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:54 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:54 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:54 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:54 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:54 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:54 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:54 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:54 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:54 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:54 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:55 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:55 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:55 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:55 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:55 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:55 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:55 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:55 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:55 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:55 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:55 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:55 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:56 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:56 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:56 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:56 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:56 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:56 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:56 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:56 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:56 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:56 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:56 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:56 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:56 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:56 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:56 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:56 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:57 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:57 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:57 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:57 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:57 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:57 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:57 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:57 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:57 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:57 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:57 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:57 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:57 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:57 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:57 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:57 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:58 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:58 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:58 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:58 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:58 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:58 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:58 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:58 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:58 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:58 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:58 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:58 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:58 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:58 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:58 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:58 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:24:59 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:59 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:59 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:59 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:59 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:24:59 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:59 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:59 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:59 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:59 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:59 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:24:59 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:24:59 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:24:59 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:24:59 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:24:59 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:00 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:00 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:00 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:00 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:00 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:00 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:00 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:00 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:00 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:00 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:00 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:00 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:00 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:00 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:00 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:00 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:01 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:01 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:01 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:01 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:01 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:01 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:01 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:01 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:01 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:01 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:01 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:01 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:02 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:02 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:02 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:02 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:02 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:02 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:02 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:02 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:02 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:02 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:02 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:02 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:02 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:02 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:02 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:02 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:03 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:03 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:03 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:03 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:03 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:03 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:03 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:03 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:03 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:03 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:03 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:03 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:04 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:04 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:04 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:04 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:04 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:04 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:04 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:04 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:04 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:04 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:04 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:04 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:04 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:04 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:04 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:04 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:05 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:05 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:05 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:05 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:05 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:05 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:05 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:05 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6784375
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6784375
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6769123
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6769123
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742882
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742882
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720557
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720557
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6712089
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6712089
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6714987
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6714987
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6709715
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6709715
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6740957
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6740957
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6704143
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6704143
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6710875
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6710875
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6713052
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6713052
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6707345
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6707345
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6748485
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6748485
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5650567
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5650567
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5647636
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5647636
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5651565
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5651565
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 157279661
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:25:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.1, 1 -> 10.0.1.2)
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.1, 1 -> 10.0.1.2, 2 -> 10.0.1.1, 3 -> 10.0.1.2)
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/2b/shuffle_1_0_0.data
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1540980
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1524571
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1508900
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3_redundant
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0f/shuffle_1_0_0.index
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/2b/shuffle_1_0_0.data
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4600294
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1527125
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 3034874
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1545036
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_0_redundant
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1_redundant
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0f/shuffle_1_0_0.index
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2_redundant
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:05 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:25:06 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:06 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:06 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:06 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:06 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:06 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:06 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:06 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:06 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:06 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:07 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:07 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:07 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:07 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:07 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6796083
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6764532
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6784375
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6769123
18/06/26 03:25:07 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6738128
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6720833
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6742882
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6720557
18/06/26 03:25:07 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6742152
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6712089
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6714987
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6709715
18/06/26 03:25:07 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6723039
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6740957
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6704143
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6710875
18/06/26 03:25:07 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6711026
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6713052
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6707345
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 6748485
18/06/26 03:25:07 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 5655515
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 5650567
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 5647636
18/06/26 03:25:07 INFO scheduler.RawMapStatus: 5651565
18/06/26 03:25:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:07 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:07 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:07 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:07 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:07 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:07 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:07 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:07 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:08 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:08 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:08 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:08 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:08 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:08 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:08 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:08 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:08 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:08 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:08 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:08 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:08 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:08 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:08 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:08 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:09 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:09 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:09 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:09 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:09 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:09 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:09 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:09 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:09 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:09 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:09 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:09 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:09 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:09 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:09 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:09 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:11 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:11 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:11 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:11 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:12 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:25:12 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:25:12 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:25:12 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:12 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:12 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:12 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:12 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:12 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:12 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:12 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:13 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:13 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:13 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:13 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:13 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:13 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:13 INFO scheduler.RawMapStatus: 1540980
18/06/26 03:25:13 INFO scheduler.RawMapStatus: 1524571
18/06/26 03:25:13 INFO scheduler.RawMapStatus: 1534743
18/06/26 03:25:13 INFO scheduler.RawMapStatus: 1527125
18/06/26 03:25:13 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:13 INFO scheduler.RawMapStatus: 1508900
18/06/26 03:25:13 INFO scheduler.RawMapStatus: 1525974
18/06/26 03:25:13 INFO scheduler.RawMapStatus: 1545036
18/06/26 03:25:13 INFO scheduler.RawMapStatus: 1520678
18/06/26 03:25:13 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:13 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.1.1:32861 (size: 575.0 B, free: 901.4 MB)
18/06/26 03:25:13 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.1.2:46588 (size: 575.0 B, free: 901.4 MB)
18/06/26 03:25:14 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:14 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:14 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:14 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:15 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:15 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:15 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:15 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 32) in 33110 ms on 10.0.1.1 (executor 1) (1/4)
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 10.0 (TID 34) in 33106 ms on 10.0.1.1 (executor 1) (2/4)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_2_0_0.data
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_2_0_0.index
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_2_2_0.data
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_2_2_0.index
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 10.0 (TID 33) in 33158 ms on 10.0.1.2 (executor 0) (3/4)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/29/shuffle_2_1_0.data
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_2_1_0.index
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 10.0 (TID 35) in 33180 ms on 10.0.1.2 (executor 0) (4/4)
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/27/shuffle_2_3_0.data
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_2_3_0.index
18/06/26 03:25:16 INFO scheduler.DAGScheduler: ShuffleMapStage 10 (processCmd at CliDriver.java:376) finished in 33.196 s
18/06/26 03:25:16 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:16 INFO scheduler.DAGScheduler: running: Set()
18/06/26 03:25:16 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ResultStage 14)
18/06/26 03:25:16 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:16 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[87] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 294
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 294
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 285
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 285
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 286
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 286
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 157
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 157
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 165
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 165
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 160
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 160
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 267
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 267
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 157
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 157
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 149
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 149
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 197
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 197
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 184
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 184
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 91
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 91
18/06/26 03:25:16 INFO memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 155.4 KB, free 329.9 MB)
18/06/26 03:25:16 INFO memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 60.1 KB, free 329.8 MB)
18/06/26 03:25:16 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on dc1master-lan1:32913 (size: 60.1 KB, free: 397.9 MB)
18/06/26 03:25:16 INFO spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:16 INFO scheduler.DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[87] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: Adding task set 13.0 with 12 tasks
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 36, 10.0.1.1, executor 1, partition 0, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 13.0 (TID 37, 10.0.1.2, executor 0, partition 1, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 13.0 (TID 38, 10.0.1.1, executor 1, partition 2, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 13.0 (TID 39, 10.0.1.2, executor 0, partition 3, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 13.0 (TID 40, 10.0.1.1, executor 1, partition 8, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 13.0 (TID 41, 10.0.1.2, executor 0, partition 4, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 13.0 (TID 42, 10.0.1.1, executor 1, partition 9, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 13.0 (TID 43, 10.0.1.2, executor 0, partition 5, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 13.0 (TID 44, 10.0.1.1, executor 1, partition 10, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 13.0 (TID 45, 10.0.1.2, executor 0, partition 6, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 13.0 (TID 46, 10.0.1.1, executor 1, partition 11, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 13.0 (TID 47, 10.0.1.2, executor 0, partition 7, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 4
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 5
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 5
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 5
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 5
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 5
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 5
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 6
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 6
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 6
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 6
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 6
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 6
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 7
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 7
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 7
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:16 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 7
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 7
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 7
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:16 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:25:16 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.1.1:32861 (size: 60.1 KB, free: 901.3 MB)
18/06/26 03:25:16 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.1.2:46588 (size: 60.1 KB, free: 901.3 MB)
18/06/26 03:25:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 4 to 10.0.1.1:34004
18/06/26 03:25:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 2 to 10.0.1.1:34004
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 4 to 10.0.1.1:34004
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 2 to 10.0.1.1:34004
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 3 to 10.0.1.2:52552
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 3 to 10.0.1.2:52552
18/06/26 03:25:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 2 to 10.0.1.2:52552
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 2 to 10.0.1.2:52552
18/06/26 03:25:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.1.1:34004
18/06/26 03:25:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.1.1:34004
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 283
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 164
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 194
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 283
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 157
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 197
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 267
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 149
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 184
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 290
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 91
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 162
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 294
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 157
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 285
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 165
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 286
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 160
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.1.2:52552
18/06/26 03:25:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.1.2:52552
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 2338
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 2675
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 2405
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 2382
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 13.0 (TID 42) in 1215 ms on 10.0.1.1 (executor 1) (1/12)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 13.0 (TID 40) in 1216 ms on 10.0.1.1 (executor 1) (2/12)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 13.0 (TID 46) in 1215 ms on 10.0.1.1 (executor 1) (3/12)
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/02/shuffle_5_9_0.data
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/3e/shuffle_5_9_0.index
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/1f/shuffle_5_8_0.data
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/03/shuffle_5_8_0.index
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/29/shuffle_5_11_0.data
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/3b/shuffle_5_11_0.index
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 13.0 (TID 44) in 1218 ms on 10.0.1.1 (executor 1) (4/12)
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_5_10_0.data
18/06/26 03:25:17 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/04/shuffle_5_10_0.index
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 13.0 (TID 38, 10.0.1.1, executor 1): FetchFailed(BlockManagerId(1, 10.0.1.1, 32861, None), shuffleId=2, mapId=1, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_2_1_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_2_1_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Task 2.0 in stage 13.0 (TID 38) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:17 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 13.0 (TID 36, 10.0.1.1, executor 1): FetchFailed(BlockManagerId(1, 10.0.1.1, 32861, None), shuffleId=2, mapId=1, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_2_1_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_2_1_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Task 0.0 in stage 13.0 (TID 36) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Marking ShuffleMapStage 13 (processCmd at CliDriver.java:376) as failed due to a fetch failure from ShuffleMapStage 10 (processCmd at CliDriver.java:376)
18/06/26 03:25:17 INFO scheduler.DAGScheduler: ShuffleMapStage 13 (processCmd at CliDriver.java:376) failed in 1.251 s due to org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_2_1_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_2_1_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

18/06/26 03:25:17 INFO scheduler.DAGScheduler: Resubmitting ShuffleMapStage 10 (processCmd at CliDriver.java:376) and ShuffleMapStage 13 (processCmd at CliDriver.java:376) due to fetch failure
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 5)
18/06/26 03:25:17 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
18/06/26 03:25:17 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 10.0.1.1, 32861, None)
18/06/26 03:25:17 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 1 (epoch 5)
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 13.0 (TID 37, 10.0.1.2, executor 0): FetchFailed(BlockManagerId(0, 10.0.1.2, 46588, None), shuffleId=2, mapId=0, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_2_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_2_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Task 1.0 in stage 13.0 (TID 37) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Executor lost: 0 (epoch 5)
18/06/26 03:25:17 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
18/06/26 03:25:17 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 10.0.1.2, 46588, None)
18/06/26 03:25:17 INFO storage.BlockManagerMaster: Removed 0 successfully in removeExecutor
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 0 (epoch 5)
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 13.0 (TID 39, 10.0.1.2, executor 0): FetchFailed(BlockManagerId(0, 10.0.1.2, 46588, None), shuffleId=2, mapId=0, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_2_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_2_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Task 3.0 in stage 13.0 (TID 39) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 13.0 (TID 43) in 1278 ms on 10.0.1.2 (executor 0) (9/12)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 13.0 (TID 41) in 1279 ms on 10.0.1.2 (executor 0) (10/12)
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 5) completion from executor 0
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 4) completion from executor 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 13.0 (TID 45) in 1289 ms on 10.0.1.2 (executor 0) (11/12)
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 13.0 (TID 47) in 1289 ms on 10.0.1.2 (executor 0) (12/12)
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 6) completion from executor 0
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 7) completion from executor 0
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Resubmitting failed stages
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[61] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:17 INFO memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 13.7 KB, free 329.8 MB)
18/06/26 03:25:17 INFO memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 6.8 KB, free 329.8 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on dc1master-lan1:32913 (size: 6.8 KB, free: 397.9 MB)
18/06/26 03:25:17 INFO spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[61] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: Adding task set 8.1 with 2 tasks
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[53] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.1 (TID 48, 10.0.1.1, executor 1, partition 0, ANY, 7909 bytes)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 8.1 (TID 49, 10.0.1.2, executor 0, partition 1, ANY, 7909 bytes)
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:25:17 INFO memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 15.0 KB, free 329.8 MB)
18/06/26 03:25:17 INFO memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 7.1 KB, free 329.8 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on dc1master-lan1:32913 (size: 7.1 KB, free: 397.9 MB)
18/06/26 03:25:17 INFO spark.SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[53] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: Adding task set 9.1 with 6 tasks
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[82] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.1 (TID 50, 10.0.1.1, executor 1, partition 0, ANY, 7907 bytes)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 9.1 (TID 51, 10.0.1.2, executor 0, partition 1, ANY, 7907 bytes)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 9.1 (TID 52, 10.0.1.1, executor 1, partition 2, ANY, 7907 bytes)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 9.1 (TID 53, 10.0.1.2, executor 0, partition 3, ANY, 7907 bytes)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 9.1 (TID 54, 10.0.1.1, executor 1, partition 4, ANY, 7907 bytes)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 9.1 (TID 55, 10.0.1.2, executor 0, partition 5, ANY, 7907 bytes)
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 6
18/06/26 03:25:17 INFO memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 84.6 KB, free 329.7 MB)
18/06/26 03:25:17 INFO memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 33.4 KB, free 329.7 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on dc1master-lan1:32913 (size: 33.4 KB, free: 397.9 MB)
18/06/26 03:25:17 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.1.2:46588 with 912.3 MB RAM, BlockManagerId(0, 10.0.1.2, 46588, None)
18/06/26 03:25:17 INFO spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[82] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2))
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: Adding task set 11.1 with 3 tasks
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[74] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.1 (TID 56, 10.0.1.1, executor 1, partition 0, ANY, 7905 bytes)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 11.1 (TID 57, 10.0.1.2, executor 0, partition 1, ANY, 7905 bytes)
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 11.1 (TID 58, 10.0.1.1, executor 1, partition 2, ANY, 7905 bytes)
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 3
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.1.2:46588 (size: 3.8 KB, free: 912.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.0.1.2:46588 (size: 7.1 KB, free: 912.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.1.1:32861 with 912.3 MB RAM, BlockManagerId(1, 10.0.1.1, 32861, None)
18/06/26 03:25:17 INFO memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 83.1 KB, free 329.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.1.2:46588 (size: 6.1 KB, free: 912.3 MB)
18/06/26 03:25:17 INFO memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 32.9 KB, free 329.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on dc1master-lan1:32913 (size: 32.9 KB, free: 397.8 MB)
18/06/26 03:25:17 INFO spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:17 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[74] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: Adding task set 12.1 with 5 tasks
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 8
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 8
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.1 (TID 59, 10.0.1.2, executor 0, partition 0, ANY, 7909 bytes)
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 12.1 (TID 60, 10.0.1.1, executor 1, partition 1, ANY, 7909 bytes)
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 12.1 (TID 61, 10.0.1.2, executor 0, partition 2, ANY, 7909 bytes)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.1.2:46588 (size: 24.0 KB, free: 912.3 MB)
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 12.1 (TID 62, 10.0.1.1, executor 1, partition 3, ANY, 7909 bytes)
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:17 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 12.1 (TID 63, 10.0.1.2, executor 0, partition 4, ANY, 7909 bytes)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.0.1.1:32861 (size: 33.4 KB, free: 912.3 MB)
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 5
18/06/26 03:25:17 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.1.1:32861 (size: 3.8 KB, free: 912.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.1.2:46588 (size: 32.1 KB, free: 912.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.0.1.2:46588 (size: 33.4 KB, free: 912.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.1.1:32861 (size: 6.1 KB, free: 912.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.1.2:46588 (size: 546.0 B, free: 912.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 912.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.1.2:46588 (size: 24.9 KB, free: 912.1 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.0.1.2:46588 (size: 32.9 KB, free: 912.1 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.1.1:32861 (size: 24.0 KB, free: 912.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.1.2:46588 (size: 6.7 KB, free: 912.1 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.2:46588 (size: 24.9 KB, free: 912.1 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.1.2:46588 (size: 7.1 KB, free: 912.1 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.1.2:46588 (size: 3.4 MB, free: 908.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.0.1.1:32861 (size: 7.1 KB, free: 912.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 908.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.1.2:46588 (size: 24.8 KB, free: 908.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.1.1:32861 (size: 32.1 KB, free: 912.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.1.1:32861 (size: 546.0 B, free: 912.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 912.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.1.2:46588 (size: 25.1 KB, free: 908.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.1.2:46588 (size: 25.1 KB, free: 908.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.1.1:32861 (size: 24.9 KB, free: 912.1 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_25_piece1 in memory on 10.0.1.2:46588 (size: 2.9 MB, free: 905.7 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.1.2:46588 (size: 5.9 KB, free: 905.7 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.0.1.1:32861 (size: 32.9 KB, free: 912.1 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.1.1:32861 (size: 6.7 KB, free: 912.1 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.1:32861 (size: 24.9 KB, free: 912.1 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 905.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.1.1:32861 (size: 7.1 KB, free: 912.1 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.1.1:32861 (size: 3.4 MB, free: 908.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 908.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.1.1:32861 (size: 24.8 KB, free: 908.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 908.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.1.2:46588 (size: 25.1 KB, free: 905.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 908.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.1.2:46588 (size: 60.1 KB, free: 905.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_25_piece1 in memory on 10.0.1.1:32861 (size: 2.9 MB, free: 905.7 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.1.2:46588 (size: 33.3 KB, free: 905.5 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.1.2:46588 (size: 25.2 KB, free: 905.5 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.1.2:46588 (size: 32.9 KB, free: 905.5 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.1.2:46588 (size: 166.0 KB, free: 905.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.1.2:46588 (size: 713.0 B, free: 905.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.1.2:46588 (size: 6.0 KB, free: 905.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.1.2:46588 (size: 6.1 KB, free: 905.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.1.2:46588 (size: 6.2 KB, free: 905.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.1.2:46588 (size: 4.0 MB, free: 901.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.0.1.2:46588 (size: 6.8 KB, free: 901.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.1.2:46588 (size: 25.2 KB, free: 901.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 905.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.1.2:46588 (size: 575.0 B, free: 901.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.1.2:46588 (size: 6.0 KB, free: 901.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 901.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.1.1:32861 (size: 5.9 KB, free: 905.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 905.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.1.1:32861 (size: 60.1 KB, free: 905.6 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.1.1:32861 (size: 33.3 KB, free: 905.5 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.1.1:32861 (size: 25.2 KB, free: 905.5 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.1.1:32861 (size: 32.9 KB, free: 905.5 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.1.1:32861 (size: 166.0 KB, free: 905.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.1.1:32861 (size: 713.0 B, free: 905.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.1.1:32861 (size: 6.0 KB, free: 905.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.1.1:32861 (size: 6.1 KB, free: 905.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.1.1:32861 (size: 6.2 KB, free: 905.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.1.1:32861 (size: 4.0 MB, free: 901.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.0.1.1:32861 (size: 6.8 KB, free: 901.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.1.1:32861 (size: 25.2 KB, free: 901.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.1.1:32861 (size: 575.0 B, free: 901.3 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.1.1:32861 (size: 6.0 KB, free: 901.2 MB)
18/06/26 03:25:17 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 901.2 MB)
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:18 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 11.1 (TID 58) in 685 ms on 10.0.1.1 (executor 1) (1/3)
18/06/26 03:25:18 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:18 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/3a/shuffle_4_2_0.data
18/06/26 03:25:18 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_4_2_0.index
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:18 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.1 (TID 48) in 871 ms on 10.0.1.1 (executor 1) (1/2)
18/06/26 03:25:18 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:18 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/2b/shuffle_1_0_0.data
18/06/26 03:25:18 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0f/shuffle_1_0_0.index
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:18 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 8.1 (TID 49) in 894 ms on 10.0.1.2 (executor 0) (2/2)
18/06/26 03:25:18 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 8.1, whose tasks have all completed, from pool 
18/06/26 03:25:18 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:18 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:25:18 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:25:18 INFO scheduler.DAGScheduler: ShuffleMapStage 8 (processCmd at CliDriver.java:376) finished in 0.901 s
18/06/26 03:25:18 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:18 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 12, ShuffleMapStage 9, ShuffleMapStage 11)
18/06/26 03:25:18 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:25:18 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:19 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:19 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:19 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:19 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:19 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 12.1 (TID 63) in 1164 ms on 10.0.1.2 (executor 0) (1/5)
18/06/26 03:25:19 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:19 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/1b/shuffle_3_4_0.data
18/06/26 03:25:19 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/37/shuffle_3_4_0.index
18/06/26 03:25:19 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:19 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:19 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:19 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.1 (TID 56) in 2189 ms on 10.0.1.1 (executor 1) (2/3)
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_4_0_0.data
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_4_0_0.index
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 11.1 (TID 57) in 2194 ms on 10.0.1.2 (executor 0) (3/3)
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 11.1, whose tasks have all completed, from pool 
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/27/shuffle_4_1_0.data
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_4_1_0.index
18/06/26 03:25:20 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (processCmd at CliDriver.java:376) finished in 2.203 s
18/06/26 03:25:20 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:20 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 12, ShuffleMapStage 9)
18/06/26 03:25:20 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:25:20 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 12.1 (TID 60) in 2305 ms on 10.0.1.1 (executor 1) (2/5)
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/08/shuffle_3_1_0.data
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_3_1_0.index
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.1 (TID 59) in 2374 ms on 10.0.1.2 (executor 0) (3/5)
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/17/shuffle_3_0_0.data
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_3_0_0.index
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 12.1 (TID 61) in 2401 ms on 10.0.1.2 (executor 0) (4/5)
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/19/shuffle_3_2_0.data
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_3_2_0.index
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:20 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 12.1 (TID 62) in 2542 ms on 10.0.1.1 (executor 1) (5/5)
18/06/26 03:25:20 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 12.1, whose tasks have all completed, from pool 
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/06/shuffle_3_3_0.data
18/06/26 03:25:20 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_3_3_0.index
18/06/26 03:25:20 INFO scheduler.DAGScheduler: ShuffleMapStage 12 (processCmd at CliDriver.java:376) finished in 2.552 s
18/06/26 03:25:20 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:20 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 9)
18/06/26 03:25:20 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:25:20 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:21 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 9.1 (TID 55) in 4064 ms on 10.0.1.2 (executor 0) (1/6)
18/06/26 03:25:21 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:21 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/27/shuffle_0_5_0.data
18/06/26 03:25:21 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_0_5_0.index
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:21 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 9.1 (TID 53) in 4071 ms on 10.0.1.2 (executor 0) (2/6)
18/06/26 03:25:21 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:21 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/29/shuffle_0_3_0.data
18/06/26 03:25:21 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_0_3_0.index
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:21 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 9.1 (TID 51) in 4079 ms on 10.0.1.2 (executor 0) (3/6)
18/06/26 03:25:21 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:21 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/15/shuffle_0_1_0.data
18/06/26 03:25:21 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_0_1_0.index
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:22 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.1 (TID 50) in 4440 ms on 10.0.1.1 (executor 1) (4/6)
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_0_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/30/shuffle_0_0_0.index
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:22 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 9.1 (TID 52) in 4446 ms on 10.0.1.1 (executor 1) (5/6)
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/36/shuffle_0_2_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_0_2_0.index
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:22 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 9.1 (TID 54) in 4451 ms on 10.0.1.1 (executor 1) (6/6)
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 9.1, whose tasks have all completed, from pool 
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_0_4_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_4_0.index
18/06/26 03:25:22 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (processCmd at CliDriver.java:376) finished in 4.460 s
18/06/26 03:25:22 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:22 INFO scheduler.DAGScheduler: running: Set()
18/06/26 03:25:22 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:25:22 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:22 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[66] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6712089
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6712089
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6740957
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6740957
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6713052
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6713052
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5650567
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5650567
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6784375
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6784375
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742882
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742882
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6714987
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6714987
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6704143
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6704143
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6707345
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6707345
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5647636
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5647636
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6769123
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6769123
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720557
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720557
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6709715
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6709715
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6710875
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6710875
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6748485
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6748485
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5651565
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5651565
18/06/26 03:25:22 INFO memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 81.7 KB, free 329.5 MB)
18/06/26 03:25:22 INFO memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 32.1 KB, free 329.5 MB)
18/06/26 03:25:22 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on dc1master-lan1:32913 (size: 32.1 KB, free: 397.8 MB)
18/06/26 03:25:22 INFO spark.SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:22 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[66] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: Adding task set 10.1 with 4 tasks
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:22 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.1 (TID 64, 10.0.1.2, executor 0, partition 0, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:22 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 10.1 (TID 65, 10.0.1.1, executor 1, partition 1, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:25:22 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 10.1 (TID 66, 10.0.1.2, executor 0, partition 2, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:22 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 10.1 (TID 67, 10.0.1.1, executor 1, partition 3, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:22 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:22 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6784375
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6784375
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6784375
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6784375
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6769123
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6769123
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742882
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742882
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742882
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742882
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720557
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720557
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6712089
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6712089
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6712089
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6712089
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6714987
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6714987
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6712089
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6712089
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6714987
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6714987
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6709715
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6709715
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6740957
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6740957
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6740957
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6740957
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6704143
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6704143
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6740957
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6740957
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6704143
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6704143
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6710875
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6710875
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6713052
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6713052
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6713052
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6713052
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6707345
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6707345
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6713052
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6713052
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6707345
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6707345
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6748485
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6748485
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5650567
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5650567
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5650567
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5650567
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5647636
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5647636
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5650567
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5650567
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5647636
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5647636
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5651565
18/06/26 03:25:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5651565
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.1, 1 -> 10.0.1.2, 2 -> 10.0.1.1, 3 -> 10.0.1.2, 4 -> 10.0.1.1, 5 -> 10.0.1.2)
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2, 2 -> 10.0.1.1, 3 -> 10.0.1.2)
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_2_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_0_3_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_0_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/30/shuffle_0_0_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 5_2_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 5
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_0_5_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 2_0_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_0_2_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 4_0_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_4_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_0_1_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 4_1_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_4_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_0_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6796083
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_0_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 6796083
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6764532
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/30/shuffle_0_0_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 2_0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/36/shuffle_0_2_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6742152
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 2_3_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_0_2_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_0_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 20344990
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6769123
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/15/shuffle_0_1_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 13458961
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6742882
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 2_1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/36/shuffle_0_2_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 6742152
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6712089
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 4_0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_0_4_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6711026
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 2_3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/36/shuffle_0_2_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 20169228
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6709715
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/29/shuffle_0_3_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 13463996
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6704143
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 4_1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_0_4_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 6711026
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6713052
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 4_3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_0_4_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 20131423
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 6748485
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 5_2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 5
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/27/shuffle_0_5_0.data
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 11306082
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 5647636
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 4_3_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 4
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_4_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/30/shuffle_0_0_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ filename: 2_1_redundant
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_0_2_0.index
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.1
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.2
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:22 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:25:22 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.1.1:32861 (size: 32.1 KB, free: 901.2 MB)
18/06/26 03:25:22 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.1.2:46588 (size: 32.1 KB, free: 901.2 MB)
18/06/26 03:25:22 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:22 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:22 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:23 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:23 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:23 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:23 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:23 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:23 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6796083
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6764532
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6784375
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6769123
18/06/26 03:25:23 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6738128
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6720833
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6742882
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6720557
18/06/26 03:25:23 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6742152
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6712089
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6714987
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6709715
18/06/26 03:25:23 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6723039
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6740957
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6704143
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6710875
18/06/26 03:25:23 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6711026
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6713052
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6707345
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 6748485
18/06/26 03:25:23 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 5655515
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 5650567
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 5647636
18/06/26 03:25:23 INFO scheduler.RawMapStatus: 5651565
18/06/26 03:25:23 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:23 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:23 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:23 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:23 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:23 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:23 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:24 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:24 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:24 INFO scheduler.RawMapStatus: 1540980
18/06/26 03:25:24 INFO scheduler.RawMapStatus: 1524571
18/06/26 03:25:24 INFO scheduler.RawMapStatus: 1534743
18/06/26 03:25:24 INFO scheduler.RawMapStatus: 1527125
18/06/26 03:25:24 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:24 INFO scheduler.RawMapStatus: 1508900
18/06/26 03:25:24 INFO scheduler.RawMapStatus: 1525974
18/06/26 03:25:24 INFO scheduler.RawMapStatus: 1545036
18/06/26 03:25:24 INFO scheduler.RawMapStatus: 1520678
18/06/26 03:25:24 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:25 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:25 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:25 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:25 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.1 (TID 64) in 4247 ms on 10.0.1.2 (executor 0) (1/4)
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 10.1 (TID 66) in 4246 ms on 10.0.1.2 (executor 0) (2/4)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_2_0_0.data
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_2_0_0.index
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/38/shuffle_2_2_0.data
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_2_2_0.index
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 10.1 (TID 67) in 4289 ms on 10.0.1.1 (executor 1) (3/4)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/27/shuffle_2_3_0.data
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/35/shuffle_2_3_0.index
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 10.1 (TID 65) in 4315 ms on 10.0.1.1 (executor 1) (4/4)
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 10.1, whose tasks have all completed, from pool 
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/29/shuffle_2_1_0.data
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0d/shuffle_2_1_0.index
18/06/26 03:25:26 INFO scheduler.DAGScheduler: ShuffleMapStage 10 (processCmd at CliDriver.java:376) finished in 4.325 s
18/06/26 03:25:26 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:26 INFO scheduler.DAGScheduler: running: Set()
18/06/26 03:25:26 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ResultStage 14)
18/06/26 03:25:26 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:26 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[87] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 294
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 294
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 285
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 285
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 286
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 286
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 157
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 157
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 165
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 165
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 160
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 160
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 267
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 267
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 157
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 157
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 149
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 149
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 197
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 197
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 184
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 184
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 91
18/06/26 03:25:26 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 91
18/06/26 03:25:26 INFO memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 155.4 KB, free 329.3 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on dc1master-lan1:32913 in memory (size: 60.1 KB, free: 397.8 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on 10.0.1.2:46588 in memory (size: 60.1 KB, free: 901.2 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on 10.0.1.1:32861 in memory (size: 60.1 KB, free: 901.2 MB)
18/06/26 03:25:26 INFO memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 60.1 KB, free 329.5 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on dc1master-lan1:32913 (size: 60.1 KB, free: 397.8 MB)
18/06/26 03:25:26 INFO spark.SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 485
18/06/26 03:25:26 INFO scheduler.DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[87] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 384
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: Adding task set 13.1 with 12 tasks
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 387
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 472
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 399
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on dc1master-lan1:32913 in memory (size: 33.4 KB, free: 397.8 MB)
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.1 (TID 68, 10.0.1.2, executor 0, partition 0, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on 10.0.1.1:32861 in memory (size: 33.4 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 13.1 (TID 69, 10.0.1.1, executor 1, partition 1, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 13.1 (TID 70, 10.0.1.2, executor 0, partition 2, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on 10.0.1.2:46588 in memory (size: 33.4 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 13.1 (TID 71, 10.0.1.1, executor 1, partition 3, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 13.1 (TID 72, 10.0.1.2, executor 0, partition 4, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 13.1 (TID 73, 10.0.1.1, executor 1, partition 8, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 13.1 (TID 74, 10.0.1.2, executor 0, partition 5, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 13.1 (TID 75, 10.0.1.1, executor 1, partition 9, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 13.1 (TID 76, 10.0.1.2, executor 0, partition 6, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 455
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 13.1 (TID 77, 10.0.1.1, executor 1, partition 10, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 13.1 (TID 78, 10.0.1.2, executor 0, partition 7, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 13.1 (TID 79, 10.0.1.1, executor 1, partition 11, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 5
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 5
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 5
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on dc1master-lan1:32913 in memory (size: 32.9 KB, free: 397.9 MB)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 6
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 6
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 6
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on 10.0.1.1:32861 in memory (size: 32.9 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 7
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 7
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 7
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:26 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on 10.0.1.2:46588 in memory (size: 32.9 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 440
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 378
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 400
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 397
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 497
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 419
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 410
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 425
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 389
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 381
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 500
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 490
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 376
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 412
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 368
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 509
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 409
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 461
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 413
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 435
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 471
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 466
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 492
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on dc1master-lan1:32913 in memory (size: 32.1 KB, free: 397.9 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on 10.0.1.1:32861 in memory (size: 32.1 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on 10.0.1.2:46588 in memory (size: 32.1 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 456
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 444
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 402
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.1.2:46588 (size: 60.1 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 406
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 463
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.1.1:32861 (size: 60.1 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on dc1master-lan1:32913 in memory (size: 6.8 KB, free: 397.9 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on 10.0.1.2:46588 in memory (size: 6.8 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on 10.0.1.1:32861 in memory (size: 6.8 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 2 to 10.0.1.1:34004
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 2 to 10.0.1.1:34004
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:26 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 4 to 10.0.1.1:34004
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 4 to 10.0.1.1:34004
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:26 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 3 to 10.0.1.2:52552
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 3 to 10.0.1.2:52552
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 516
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 391
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 445
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 404
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 481
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 392
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 499
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 467
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 394
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 411
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 486
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 501
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 436
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 474
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 377
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 372
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 483
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 415
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on dc1master-lan1:32913 in memory (size: 33.3 KB, free: 397.9 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on 10.0.1.2:46588 in memory (size: 33.3 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 2 to 10.0.1.2:52552
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on 10.0.1.1:32861 in memory (size: 33.3 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 2 to 10.0.1.2:52552
18/06/26 03:25:26 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 465
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 473
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 439
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 437
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 450
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 506
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 386
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 459
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 482
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 423
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 417
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 504
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on dc1master-lan1:32913 in memory (size: 7.1 KB, free: 397.9 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on 10.0.1.2:46588 in memory (size: 7.1 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on 10.0.1.1:32861 in memory (size: 7.1 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 513
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 462
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 367
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 429
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 494
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 424
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 503
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 453
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 379
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 468
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 511
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 375
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on dc1master-lan1:32913 in memory (size: 7.1 KB, free: 397.9 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.0.1.2:46588 in memory (size: 7.1 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.0.1.1:32861 in memory (size: 7.1 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 427
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 396
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 434
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 476
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 464
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on dc1master-lan1:32913 in memory (size: 6.7 KB, free: 397.9 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.0.1.2:46588 in memory (size: 6.7 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.0.1.1:32861 in memory (size: 6.7 KB, free: 901.3 MB)
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 405
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 446
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 495
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 438
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on dc1master-lan1:32913 in memory (size: 32.9 KB, free: 398.0 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on 10.0.1.2:46588 in memory (size: 32.9 KB, free: 901.4 MB)
18/06/26 03:25:26 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on 10.0.1.1:32861 in memory (size: 32.9 KB, free: 901.4 MB)
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 430
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 421
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 426
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 458
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 369
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 475
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 496
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 408
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 433
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 393
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 451
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 449
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 505
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 491
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 442
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 484
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 479
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 374
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 407
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 470
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 373
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 390
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 388
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 431
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 515
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 401
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 469
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 502
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 498
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 414
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 508
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 383
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 512
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 398
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 477
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 403
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 370
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 432
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 441
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 416
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 480
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 418
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 448
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 514
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 489
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 460
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 420
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 510
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 454
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 428
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 443
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 447
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 457
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 478
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 488
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 422
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 493
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 507
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 382
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 452
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 385
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 371
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 380
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 487
18/06/26 03:25:26 INFO spark.ContextCleaner: Cleaned accumulator 395
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.1.1:34004
18/06/26 03:25:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.1.1:34004
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 290
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 162
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 294
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 283
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 164
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 194
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.1.2:52552
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 283
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 157
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 197
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 157
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 267
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 285
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 149
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 184
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 165
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 91
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 286
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 160
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 2338
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 2675
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 2405
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 2382
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.1.2:52552
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 13.1 (TID 69, 10.0.1.1, executor 1): FetchFailed(BlockManagerId(1, 10.0.1.1, 32861, None), shuffleId=2, mapId=0, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_2_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_2_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Task 1.0 in stage 13.1 (TID 69) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Marking ShuffleMapStage 13 (processCmd at CliDriver.java:376) as failed due to a fetch failure from ShuffleMapStage 10 (processCmd at CliDriver.java:376)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: ShuffleMapStage 13 (processCmd at CliDriver.java:376) failed in 1.083 s due to org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_2_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_2_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

18/06/26 03:25:27 INFO scheduler.DAGScheduler: Resubmitting ShuffleMapStage 10 (processCmd at CliDriver.java:376) and ShuffleMapStage 13 (processCmd at CliDriver.java:376) due to fetch failure
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 16)
18/06/26 03:25:27 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 10.0.1.1, 32861, None)
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 13.1 (TID 70, 10.0.1.2, executor 0): FetchFailed(BlockManagerId(0, 10.0.1.2, 46588, None), shuffleId=2, mapId=1, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0d/shuffle_2_1_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0d/shuffle_2_1_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:27 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Task 2.0 in stage 13.1 (TID 70) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 1 (epoch 16)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Executor lost: 0 (epoch 16)
18/06/26 03:25:27 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
18/06/26 03:25:27 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 10.0.1.2, 46588, None)
18/06/26 03:25:27 INFO storage.BlockManagerMaster: Removed 0 successfully in removeExecutor
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 0 (epoch 16)
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 13.1 (TID 78) in 1047 ms on 10.0.1.2 (executor 0) (3/12)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 7) completion from executor 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 13.1 (TID 77) in 1049 ms on 10.0.1.1 (executor 1) (4/12)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 13.1 (TID 76) in 1049 ms on 10.0.1.2 (executor 0) (5/12)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 10) completion from executor 1
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 6) completion from executor 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 13.1 (TID 79) in 1050 ms on 10.0.1.1 (executor 1) (6/12)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 11) completion from executor 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 13.1 (TID 71, 10.0.1.1, executor 1): FetchFailed(BlockManagerId(1, 10.0.1.1, 32861, None), shuffleId=2, mapId=0, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_2_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_2_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Task 3.0 in stage 13.1 (TID 71) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 13.1 (TID 75) in 1055 ms on 10.0.1.1 (executor 1) (8/12)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 13.1 (TID 74) in 1055 ms on 10.0.1.2 (executor 0) (9/12)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 9) completion from executor 1
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 13.1 (TID 72) in 1057 ms on 10.0.1.2 (executor 0) (10/12)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 5) completion from executor 0
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 13.1 (TID 73) in 1057 ms on 10.0.1.1 (executor 1) (11/12)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 4) completion from executor 0
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Ignoring possibly bogus ShuffleMapTask(13, 8) completion from executor 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:27 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 13.1 (TID 68, 10.0.1.2, executor 0): FetchFailed(BlockManagerId(0, 10.0.1.2, 46588, None), shuffleId=2, mapId=1, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0d/shuffle_2_1_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0d/shuffle_2_1_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Task 0.0 in stage 13.1 (TID 68) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 13.1, whose tasks have all completed, from pool 
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Resubmitting failed stages
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[61] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:27 INFO memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 13.7 KB, free 330.1 MB)
18/06/26 03:25:27 INFO memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 6.8 KB, free 330.1 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on dc1master-lan1:32913 (size: 6.8 KB, free: 398.0 MB)
18/06/26 03:25:27 INFO spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[61] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: Adding task set 8.2 with 2 tasks
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[53] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.2 (TID 80, 10.0.1.2, executor 0, partition 0, ANY, 7909 bytes)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 8.2 (TID 81, 10.0.1.1, executor 1, partition 1, ANY, 7909 bytes)
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:25:27 INFO memory.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 15.0 KB, free 330.1 MB)
18/06/26 03:25:27 INFO memory.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 7.1 KB, free 330.1 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on dc1master-lan1:32913 (size: 7.1 KB, free: 398.0 MB)
18/06/26 03:25:27 INFO spark.SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[53] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: Adding task set 9.2 with 6 tasks
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[82] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.2 (TID 82, 10.0.1.1, executor 1, partition 0, ANY, 7907 bytes)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 9.2 (TID 83, 10.0.1.2, executor 0, partition 1, ANY, 7907 bytes)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 9.2 (TID 84, 10.0.1.1, executor 1, partition 2, ANY, 7907 bytes)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 9.2 (TID 85, 10.0.1.2, executor 0, partition 3, ANY, 7907 bytes)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 9.2 (TID 86, 10.0.1.1, executor 1, partition 4, ANY, 7907 bytes)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 9.2 (TID 87, 10.0.1.2, executor 0, partition 5, ANY, 7907 bytes)
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 6
18/06/26 03:25:27 INFO memory.MemoryStore: Block broadcast_42 stored as values in memory (estimated size 84.6 KB, free 330.0 MB)
18/06/26 03:25:27 INFO memory.MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 33.4 KB, free 330.0 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on dc1master-lan1:32913 (size: 33.4 KB, free: 397.9 MB)
18/06/26 03:25:27 INFO spark.SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[82] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2))
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: Adding task set 11.2 with 3 tasks
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[74] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.2 (TID 88, 10.0.1.1, executor 1, partition 0, ANY, 7905 bytes)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 11.2 (TID 89, 10.0.1.2, executor 0, partition 1, ANY, 7905 bytes)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 11.2 (TID 90, 10.0.1.1, executor 1, partition 2, ANY, 7905 bytes)
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 3
18/06/26 03:25:27 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.1.2:46588 with 912.3 MB RAM, BlockManagerId(0, 10.0.1.2, 46588, None)
18/06/26 03:25:27 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.1.1:32861 with 912.3 MB RAM, BlockManagerId(1, 10.0.1.1, 32861, None)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.1.2:46588 (size: 6.8 KB, free: 912.3 MB)
18/06/26 03:25:27 INFO memory.MemoryStore: Block broadcast_43 stored as values in memory (estimated size 83.1 KB, free 329.9 MB)
18/06/26 03:25:27 INFO memory.MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 32.9 KB, free 329.8 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.1.2:46588 (size: 3.8 KB, free: 912.3 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on dc1master-lan1:32913 (size: 32.9 KB, free: 397.9 MB)
18/06/26 03:25:27 INFO spark.SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.1.1:32861 (size: 6.8 KB, free: 912.3 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.1.2:46588 (size: 6.1 KB, free: 912.3 MB)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[74] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: Adding task set 12.2 with 5 tasks
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 8
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 8
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.0.1.2:46588 (size: 7.1 KB, free: 912.3 MB)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.2 (TID 91, 10.0.1.1, executor 1, partition 0, ANY, 7909 bytes)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.1.2:46588 (size: 24.0 KB, free: 912.3 MB)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 12.2 (TID 92, 10.0.1.2, executor 0, partition 1, ANY, 7909 bytes)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.1.1:32861 (size: 3.8 KB, free: 912.3 MB)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 12.2 (TID 93, 10.0.1.1, executor 1, partition 2, ANY, 7909 bytes)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.0.1.1:32861 (size: 7.1 KB, free: 912.3 MB)
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 12.2 (TID 94, 10.0.1.2, executor 0, partition 3, ANY, 7909 bytes)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:27 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 12.2 (TID 95, 10.0.1.1, executor 1, partition 4, ANY, 7909 bytes)
18/06/26 03:25:27 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 5
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.1.1:32861 (size: 6.1 KB, free: 912.3 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.1.2:46588 (size: 546.0 B, free: 912.3 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 912.2 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.1.1:32861 (size: 24.0 KB, free: 912.3 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.1.2:46588 (size: 24.9 KB, free: 912.2 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.2:46588 (size: 24.9 KB, free: 912.2 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.0.1.2:46588 (size: 33.4 KB, free: 912.1 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.1.2:46588 (size: 3.4 MB, free: 908.7 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 908.7 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.1.2:46588 (size: 24.8 KB, free: 908.7 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.1.2:46588 (size: 60.1 KB, free: 908.6 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.1.1:32861 (size: 546.0 B, free: 912.3 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.0.1.2:46588 (size: 32.9 KB, free: 908.6 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.0.1.1:32861 (size: 33.4 KB, free: 912.2 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.1.2:46588 (size: 25.1 KB, free: 908.6 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 912.2 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.1.2:46588 (size: 25.1 KB, free: 908.5 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.1.1:32861 (size: 24.9 KB, free: 912.2 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_25_piece1 in memory on 10.0.1.2:46588 (size: 2.9 MB, free: 905.6 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.1.2:46588 (size: 5.9 KB, free: 905.6 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 905.6 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.1.2:46588 (size: 25.1 KB, free: 905.6 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.1.2:46588 (size: 25.2 KB, free: 905.6 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.1.2:46588 (size: 166.0 KB, free: 905.4 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.1:32861 (size: 24.9 KB, free: 912.1 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.1.2:46588 (size: 713.0 B, free: 905.4 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.1.2:46588 (size: 32.1 KB, free: 905.4 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.1.2:46588 (size: 6.0 KB, free: 905.4 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.1.1:32861 (size: 3.4 MB, free: 908.7 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.1.2:46588 (size: 6.1 KB, free: 905.4 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 908.7 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.0.1.1:32861 (size: 32.9 KB, free: 908.7 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.1.2:46588 (size: 6.2 KB, free: 905.4 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.1.1:32861 (size: 24.8 KB, free: 908.6 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.1.2:46588 (size: 4.0 MB, free: 901.4 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.1.2:46588 (size: 25.2 KB, free: 901.3 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.1.1:32861 (size: 60.1 KB, free: 908.6 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.1.2:46588 (size: 575.0 B, free: 901.3 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.1.2:46588 (size: 6.0 KB, free: 901.3 MB)
18/06/26 03:25:27 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.1.2:46588 (size: 25.0 KB, free: 901.3 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 908.6 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 908.5 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_25_piece1 in memory on 10.0.1.1:32861 (size: 2.9 MB, free: 905.6 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 905.6 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.1.1:32861 (size: 5.9 KB, free: 905.6 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 905.6 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.1.1:32861 (size: 25.2 KB, free: 905.6 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.1.1:32861 (size: 166.0 KB, free: 905.4 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.1.1:32861 (size: 713.0 B, free: 905.4 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.1.1:32861 (size: 32.1 KB, free: 905.4 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.1.1:32861 (size: 6.0 KB, free: 905.4 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.1.1:32861 (size: 6.1 KB, free: 905.4 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.1.1:32861 (size: 6.2 KB, free: 905.4 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.1.1:32861 (size: 4.0 MB, free: 901.4 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.1.1:32861 (size: 25.2 KB, free: 901.3 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.1.1:32861 (size: 575.0 B, free: 901.3 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.1.1:32861 (size: 6.0 KB, free: 901.3 MB)
18/06/26 03:25:28 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 901.3 MB)
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:28 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 11.2 (TID 90) in 663 ms on 10.0.1.1 (executor 1) (1/3)
18/06/26 03:25:28 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:28 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/3a/shuffle_4_2_0.data
18/06/26 03:25:28 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_4_2_0.index
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:28 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.2 (TID 80) in 778 ms on 10.0.1.2 (executor 0) (1/2)
18/06/26 03:25:28 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:28 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:25:28 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:28 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 8.2 (TID 81) in 927 ms on 10.0.1.1 (executor 1) (2/2)
18/06/26 03:25:28 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 8.2, whose tasks have all completed, from pool 
18/06/26 03:25:28 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:28 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_1_1_0.data
18/06/26 03:25:28 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_1_1_0.index
18/06/26 03:25:28 INFO scheduler.DAGScheduler: ShuffleMapStage 8 (processCmd at CliDriver.java:376) finished in 0.932 s
18/06/26 03:25:28 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:28 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 12, ShuffleMapStage 9, ShuffleMapStage 11)
18/06/26 03:25:28 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:25:28 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:29 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 12.2 (TID 95) in 1142 ms on 10.0.1.1 (executor 1) (1/5)
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/1b/shuffle_3_4_0.data
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/37/shuffle_3_4_0.index
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:29 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 11.2 (TID 89) in 1972 ms on 10.0.1.2 (executor 0) (2/3)
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/27/shuffle_4_1_0.data
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_4_1_0.index
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:29 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 12.2 (TID 92) in 1972 ms on 10.0.1.2 (executor 0) (2/5)
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/08/shuffle_3_1_0.data
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_3_1_0.index
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:29 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 12.2 (TID 94) in 2025 ms on 10.0.1.2 (executor 0) (3/5)
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/06/shuffle_3_3_0.data
18/06/26 03:25:29 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_3_3_0.index
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:30 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.2 (TID 88) in 2218 ms on 10.0.1.1 (executor 1) (3/3)
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 11.2, whose tasks have all completed, from pool 
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_4_0_0.data
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_4_0_0.index
18/06/26 03:25:30 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (processCmd at CliDriver.java:376) finished in 2.225 s
18/06/26 03:25:30 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:30 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 12, ShuffleMapStage 9)
18/06/26 03:25:30 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:25:30 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:30 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 12.2 (TID 93) in 2251 ms on 10.0.1.1 (executor 1) (4/5)
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/19/shuffle_3_2_0.data
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/35/shuffle_3_2_0.index
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:30 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.2 (TID 91) in 2460 ms on 10.0.1.1 (executor 1) (5/5)
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 12.2, whose tasks have all completed, from pool 
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/17/shuffle_3_0_0.data
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0d/shuffle_3_0_0.index
18/06/26 03:25:30 INFO scheduler.DAGScheduler: ShuffleMapStage 12 (processCmd at CliDriver.java:376) finished in 2.468 s
18/06/26 03:25:30 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:30 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 9)
18/06/26 03:25:30 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:25:30 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:30 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 9.2 (TID 87) in 2849 ms on 10.0.1.2 (executor 0) (1/6)
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/27/shuffle_0_5_0.data
18/06/26 03:25:30 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_0_5_0.index
18/06/26 03:25:31 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:31 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:31 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:31 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:31 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:31 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:31 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:31 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:31 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 9.2 (TID 83) in 4085 ms on 10.0.1.2 (executor 0) (2/6)
18/06/26 03:25:31 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:31 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/15/shuffle_0_1_0.data
18/06/26 03:25:31 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_0_1_0.index
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:32 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 9.2 (TID 85) in 4088 ms on 10.0.1.2 (executor 0) (3/6)
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/29/shuffle_0_3_0.data
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_0_3_0.index
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:32 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.2 (TID 82) in 4444 ms on 10.0.1.1 (executor 1) (4/6)
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_0_0.data
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/30/shuffle_0_0_0.index
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:32 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 9.2 (TID 86) in 4465 ms on 10.0.1.1 (executor 1) (5/6)
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/38/shuffle_0_4_0.data
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0c/shuffle_0_4_0.index
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:32 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 9.2 (TID 84) in 4487 ms on 10.0.1.1 (executor 1) (6/6)
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 9.2, whose tasks have all completed, from pool 
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/36/shuffle_0_2_0.data
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_0_2_0.index
18/06/26 03:25:32 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (processCmd at CliDriver.java:376) finished in 4.491 s
18/06/26 03:25:32 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:32 INFO scheduler.DAGScheduler: running: Set()
18/06/26 03:25:32 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:25:32 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:32 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[66] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6712089
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6712089
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6740957
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6740957
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6713052
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6713052
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5650567
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5650567
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6784375
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6784375
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742882
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742882
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6714987
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6714987
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6704143
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6704143
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6707345
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6707345
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5647636
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5647636
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6769123
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6769123
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720557
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720557
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6709715
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6709715
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6710875
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6710875
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6748485
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6748485
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5651565
18/06/26 03:25:32 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5651565
18/06/26 03:25:32 INFO memory.MemoryStore: Block broadcast_44 stored as values in memory (estimated size 81.7 KB, free 329.8 MB)
18/06/26 03:25:32 INFO memory.MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 32.1 KB, free 329.7 MB)
18/06/26 03:25:32 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on dc1master-lan1:32913 (size: 32.1 KB, free: 397.9 MB)
18/06/26 03:25:32 INFO spark.SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:32 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[66] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: Adding task set 10.2 with 4 tasks
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:32 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.2 (TID 96, 10.0.1.2, executor 0, partition 0, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:32 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 10.2 (TID 97, 10.0.1.1, executor 1, partition 1, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:32 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 10.2 (TID 98, 10.0.1.2, executor 0, partition 2, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:32 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 10.2 (TID 99, 10.0.1.1, executor 1, partition 3, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 4
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:32 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:32 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.0.1.1:32861 (size: 32.1 KB, free: 901.3 MB)
18/06/26 03:25:32 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.0.1.2:46588 (size: 32.1 KB, free: 901.3 MB)
18/06/26 03:25:32 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:32 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:32 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:33 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:33 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:33 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:33 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:33 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.1.1:34004
18/06/26 03:25:33 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6796083
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6764532
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6784375
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6769123
18/06/26 03:25:33 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6738128
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6720833
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6742882
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6720557
18/06/26 03:25:33 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6742152
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6712089
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6714987
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6709715
18/06/26 03:25:33 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6723039
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6740957
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6704143
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6710875
18/06/26 03:25:33 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6711026
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6713052
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6707345
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 6748485
18/06/26 03:25:33 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 5655515
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 5650567
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 5647636
18/06/26 03:25:33 INFO scheduler.RawMapStatus: 5651565
18/06/26 03:25:33 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:33 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:33 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:33 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:33 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:33 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:33 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:34 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.1.1:34004
18/06/26 03:25:34 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:34 INFO scheduler.RawMapStatus: 1540980
18/06/26 03:25:34 INFO scheduler.RawMapStatus: 1524571
18/06/26 03:25:34 INFO scheduler.RawMapStatus: 1534743
18/06/26 03:25:34 INFO scheduler.RawMapStatus: 1527125
18/06/26 03:25:34 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:34 INFO scheduler.RawMapStatus: 1508900
18/06/26 03:25:34 INFO scheduler.RawMapStatus: 1525974
18/06/26 03:25:34 INFO scheduler.RawMapStatus: 1545036
18/06/26 03:25:34 INFO scheduler.RawMapStatus: 1520678
18/06/26 03:25:34 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:34 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 10.2 (TID 97, 10.0.1.1, executor 1): FetchFailed(BlockManagerId(1, 10.0.1.1, 32861, None), shuffleId=1, mapId=0, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)
	at org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedBufferedToRowWithNullFreeJoinKey(SortMergeJoinExec.scala:811)
	at org.apache.spark.sql.execution.joins.SortMergeJoinScanner.<init>(SortMergeJoinExec.scala:686)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec$$anonfun$doExecute$1.apply(SortMergeJoinExec.scala:213)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec$$anonfun$doExecute$1.apply(SortMergeJoinExec.scala:150)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 16 more

)
18/06/26 03:25:34 INFO scheduler.TaskSetManager: Task 1.0 in stage 10.2 (TID 97) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:34 INFO scheduler.DAGScheduler: Marking ShuffleMapStage 10 (processCmd at CliDriver.java:376) as failed due to a fetch failure from ShuffleMapStage 8 (processCmd at CliDriver.java:376)
18/06/26 03:25:34 INFO scheduler.DAGScheduler: ShuffleMapStage 10 (processCmd at CliDriver.java:376) failed in 2.042 s due to org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)
	at org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedBufferedToRowWithNullFreeJoinKey(SortMergeJoinExec.scala:811)
	at org.apache.spark.sql.execution.joins.SortMergeJoinScanner.<init>(SortMergeJoinExec.scala:686)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec$$anonfun$doExecute$1.apply(SortMergeJoinExec.scala:213)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec$$anonfun$doExecute$1.apply(SortMergeJoinExec.scala:150)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 16 more

18/06/26 03:25:34 INFO scheduler.DAGScheduler: Resubmitting ShuffleMapStage 8 (processCmd at CliDriver.java:376) and ShuffleMapStage 10 (processCmd at CliDriver.java:376) due to fetch failure
18/06/26 03:25:34 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 26)
18/06/26 03:25:34 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
18/06/26 03:25:34 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 10.0.1.1, 32861, None)
18/06/26 03:25:34 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor
18/06/26 03:25:34 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 1 (epoch 26)
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:34 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 10.2 (TID 99, 10.0.1.1, executor 1): FetchFailed(BlockManagerId(1, 10.0.1.1, 32861, None), shuffleId=1, mapId=0, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)
	at org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedBufferedToRowWithNullFreeJoinKey(SortMergeJoinExec.scala:811)
	at org.apache.spark.sql.execution.joins.SortMergeJoinScanner.<init>(SortMergeJoinExec.scala:686)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec$$anonfun$doExecute$1.apply(SortMergeJoinExec.scala:213)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec$$anonfun$doExecute$1.apply(SortMergeJoinExec.scala:150)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 16 more

)
18/06/26 03:25:34 INFO scheduler.TaskSetManager: Task 3.0 in stage 10.2 (TID 99) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:34 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 10.2 (TID 96, 10.0.1.2, executor 0): FetchFailed(BlockManagerId(1, 10.0.1.1, 7337, None), shuffleId=1, mapId=1, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_1_1_0.data, offset=0, length=1508900}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:547)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)
	at org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedBufferedToRowWithNullFreeJoinKey(SortMergeJoinExec.scala:811)
	at org.apache.spark.sql.execution.joins.SortMergeJoinScanner.<init>(SortMergeJoinExec.scala:686)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec$$anonfun$doExecute$1.apply(SortMergeJoinExec.scala:213)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec$$anonfun$doExecute$1.apply(SortMergeJoinExec.scala:150)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_1_1_0.data, offset=0, length=1508900}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:114)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:540)
	... 32 more
Caused by: java.io.FileNotFoundException: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_1_1_0.data (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:99)
	... 33 more

)
18/06/26 03:25:34 INFO scheduler.TaskSetManager: Task 0.0 in stage 10.2 (TID 96) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:34 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 10.2 (TID 98, 10.0.1.2, executor 0): FetchFailed(BlockManagerId(1, 10.0.1.1, 7337, None), shuffleId=1, mapId=1, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_1_1_0.data, offset=3034874, length=1545036}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:547)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)
	at org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedBufferedToRowWithNullFreeJoinKey(SortMergeJoinExec.scala:811)
	at org.apache.spark.sql.execution.joins.SortMergeJoinScanner.<init>(SortMergeJoinExec.scala:686)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec$$anonfun$doExecute$1.apply(SortMergeJoinExec.scala:213)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec$$anonfun$doExecute$1.apply(SortMergeJoinExec.scala:150)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_1_1_0.data, offset=3034874, length=1545036}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:114)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:540)
	... 32 more
Caused by: java.io.FileNotFoundException: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_1_1_0.data (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:99)
	... 33 more

)
18/06/26 03:25:34 INFO scheduler.TaskSetManager: Task 2.0 in stage 10.2 (TID 98) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 10.2, whose tasks have all completed, from pool 
18/06/26 03:25:34 INFO scheduler.DAGScheduler: Resubmitting failed stages
18/06/26 03:25:34 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[61] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:34 INFO memory.MemoryStore: Block broadcast_45 stored as values in memory (estimated size 13.7 KB, free 329.7 MB)
18/06/26 03:25:34 INFO memory.MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 6.8 KB, free 329.7 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on dc1master-lan1:32913 (size: 6.8 KB, free: 397.9 MB)
18/06/26 03:25:34 INFO spark.SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:34 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[61] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(1))
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: Adding task set 8.3 with 1 tasks
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:34 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[53] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:34 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.3 (TID 100, 10.0.1.2, executor 0, partition 1, ANY, 7909 bytes)
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 1
18/06/26 03:25:34 INFO memory.MemoryStore: Block broadcast_46 stored as values in memory (estimated size 15.0 KB, free 329.7 MB)
18/06/26 03:25:34 INFO memory.MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 7.1 KB, free 329.7 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on dc1master-lan1:32913 (size: 7.1 KB, free: 397.9 MB)
18/06/26 03:25:34 INFO spark.SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:34 INFO scheduler.DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[53] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 2, 4))
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: Adding task set 9.3 with 3 tasks
18/06/26 03:25:34 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 8
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:34 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.3 (TID 101, 10.0.1.2, executor 0, partition 0, ANY, 7907 bytes)
18/06/26 03:25:34 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:34 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 9.3 (TID 102, 10.0.1.1, executor 1, partition 2, ANY, 7907 bytes)
18/06/26 03:25:34 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:34 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 9.3 (TID 103, 10.0.1.2, executor 0, partition 4, ANY, 7907 bytes)
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 3
18/06/26 03:25:34 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 9
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.0.1.2:46588 (size: 6.8 KB, free: 901.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.0.1.2:46588 (size: 7.1 KB, free: 901.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.1.1:32861 with 912.3 MB RAM, BlockManagerId(1, 10.0.1.1, 32861, None)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.0.1.1:32861 (size: 32.9 KB, free: 912.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.1.1:32861 (size: 6.8 KB, free: 912.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.1.1:32861 (size: 3.8 KB, free: 912.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.1.1:32861 (size: 6.1 KB, free: 912.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.1.1:32861 (size: 24.0 KB, free: 912.2 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.1.1:32861 (size: 546.0 B, free: 912.2 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 912.2 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.0.1.1:32861 (size: 33.4 KB, free: 912.2 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.1.1:32861 (size: 24.9 KB, free: 912.1 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.1:32861 (size: 24.9 KB, free: 912.1 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.1.1:32861 (size: 3.4 MB, free: 908.7 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 908.7 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.1.1:32861 (size: 24.8 KB, free: 908.6 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.1.1:32861 (size: 60.1 KB, free: 908.6 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 908.6 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 908.5 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.0.1.1:32861 (size: 7.1 KB, free: 908.5 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_25_piece1 in memory on 10.0.1.1:32861 (size: 2.9 MB, free: 905.6 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 905.6 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.1.1:32861 (size: 5.9 KB, free: 905.6 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 905.6 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.1.1:32861 (size: 25.2 KB, free: 905.6 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.1.1:32861 (size: 166.0 KB, free: 905.4 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.1.1:32861 (size: 713.0 B, free: 905.4 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.1.1:32861 (size: 32.1 KB, free: 905.4 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.1.1:32861 (size: 6.0 KB, free: 905.4 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.0.1.1:32861 (size: 7.1 KB, free: 905.4 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.1.1:32861 (size: 6.1 KB, free: 905.4 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.1.1:32861 (size: 6.2 KB, free: 905.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.1.1:32861 (size: 4.0 MB, free: 901.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.1.1:32861 (size: 25.2 KB, free: 901.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.1.1:32861 (size: 575.0 B, free: 901.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.1.1:32861 (size: 6.0 KB, free: 901.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.0.1.1:32861 (size: 32.1 KB, free: 901.3 MB)
18/06/26 03:25:34 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 901.3 MB)
18/06/26 03:25:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:35 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.3 (TID 100) in 723 ms on 10.0.1.2 (executor 0) (1/1)
18/06/26 03:25:35 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 8.3, whose tasks have all completed, from pool 
18/06/26 03:25:35 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:35 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:25:35 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:25:35 INFO scheduler.DAGScheduler: ShuffleMapStage 8 (processCmd at CliDriver.java:376) finished in 0.727 s
18/06/26 03:25:35 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:35 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 9)
18/06/26 03:25:35 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:25:35 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:36 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:36 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:36 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:36 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:37 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 9.3 (TID 102) in 3005 ms on 10.0.1.1 (executor 1) (1/3)
18/06/26 03:25:37 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:37 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/36/shuffle_0_2_0.data
18/06/26 03:25:37 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/32/shuffle_0_2_0.index
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:38 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 9.3 (TID 103) in 3360 ms on 10.0.1.2 (executor 0) (2/3)
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/38/shuffle_0_4_0.data
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_0_4_0.index
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:38 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.3 (TID 101) in 3369 ms on 10.0.1.2 (executor 0) (3/3)
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 9.3, whose tasks have all completed, from pool 
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_0_0_0.data
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/30/shuffle_0_0_0.index
18/06/26 03:25:38 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (processCmd at CliDriver.java:376) finished in 3.373 s
18/06/26 03:25:38 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:38 INFO scheduler.DAGScheduler: running: Set()
18/06/26 03:25:38 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ShuffleMapStage 10, ResultStage 14)
18/06/26 03:25:38 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:38 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[66] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742152
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742152
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6723039
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6723039
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6711026
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6711026
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5655515
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5655515
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6712089
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6712089
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6740957
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6740957
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6713052
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6713052
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5650567
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5650567
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6784375
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6784375
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742882
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742882
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6714987
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6714987
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6704143
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6704143
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6707345
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6707345
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5647636
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5647636
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6769123
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6769123
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720557
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720557
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6709715
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6709715
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6710875
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6710875
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6748485
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6748485
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 5651565
18/06/26 03:25:38 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 5651565
18/06/26 03:25:38 INFO memory.MemoryStore: Block broadcast_47 stored as values in memory (estimated size 81.7 KB, free 329.6 MB)
18/06/26 03:25:38 INFO memory.MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 32.2 KB, free 329.6 MB)
18/06/26 03:25:38 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on dc1master-lan1:32913 (size: 32.2 KB, free: 397.8 MB)
18/06/26 03:25:38 INFO spark.SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:38 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[66] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: Adding task set 10.3 with 4 tasks
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:38 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.3 (TID 104, 10.0.1.2, executor 0, partition 0, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:38 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 10.3 (TID 105, 10.0.1.2, executor 0, partition 1, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:38 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 10.3 (TID 106, 10.0.1.2, executor 0, partition 2, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:38 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 10.3 (TID 107, 10.0.1.2, executor 0, partition 3, NODE_LOCAL, 8075 bytes)
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 10
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 4
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 9
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 8
18/06/26 03:25:38 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 1
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:38 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.0.1.2:46588 (size: 32.2 KB, free: 901.2 MB)
18/06/26 03:25:38 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:38 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:39 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.1.2:52552
18/06/26 03:25:39 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6796083
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6764532
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6784375
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6769123
18/06/26 03:25:39 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6738128
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6720833
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6742882
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6720557
18/06/26 03:25:39 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6742152
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6712089
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6714987
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6709715
18/06/26 03:25:39 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6723039
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6740957
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6704143
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6710875
18/06/26 03:25:39 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6711026
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6713052
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6707345
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 6748485
18/06/26 03:25:39 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 5655515
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 5650567
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 5647636
18/06/26 03:25:39 INFO scheduler.RawMapStatus: 5651565
18/06/26 03:25:39 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:39 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:39 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:40 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.1.2:52552
18/06/26 03:25:40 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:40 INFO scheduler.RawMapStatus: 1540980
18/06/26 03:25:40 INFO scheduler.RawMapStatus: 1524571
18/06/26 03:25:40 INFO scheduler.RawMapStatus: 1534743
18/06/26 03:25:40 INFO scheduler.RawMapStatus: 1527125
18/06/26 03:25:40 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:40 INFO scheduler.RawMapStatus: 1508900
18/06/26 03:25:40 INFO scheduler.RawMapStatus: 1525974
18/06/26 03:25:40 INFO scheduler.RawMapStatus: 1545036
18/06/26 03:25:40 INFO scheduler.RawMapStatus: 1520678
18/06/26 03:25:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:41 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:41 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:41 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:41 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 10.3 (TID 105) in 4295 ms on 10.0.1.2 (executor 0) (1/4)
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/29/shuffle_2_1_0.data
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_2_1_0.index
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 10.3 (TID 106) in 4397 ms on 10.0.1.2 (executor 0) (2/4)
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/38/shuffle_2_2_0.data
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_2_2_0.index
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 10.3 (TID 107) in 4412 ms on 10.0.1.2 (executor 0) (3/4)
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/27/shuffle_2_3_0.data
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_2_3_0.index
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.3 (TID 104) in 4453 ms on 10.0.1.2 (executor 0) (4/4)
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 10.3, whose tasks have all completed, from pool 
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_2_0_0.data
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_2_0_0.index
18/06/26 03:25:42 INFO scheduler.DAGScheduler: ShuffleMapStage 10 (processCmd at CliDriver.java:376) finished in 4.461 s
18/06/26 03:25:42 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:42 INFO scheduler.DAGScheduler: running: Set()
18/06/26 03:25:42 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ResultStage 14)
18/06/26 03:25:42 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:42 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[82] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:42 INFO memory.MemoryStore: Block broadcast_48 stored as values in memory (estimated size 84.6 KB, free 329.5 MB)
18/06/26 03:25:42 INFO memory.MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 33.4 KB, free 329.5 MB)
18/06/26 03:25:42 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on dc1master-lan1:32913 (size: 33.4 KB, free: 397.8 MB)
18/06/26 03:25:42 INFO spark.SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:42 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[82] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 2))
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: Adding task set 11.3 with 2 tasks
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:42 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[74] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.3 (TID 108, 10.0.1.2, executor 0, partition 0, ANY, 7905 bytes)
18/06/26 03:25:42 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 11.3 (TID 109, 10.0.1.1, executor 1, partition 2, ANY, 7905 bytes)
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 03:25:42 INFO memory.MemoryStore: Block broadcast_49 stored as values in memory (estimated size 83.1 KB, free 329.4 MB)
18/06/26 03:25:42 INFO memory.MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 32.9 KB, free 329.3 MB)
18/06/26 03:25:42 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on dc1master-lan1:32913 (size: 32.9 KB, free: 397.8 MB)
18/06/26 03:25:42 INFO spark.SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:42 INFO scheduler.DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[74] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 2, 4))
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: Adding task set 12.3 with 3 tasks
18/06/26 03:25:42 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:25:42 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.3 (TID 110, 10.0.1.2, executor 0, partition 0, ANY, 7909 bytes)
18/06/26 03:25:42 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:42 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 12.3 (TID 111, 10.0.1.1, executor 1, partition 2, ANY, 7909 bytes)
18/06/26 03:25:42 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:42 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 12.3 (TID 112, 10.0.1.2, executor 0, partition 4, ANY, 7909 bytes)
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:42 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 3
18/06/26 03:25:42 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.0.1.2:46588 (size: 33.4 KB, free: 901.2 MB)
18/06/26 03:25:42 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.0.1.2:46588 (size: 32.9 KB, free: 901.2 MB)
18/06/26 03:25:42 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.0.1.1:32861 (size: 33.4 KB, free: 901.2 MB)
18/06/26 03:25:42 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.0.1.1:32861 (size: 32.9 KB, free: 901.2 MB)
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:42 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 11.3 (TID 109) in 407 ms on 10.0.1.1 (executor 1) (1/2)
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/3a/shuffle_4_2_0.data
18/06/26 03:25:42 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/0a/shuffle_4_2_0.index
18/06/26 03:25:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:43 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 12.3 (TID 112) in 807 ms on 10.0.1.2 (executor 0) (1/3)
18/06/26 03:25:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/1b/shuffle_3_4_0.data
18/06/26 03:25:43 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/37/shuffle_3_4_0.index
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 12.3 (TID 111) in 1750 ms on 10.0.1.1 (executor 1) (2/3)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/19/shuffle_3_2_0.data
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/35/shuffle_3_2_0.index
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.3 (TID 108) in 1800 ms on 10.0.1.2 (executor 0) (2/2)
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 11.3, whose tasks have all completed, from pool 
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/38/shuffle_4_0_0.data
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_4_0_0.index
18/06/26 03:25:44 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (processCmd at CliDriver.java:376) finished in 1.808 s
18/06/26 03:25:44 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:44 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 12)
18/06/26 03:25:44 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ResultStage 14)
18/06/26 03:25:44 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.3 (TID 110) in 1846 ms on 10.0.1.2 (executor 0) (3/3)
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 12.3, whose tasks have all completed, from pool 
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/17/shuffle_3_0_0.data
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0d/shuffle_3_0_0.index
18/06/26 03:25:44 INFO scheduler.DAGScheduler: ShuffleMapStage 12 (processCmd at CliDriver.java:376) finished in 1.854 s
18/06/26 03:25:44 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:44 INFO scheduler.DAGScheduler: running: Set()
18/06/26 03:25:44 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ResultStage 14)
18/06/26 03:25:44 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:44 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[87] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 294
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 294
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 285
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 285
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 286
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 286
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 157
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 157
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 165
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 165
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 160
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 160
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 95
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 95
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 267
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 267
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 157
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 157
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 149
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 149
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 197
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 197
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 184
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 184
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 91
18/06/26 03:25:44 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 91
18/06/26 03:25:44 INFO memory.MemoryStore: Block broadcast_50 stored as values in memory (estimated size 155.4 KB, free 329.2 MB)
18/06/26 03:25:44 INFO memory.MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 60.2 KB, free 329.1 MB)
18/06/26 03:25:44 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on dc1master-lan1:32913 (size: 60.2 KB, free: 397.7 MB)
18/06/26 03:25:44 INFO spark.SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:44 INFO scheduler.DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[87] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: Adding task set 13.2 with 12 tasks
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 13.2 (TID 113, 10.0.1.1, executor 1, partition 8, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.2 (TID 114, 10.0.1.2, executor 0, partition 0, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 13.2 (TID 115, 10.0.1.1, executor 1, partition 9, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 13.2 (TID 116, 10.0.1.2, executor 0, partition 1, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 13.2 (TID 117, 10.0.1.1, executor 1, partition 10, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 13.2 (TID 118, 10.0.1.2, executor 0, partition 2, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 13.2 (TID 119, 10.0.1.1, executor 1, partition 11, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 13.2 (TID 120, 10.0.1.2, executor 0, partition 3, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 13.2 (TID 121, 10.0.1.2, executor 0, partition 4, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 13.2 (TID 122, 10.0.1.2, executor 0, partition 5, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 13.2 (TID 123, 10.0.1.2, executor 0, partition 6, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 13.2 (TID 124, 10.0.1.2, executor 0, partition 7, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 5
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 5
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 5
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 6
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 6
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 6
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 7
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 7
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:44 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 7
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:44 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.0.1.1:32861 (size: 60.2 KB, free: 901.1 MB)
18/06/26 03:25:44 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.0.1.2:46588 (size: 60.2 KB, free: 901.1 MB)
18/06/26 03:25:44 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 4 to 10.0.1.1:34004
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 4 to 10.0.1.1:34004
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:44 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 2 to 10.0.1.2:52552
18/06/26 03:25:44 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 3 to 10.0.1.2:52552
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 2 to 10.0.1.2:52552
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 3 to 10.0.1.2:52552
18/06/26 03:25:44 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.1.1:34004
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 283
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 164
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 194
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:45 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.1.2:52552
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 283
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 157
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 197
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 267
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 149
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 184
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 91
18/06/26 03:25:45 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.1.2:52552
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 290
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 162
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 294
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 157
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 2338
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 2675
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 2405
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 2382
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 285
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 165
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 286
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 160
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 95
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.RawMapStatus: 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 WARN scheduler.TaskSetManager: Lost task 11.0 in stage 13.2 (TID 119, 10.0.1.1, executor 1): FetchFailed(BlockManagerId(1, 10.0.1.1, 32861, None), shuffleId=4, mapId=0, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_4_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage24.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage24.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_4_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Task 11.0 in stage 13.2 (TID 119) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:45 INFO scheduler.DAGScheduler: Marking ShuffleMapStage 13 (processCmd at CliDriver.java:376) as failed due to a fetch failure from ShuffleMapStage 11 (processCmd at CliDriver.java:376)
18/06/26 03:25:45 INFO scheduler.DAGScheduler: ShuffleMapStage 13 (processCmd at CliDriver.java:376) failed in 1.045 s due to org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_4_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage24.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage24.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_4_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

18/06/26 03:25:45 INFO scheduler.DAGScheduler: Resubmitting ShuffleMapStage 11 (processCmd at CliDriver.java:376) and ShuffleMapStage 13 (processCmd at CliDriver.java:376) due to fetch failure
18/06/26 03:25:45 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 36)
18/06/26 03:25:45 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
18/06/26 03:25:45 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 10.0.1.1, 32861, None)
18/06/26 03:25:45 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor
18/06/26 03:25:45 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 1 (epoch 36)
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 13.2 (TID 118) in 1034 ms on 10.0.1.2 (executor 0) (2/12)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/1b/shuffle_5_2_0.data
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/37/shuffle_5_2_0.index
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 WARN scheduler.TaskSetManager: Lost task 8.0 in stage 13.2 (TID 113, 10.0.1.1, executor 1): FetchFailed(BlockManagerId(1, 10.0.1.1, 32861, None), shuffleId=4, mapId=0, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_4_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage24.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage24.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_4_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Task 8.0 in stage 13.2 (TID 113) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:45 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 13.2 (TID 115, 10.0.1.1, executor 1): FetchFailed(BlockManagerId(1, 10.0.1.1, 32861, None), shuffleId=4, mapId=0, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_4_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage24.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage24.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_4_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Task 9.0 in stage 13.2 (TID 115) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 WARN scheduler.TaskSetManager: Lost task 10.0 in stage 13.2 (TID 117, 10.0.1.1, executor 1): FetchFailed(BlockManagerId(1, 10.0.1.1, 32861, None), shuffleId=4, mapId=0, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_4_0_0.index
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:652)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:583)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage24.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage24.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage25.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:618)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.file.NoSuchFileException: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0c/shuffle_4_0_0.index
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockDataNew(IndexShuffleBlockResolver.scala:241)
	at org.apache.spark.storage.BlockManager.getBlockDataNew(BlockManager.scala:396)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocksNew(ShuffleBlockFetcherIterator.scala:395)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:443)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:162)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:58)
	at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	... 7 more

)
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Task 10.0 in stage 13.2 (TID 117) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 13.2 (TID 122) in 1046 ms on 10.0.1.2 (executor 0) (6/12)
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/3e/shuffle_5_5_0.data
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/3a/shuffle_5_5_0.index
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 13.2 (TID 116) in 1048 ms on 10.0.1.2 (executor 0) (7/12)
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/06/shuffle_5_1_0.data
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_5_1_0.index
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.2 (TID 114) in 1048 ms on 10.0.1.2 (executor 0) (8/12)
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/19/shuffle_5_0_0.data
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/35/shuffle_5_0_0.index
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 13.2 (TID 124) in 1047 ms on 10.0.1.2 (executor 0) (9/12)
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 13.2 (TID 121) in 1048 ms on 10.0.1.2 (executor 0) (10/12)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/00/shuffle_5_7_0.data
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/3c/shuffle_5_7_0.index
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 13.2 (TID 120) in 1048 ms on 10.0.1.2 (executor 0) (11/12)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/1d/shuffle_5_4_0.data
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/39/shuffle_5_4_0.index
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/04/shuffle_5_3_0.data
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/08/shuffle_5_3_0.index
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 13.2 (TID 123) in 1053 ms on 10.0.1.2 (executor 0) (12/12)
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 13.2, whose tasks have all completed, from pool 
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/21/shuffle_5_6_0.data
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/05/shuffle_5_6_0.index
18/06/26 03:25:45 INFO scheduler.DAGScheduler: Resubmitting failed stages
18/06/26 03:25:45 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[82] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:45 INFO memory.MemoryStore: Block broadcast_51 stored as values in memory (estimated size 84.6 KB, free 329.1 MB)
18/06/26 03:25:45 INFO memory.MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 33.4 KB, free 329.0 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on dc1master-lan1:32913 (size: 33.4 KB, free: 397.7 MB)
18/06/26 03:25:45 INFO spark.SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:45 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[82] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(2))
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: Adding task set 11.4 with 1 tasks
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[74] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.4 (TID 125, 10.0.1.2, executor 0, partition 2, ANY, 7905 bytes)
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 1
18/06/26 03:25:45 INFO memory.MemoryStore: Block broadcast_52 stored as values in memory (estimated size 83.1 KB, free 328.9 MB)
18/06/26 03:25:45 INFO memory.MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 32.9 KB, free 328.9 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on dc1master-lan1:32913 (size: 32.9 KB, free: 397.6 MB)
18/06/26 03:25:45 INFO spark.SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.0.1.2:46588 (size: 33.4 KB, free: 901.1 MB)
18/06/26 03:25:45 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[74] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(2))
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: Adding task set 12.4 with 1 tasks
18/06/26 03:25:45 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 11
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.4 (TID 126, 10.0.1.1, executor 1, partition 2, ANY, 7909 bytes)
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 1
18/06/26 03:25:45 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 12
18/06/26 03:25:45 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.1.1:32861 with 912.3 MB RAM, BlockManagerId(1, 10.0.1.1, 32861, None)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.0.1.1:32861 (size: 32.9 KB, free: 912.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.1.1:32861 (size: 6.8 KB, free: 912.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.1.1:32861 (size: 3.8 KB, free: 912.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.1.1:32861 (size: 6.1 KB, free: 912.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.1.1:32861 (size: 24.0 KB, free: 912.2 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.1.1:32861 (size: 546.0 B, free: 912.2 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 912.2 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.0.1.1:32861 (size: 33.4 KB, free: 912.2 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.1.1:32861 (size: 24.9 KB, free: 912.1 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.0.1.1:32861 (size: 32.9 KB, free: 912.1 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.1:32861 (size: 24.9 KB, free: 912.1 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.1.1:32861 (size: 3.4 MB, free: 908.7 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 908.6 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.1.1:32861 (size: 24.8 KB, free: 908.6 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.1.1:32861 (size: 60.1 KB, free: 908.6 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 908.5 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 908.5 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.0.1.1:32861 (size: 7.1 KB, free: 908.5 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_25_piece1 in memory on 10.0.1.1:32861 (size: 2.9 MB, free: 905.6 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 905.6 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.1.1:32861 (size: 5.9 KB, free: 905.6 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 716
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 742
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 749
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 889
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 679
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 712
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 694
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 894
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 731
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 745
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 887
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 696
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 744
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 912
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.1.1:32861 (size: 25.1 KB, free: 905.6 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on dc1master-lan1:32913 in memory (size: 33.4 KB, free: 397.7 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.1.1:32861 (size: 25.2 KB, free: 905.5 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on 10.0.1.2:46588 in memory (size: 33.4 KB, free: 901.1 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.1.1:32861 (size: 166.0 KB, free: 905.4 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on 10.0.1.1:32861 (size: 32.9 KB, free: 905.3 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 882
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 732
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 871
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 692
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 682
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 913
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 688
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 785
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 671
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 681
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 750
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 886
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 734
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 701
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 766
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 746
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 685
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 693
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.1.1:32861 (size: 713.0 B, free: 905.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on dc1master-lan1:32913 in memory (size: 32.2 KB, free: 397.7 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on 10.0.1.2:46588 in memory (size: 32.2 KB, free: 901.1 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.1.1:32861 (size: 32.1 KB, free: 905.3 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 714
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 764
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 676
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 699
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 765
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.1.1:32861 (size: 6.0 KB, free: 905.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on dc1master-lan1:32913 in memory (size: 60.1 KB, free: 397.8 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on 10.0.1.2:46588 in memory (size: 60.1 KB, free: 901.2 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on 10.0.1.1:32861 in memory (size: 60.1 KB, free: 905.4 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 783
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 748
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 788
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 739
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 773
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 697
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 762
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 888
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 724
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.0.1.1:32861 (size: 7.1 KB, free: 905.4 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 729
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 790
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 675
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 877
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 733
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 753
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 674
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 884
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 767
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 902
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 910
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 715
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.1.1:32861 (size: 6.1 KB, free: 905.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on dc1master-lan1:32913 in memory (size: 32.9 KB, free: 397.8 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on 10.0.1.2:46588 in memory (size: 32.9 KB, free: 901.2 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.1.1:32861 (size: 6.2 KB, free: 905.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on 10.0.1.1:32861 in memory (size: 32.9 KB, free: 905.4 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.1.1:32861 (size: 4.0 MB, free: 901.4 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 779
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 736
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 897
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 757
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 708
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 770
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 867
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 791
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 896
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 870
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.0.1.1:32861 (size: 60.2 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on dc1master-lan1:32913 in memory (size: 33.4 KB, free: 397.8 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on 10.0.1.2:46588 in memory (size: 33.4 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.1.1:32861 (size: 25.2 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.1.1:32861 (size: 575.0 B, free: 901.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on 10.0.1.1:32861 in memory (size: 33.4 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.1.1:32861 (size: 6.0 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 727
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 698
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 758
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 702
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 900
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 885
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 774
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 906
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 916
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.0.1.1:32861 (size: 32.1 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on dc1master-lan1:32913 in memory (size: 32.9 KB, free: 397.9 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on 10.0.1.2:46588 in memory (size: 32.9 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on 10.0.1.1:32861 in memory (size: 32.9 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.1.1:32861 (size: 25.0 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 705
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 899
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 909
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 721
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 709
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 738
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 717
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 678
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 879
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 772
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 893
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 751
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 759
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 704
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 718
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 740
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 672
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 725
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 726
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 761
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 769
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 876
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 789
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 878
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 892
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 667
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 901
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 754
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 703
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on dc1master-lan1:32913 in memory (size: 7.1 KB, free: 397.9 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on 10.0.1.2:46588 in memory (size: 7.1 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on 10.0.1.1:32861 in memory (size: 7.1 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 691
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 903
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on dc1master-lan1:32913 in memory (size: 6.8 KB, free: 397.9 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on 10.0.1.2:46588 in memory (size: 6.8 KB, free: 901.3 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 777
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 687
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 683
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 895
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 780
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 868
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 771
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 673
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on dc1master-lan1:32913 in memory (size: 60.2 KB, free: 397.9 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on 10.0.1.2:46588 in memory (size: 60.2 KB, free: 901.4 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on 10.0.1.1:32861 in memory (size: 60.2 KB, free: 901.4 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 873
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 898
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 728
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 722
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 907
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 880
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 787
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 904
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 730
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 700
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on dc1master-lan1:32913 in memory (size: 6.8 KB, free: 397.9 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on 10.0.1.2:46588 in memory (size: 6.8 KB, free: 901.4 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on 10.0.1.1:32861 in memory (size: 6.8 KB, free: 901.4 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 713
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 720
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 689
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on dc1master-lan1:32913 in memory (size: 7.1 KB, free: 397.9 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on 10.0.1.2:46588 in memory (size: 7.1 KB, free: 901.4 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on 10.0.1.1:32861 in memory (size: 7.1 KB, free: 901.4 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 760
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 883
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 723
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 684
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 690
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 735
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 680
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 710
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 763
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 775
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 891
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 890
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 711
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 914
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 881
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 911
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 768
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 677
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 707
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 737
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 668
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 872
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on dc1master-lan1:32913 in memory (size: 32.1 KB, free: 398.0 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on 10.0.1.2:46588 in memory (size: 32.1 KB, free: 901.4 MB)
18/06/26 03:25:45 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on 10.0.1.1:32861 in memory (size: 32.1 KB, free: 901.4 MB)
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 752
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 776
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 874
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 786
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 875
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 781
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 908
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 747
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 719
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 784
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 670
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 778
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 782
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 905
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 915
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 756
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 706
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 695
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 869
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 755
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 686
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 741
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 669
18/06/26 03:25:45 INFO spark.ContextCleaner: Cleaned accumulator 743
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:45 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.4 (TID 125) in 344 ms on 10.0.1.2 (executor 0) (1/1)
18/06/26 03:25:45 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 11.4, whose tasks have all completed, from pool 
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/3a/shuffle_4_2_0.data
18/06/26 03:25:45 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_4_2_0.index
18/06/26 03:25:45 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (processCmd at CliDriver.java:376) finished in 0.352 s
18/06/26 03:25:45 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:45 INFO scheduler.DAGScheduler: running: Set(ShuffleMapStage 12)
18/06/26 03:25:45 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ResultStage 14)
18/06/26 03:25:45 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:46 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:46 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:46 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:46 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:46 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6796083
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6796083
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6764532
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6764532
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6784375
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6784375
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6769123
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6769123
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6738128
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6738128
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720833
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720833
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6742882
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6742882
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 6720557
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 6720557
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$16$$anonfun$apply$19.apply(MapOutputTracker.scala:735)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$16$$anonfun$apply$19.apply(MapOutputTracker.scala:734)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$16.apply(MapOutputTracker.scala:734)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$16.apply(MapOutputTracker.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:733)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:25:46 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:25:46 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2, 2 -> 10.0.1.1, 3 -> 10.0.1.2)
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_2
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 3065551
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1534743
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 3034874
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1545036
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_2_redundant
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2_redundant
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:46 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:46 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:47 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.4 (TID 126) in 1776 ms on 10.0.1.1 (executor 1) (1/1)
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 12.4, whose tasks have all completed, from pool 
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/19/shuffle_3_2_0.data
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-565aeaf0-2e03-4879-877f-cb941ddc9b2e/blockmgr-c89dcd80-1dbb-46ff-b5b9-12def0100390/35/shuffle_3_2_0.index
18/06/26 03:25:47 INFO scheduler.DAGScheduler: ShuffleMapStage 12 (processCmd at CliDriver.java:376) finished in 1.784 s
18/06/26 03:25:47 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:47 INFO scheduler.DAGScheduler: running: Set()
18/06/26 03:25:47 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 13, ResultStage 14)
18/06/26 03:25:47 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:47 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[87] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 267
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 267
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 157
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 157
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 149
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 149
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 197
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 197
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 184
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 184
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 91
18/06/26 03:25:47 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 91
18/06/26 03:25:47 INFO memory.MemoryStore: Block broadcast_53 stored as values in memory (estimated size 155.4 KB, free 329.9 MB)
18/06/26 03:25:47 INFO memory.MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 60.1 KB, free 329.9 MB)
18/06/26 03:25:47 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on dc1master-lan1:32913 (size: 60.1 KB, free: 397.9 MB)
18/06/26 03:25:47 INFO spark.SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:47 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[87] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(8, 9, 10, 11))
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: Adding task set 13.3 with 4 tasks
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:47 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.3 (TID 127, 10.0.1.2, executor 0, partition 8, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:47 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 13.3 (TID 128, 10.0.1.2, executor 0, partition 9, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 8
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 9
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 13.3 (TID 129, 10.0.1.2, executor 0, partition 10, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 13.3 (TID 130, 10.0.1.2, executor 0, partition 11, NODE_LOCAL, 7856 bytes)
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 4
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 10
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 13
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 12
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 3
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 10
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 11
18/06/26 03:25:47 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 4
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 12
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 11
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:47 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on 10.0.1.2:46588 (size: 60.1 KB, free: 901.3 MB)
18/06/26 03:25:47 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 4 to 10.0.1.2:52552
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 4 to 10.0.1.2:52552
18/06/26 03:25:47 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:48 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.1.2:52552
18/06/26 03:25:48 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 283
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 164
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 194
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:48 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 283
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 157
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 197
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 94
18/06/26 03:25:48 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 267
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 149
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 184
18/06/26 03:25:48 INFO scheduler.RawMapStatus: 91
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:48 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 13.3 (TID 128) in 1119 ms on 10.0.1.2 (executor 0) (1/4)
18/06/26 03:25:48 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 13.3 (TID 130) in 1118 ms on 10.0.1.2 (executor 0) (2/4)
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/02/shuffle_5_9_0.data
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/3e/shuffle_5_9_0.index
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:48 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 13.3 (TID 129) in 1119 ms on 10.0.1.2 (executor 0) (3/4)
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/29/shuffle_5_11_0.data
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/3b/shuffle_5_11_0.index
18/06/26 03:25:48 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.3 (TID 127) in 1120 ms on 10.0.1.2 (executor 0) (4/4)
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 13.3, whose tasks have all completed, from pool 
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/38/shuffle_5_10_0.data
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/04/shuffle_5_10_0.index
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/1f/shuffle_5_8_0.data
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/03/shuffle_5_8_0.index
18/06/26 03:25:48 INFO scheduler.DAGScheduler: ShuffleMapStage 13 (processCmd at CliDriver.java:376) finished in 1.131 s
18/06/26 03:25:48 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 03:25:48 INFO scheduler.DAGScheduler: running: Set()
18/06/26 03:25:48 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 14)
18/06/26 03:25:48 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 03:25:48 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[91] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 682
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 682
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 896
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 896
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 795
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 795
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 612
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 612
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 127
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 127
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 166
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 166
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 692
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 692
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 880
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 880
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 695
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 695
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 806
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 806
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 206
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 206
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 109
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 109
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 110
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 110
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 110
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 110
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 747
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 747
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 658
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 658
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 620
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 620
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 529
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 529
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 192
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 192
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 297
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 297
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 80
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 80
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 161
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 161
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 80
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 80
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 907
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 907
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 942
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 942
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 994
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 994
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1115
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1115
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 256
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 256
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 222
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 222
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 129
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 129
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 129
18/06/26 03:25:48 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 129
18/06/26 03:25:48 INFO memory.MemoryStore: Block broadcast_54 stored as values in memory (estimated size 112.3 KB, free 329.8 MB)
18/06/26 03:25:48 INFO memory.MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 44.1 KB, free 329.7 MB)
18/06/26 03:25:48 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on dc1master-lan1:32913 (size: 44.1 KB, free: 397.9 MB)
18/06/26 03:25:48 INFO spark.SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1074
18/06/26 03:25:48 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 14 (MapPartitionsRDD[91] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: Adding task set 14.0 with 4 tasks
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 131, 10.0.1.2, executor 0, partition 0, NODE_LOCAL, 7758 bytes)
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 14
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 13
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 5
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:48 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 14.0 (TID 132, 10.0.1.2, executor 0, partition 1, NODE_LOCAL, 7758 bytes)
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 14
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 13
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 5
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:48 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 14.0 (TID 133, 10.0.1.2, executor 0, partition 2, NODE_LOCAL, 7758 bytes)
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 14
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 13
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 5
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:48 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 14.0 (TID 134, 10.0.1.2, executor 0, partition 3, NODE_LOCAL, 7758 bytes)
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 14
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 13
18/06/26 03:25:48 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 03:25:48 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 4
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 5
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.2
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 0
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626032428-0069
18/06/26 03:25:48 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on 10.0.1.2:46588 (size: 44.1 KB, free: 901.3 MB)
18/06/26 03:25:48 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:48 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:48 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:48 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:48 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:49 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:49 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:49 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:49 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:49 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:49 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:49 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:49 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:49 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:25:49 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:653)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:652)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:652)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:25:49 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:25:49 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.1, 2 -> 10.0.1.1, 3 -> 10.0.1.2)
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1540980
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1524571
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 3065551
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1534743
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1508900
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1525974
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 3034874
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1545036
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1_redundant
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1_redundant
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_2_redundant
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2_redundant
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:49 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:49 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:25:50 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:50 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:50 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:50 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:50 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:50 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:50 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:50 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:50 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:50 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:50 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:50 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:51 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:51 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:51 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:51 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:51 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:51 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:51 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:51 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:51 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:51 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:51 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:51 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:51 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:51 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:51 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:51 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:52 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:52 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:52 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:52 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:52 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:52 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:52 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:52 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:52 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:52 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:52 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:52 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:52 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:52 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:52 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:52 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:53 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:53 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:53 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:53 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:53 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:53 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:53 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:53 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:53 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:53 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:53 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:53 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:54 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:54 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:54 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:54 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:54 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:54 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:54 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:54 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:54 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:54 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:54 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:54 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:55 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:55 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:55 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:55 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:55 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:55 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:55 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:55 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:55 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:55 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:55 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:55 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:56 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:25:56 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:653)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:652)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:652)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:25:56 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:25:56 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.1, 2 -> 10.0.1.2, 3 -> 10.0.1.2)
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1540980
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1524571
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1508900
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1525974
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1_redundant
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1_redundant
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:56 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:25:56 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:56 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:56 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:56 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:56 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:56 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:56 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:56 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:56 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:57 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:57 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:57 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:57 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:57 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:57 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:57 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:57 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:57 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:57 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:57 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:57 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:57 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:57 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:57 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:57 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:58 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:58 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:58 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:58 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:58 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:58 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:58 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:58 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:58 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:58 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:58 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:58 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:58 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:58 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:58 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:58 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:59 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:25:59 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:653)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:652)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:652)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:25:59 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:25:59 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.1, 2 -> 10.0.1.2, 3 -> 10.0.1.1)
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1540980
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1524571
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3_redundant
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1508900
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1525974
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4600294
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1527125
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4579910
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1520678
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3_redundant
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1_redundant
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1_redundant
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:25:59 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:25:59 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:25:59 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:25:59 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:25:59 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:25:59 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:59 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:59 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:25:59 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:25:59 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:00 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:00 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:00 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:00 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:00 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:00 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:00 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:00 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:00 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:00 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:00 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:00 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:00 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:00 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:00 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:00 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:01 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:01 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:01 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:01 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:01 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:01 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:01 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:01 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:01 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:01 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:01 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:01 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:02 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:02 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:02 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:02 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:02 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:02 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:02 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:02 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:02 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:02 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:02 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:02 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:02 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:02 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:02 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:02 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:03 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:03 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:03 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:03 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:03 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:03 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:03 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:03 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:03 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:03 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:03 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:03 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:04 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:04 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:04 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:04 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:04 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:04 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:04 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:04 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:04 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:04 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:04 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:04 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:04 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:04 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:04 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:04 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:05 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:05 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:05 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:05 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:05 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 4
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 4
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 4
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 5
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 5
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 5
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 6
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 6
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 6
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 7
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 7
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 7
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:653)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:652)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:652)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:26:05 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:05 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.1, 2 -> 10.0.1.2, 3 -> 10.0.1.1)
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1540980
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1524571
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3_redundant
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1508900
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1525974
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4600294
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1527125
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4579910
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1520678
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3_redundant
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1_redundant
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1_redundant
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:05 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:26:05 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:05 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:05 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:05 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:05 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:06 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:06 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:06 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:06 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:06 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:06 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:06 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:06 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:06 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:06 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:06 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:06 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:06 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:06 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:06 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:06 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:07 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:07 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:07 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:07 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:07 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:07 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:07 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:07 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:07 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:07 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:07 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:07 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:08 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:08 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:08 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:08 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:08 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:08 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:08 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:08 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:08 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:08 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:08 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:08 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:08 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:08 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:08 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:08 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:09 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:09 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:09 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:09 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:09 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:09 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:09 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:09 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:09 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:09 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:09 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:09 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:09 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:09 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:09 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:09 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:11 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:11 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:11 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:11 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:11 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:26:11 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:653)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:652)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:652)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:26:11 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:11 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.1, 2 -> 10.0.1.2, 3 -> 10.0.1.1)
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1540980
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1524571
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3_redundant
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1508900
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1525974
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4600294
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1527125
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4579910
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1520678
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3_redundant
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1_redundant
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1_redundant
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:11 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:11 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:26:12 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:12 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:12 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:12 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:12 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:12 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:12 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:12 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:12 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:12 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:12 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:12 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:13 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:13 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:13 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:13 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:13 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:13 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:13 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:13 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:13 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:13 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:13 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:13 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:13 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:13 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:13 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:13 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:14 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:14 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:14 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:14 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:14 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:14 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:14 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:14 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:14 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:14 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:14 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:14 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:14 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:14 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:14 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:14 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:15 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:15 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:15 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:15 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:15 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:15 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:15 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:15 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:15 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:15 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:15 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:15 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:15 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:15 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:15 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:15 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:17 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:26:17 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:653)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:652)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:652)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:26:17 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:17 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.1, 2 -> 10.0.1.2, 3 -> 10.0.1.1)
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1540980
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1524571
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3_redundant
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1508900
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1525974
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4600294
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1527125
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4579910
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1520678
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3_redundant
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1_redundant
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1_redundant
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:17 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:17 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:26:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:18 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:18 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:18 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:18 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:18 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:18 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:18 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:18 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:18 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:18 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:18 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:18 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:19 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:19 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:19 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:19 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:19 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:19 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:19 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:19 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:19 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:19 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:19 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:19 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:19 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:19 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:19 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:19 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:20 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:20 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:20 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:20 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:20 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:20 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:20 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:20 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:20 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:20 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:20 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:20 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:21 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:21 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:21 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:21 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:21 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:21 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:21 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:21 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:21 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:21 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:21 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:21 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:22 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:22 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:22 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:22 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:22 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:22 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:22 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:22 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:22 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:22 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:22 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:22 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:23 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:23 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:23 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:23 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:23 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:23 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:23 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:23 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:23 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:26:23 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:653)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:652)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:652)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:26:23 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:23 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.1, 2 -> 10.0.1.2, 3 -> 10.0.1.1)
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1540980
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1524571
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3_redundant
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1508900
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1525974
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4600294
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1527125
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4579910
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1520678
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3_redundant
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1_redundant
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1_redundant
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:23 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:23 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:26:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:24 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:24 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:24 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:24 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:24 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:24 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:24 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:24 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:24 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:24 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:24 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:24 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:25 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:25 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:25 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:25 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:25 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:25 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:25 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:25 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:25 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:25 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:25 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:25 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:25 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:25 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:25 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:25 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:26 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:26 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:26 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:26 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:26 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:26 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:26 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:26 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:26 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:26 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:26 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:26 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:26 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:26 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:27 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:27 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:27 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:27 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:27 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:27 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:27 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:27 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:27 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:27 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:28 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:28 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:28 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:28 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:28 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:28 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:28 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:28 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:28 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:28 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:28 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:28 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:28 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:28 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:29 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:29 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:29 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:29 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:29 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:29 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:29 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:29 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:29 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:29 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:29 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:29 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:29 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:29 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:30 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:26:30 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:653)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:652)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:652)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:26:30 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:30 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.1, 2 -> 10.0.1.2, 3 -> 10.0.1.1)
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1540980
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1524571
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3_redundant
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 1508900
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1525974
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4600294
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1527125
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4579910
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1520678
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3_redundant
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_1_redundant
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1_redundant
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:30 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:26:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:30 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:30 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:30 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:30 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:30 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:30 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:30 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:31 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:31 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:31 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:31 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:31 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:31 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:31 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:31 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:31 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:31 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:31 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:31 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:31 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:31 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:31 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:31 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:32 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:32 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:32 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:32 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:32 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:32 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:32 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:32 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:32 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:32 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:32 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:32 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:32 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:32 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:33 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:33 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:33 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:33 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:33 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:33 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:33 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:33 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:33 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:33 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:33 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:33 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:33 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:33 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:33 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:33 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:34 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:34 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:34 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:34 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:34 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:34 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:34 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:34 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:34 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:34 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:34 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:34 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:34 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:34 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:35 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:35 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:35 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:35 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:35 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:35 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:35 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:35 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:35 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:35 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:35 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:35 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:35 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:35 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:36 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:26:36 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:653)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:652)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:652)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:26:36 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:36 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2, 2 -> 10.0.1.2, 3 -> 10.0.1.1)
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3_redundant
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4600294
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1527125
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4579910
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1520678
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3_redundant
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:36 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:26:36 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:36 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:36 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:36 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:36 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:36 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:36 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:36 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:36 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:37 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:37 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:37 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:37 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:37 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:37 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:37 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:37 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:37 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:37 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:37 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:37 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:37 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:37 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:38 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:38 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:38 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:38 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:38 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:38 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:38 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:38 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:38 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:38 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:38 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:38 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:38 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:38 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:39 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:39 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:39 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:26:39 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:653)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:652)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:652)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:26:39 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:39 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2, 2 -> 10.0.1.2, 3 -> 10.0.1.1)
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3_redundant
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0f/shuffle_1_0_0.index
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ filename: 0_3
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 0
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/2b/shuffle_1_0_0.data
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4600294
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1527125
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/0a/shuffle_1_1_0.data
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 4579910
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 1520678
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3_redundant
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-c44431ba-f9d5-449e-b62e-3f3929ee6c31/blockmgr-d2d6beef-84ce-4b2e-a7b7-1100cad25002/32/shuffle_1_1_0.index
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 03:26:39 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:26:39 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:39 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:39 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:39 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:39 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:40 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:40 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:40 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:40 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:40 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:40 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:40 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:40 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:40 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:40 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:40 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:40 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:40 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:40 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:41 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:41 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:41 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:41 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:41 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:41 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:41 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:41 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:41 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:41 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:41 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:41 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:41 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:41 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:41 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:41 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:42 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:42 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:42 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:653)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$5.apply(MapOutputTracker.scala:652)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:652)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 1
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 1
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2, 2 -> 10.0.1.2, 3 -> 10.0.1.2)
18/06/26 03:26:42 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:26:42 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1540980
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1524571
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1524571
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1534743
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1534743
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1527125
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1527125
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1508900
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1525974
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1525974
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1545036
18/06/26 03:26:42 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1545036
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1520678
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1520678
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 12228007
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:26:42 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 4
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 4
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 4
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 5
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 5
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 5
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 6
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 6
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 6
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 7
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 7
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 7
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 8
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 9
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 10
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2338
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2675
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2405
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 2382
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 290
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 162
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 4
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 11
18/06/26 03:26:42 ERROR spark.MapOutputTrackerMaster: TerraLoop.shuffleStatus reduceId isDefined.
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 283
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 194
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 94
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 4
java.lang.ArrayIndexOutOfBoundsException: 4
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.scheduler.RawMapStatus$$anonfun$getSizeForBlock$2.apply(MapStatus.scala:106)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.scheduler.RawMapStatus.logInfo(MapStatus.scala:79)
	at org.apache.spark.scheduler.RawMapStatus.getSizeForBlock(MapStatus.scala:106)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:684)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8$$anonfun$apply$8.apply(MapOutputTracker.scala:669)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:669)
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$submitShuffle$8.apply(MapOutputTracker.scala:668)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.MapOutputTrackerMaster.submitShuffle(MapOutputTracker.scala:668)
	at org.apache.spark.MapOutputTrackerMaster$TerraLoop.run(MapOutputTracker.scala:602)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 5
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 5
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 5
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 5
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 206
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 206
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 206
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 206
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 297
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 297
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 109
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 109
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 109
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 109
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 80
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 80
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 166
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 166
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 166
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 166
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 166
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 166
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 161
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 161
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 80
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 80
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 682
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 682
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 682
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 682
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 692
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 692
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 682
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 682
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 692
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 692
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 747
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 747
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 682
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 682
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 692
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 692
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 747
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 747
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 907
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 907
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 896
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 896
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 896
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 896
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 880
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 880
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 896
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 896
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 880
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 880
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 658
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 658
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 896
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 896
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 880
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 880
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 658
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 658
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 942
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 942
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 795
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 795
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 795
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 795
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 695
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 695
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 795
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 795
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 695
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 695
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 620
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 620
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 795
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 795
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 695
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 695
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 620
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 620
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 994
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 994
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 612
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 612
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 612
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 612
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 806
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 806
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 612
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 612
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 806
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 806
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 529
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 529
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 612
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 612
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 806
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 806
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 529
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 529
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1115
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1115
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 192
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 192
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 192
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 192
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 256
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 256
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 127
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 127
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 127
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 127
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 127
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 127
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 127
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 127
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 222
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 222
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 129
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 129
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 129
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 129
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626032428-0069
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 5
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(11 -> 10.0.1.2, 0 -> 10.0.1.2, 1 -> 10.0.1.2, 2 -> 10.0.1.2, 3 -> 10.0.1.2, 4 -> 10.0.1.2, 5 -> 10.0.1.2, 6 -> 10.0.1.2, 7 -> 10.0.1.2, 8 -> 10.0.1.2, 9 -> 10.0.1.2, 10 -> 10.0.1.2)
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.2, 1 -> 10.0.1.2, 2 -> 10.0.1.2, 3 -> 10.0.1.2)
18/06/26 03:26:42 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 03:26:42 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 206
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 206
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 297
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 297
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 109
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 109
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 80
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 80
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 166
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 166
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 161
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 161
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 110
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 80
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 80
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 682
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 682
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 692
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 692
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 747
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 747
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 907
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 907
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 896
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 896
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 880
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 880
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 658
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 658
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 942
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 942
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 795
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 795
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 695
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 695
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 620
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 620
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 994
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 994
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 612
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 612
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 806
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 806
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 529
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 529
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 1115
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 1115
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 192
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 192
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 256
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 256
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 127
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 127
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 222
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 222
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 164
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 129
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 129
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 128
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 129
18/06/26 03:26:42 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 129
18/06/26 03:26:42 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 15876
18/06/26 03:26:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:43 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:43 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:43 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:43 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:43 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:44 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.0.1.2:52552
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 0
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 0
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 206
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 297
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 128
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 0
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 109
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 80
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 0
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 166
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 110
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 161
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 128
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 0
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 110
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 80
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 682
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 692
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 747
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 907
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 896
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 880
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 658
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 942
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 795
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 695
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 620
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 994
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 612
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 806
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 529
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 1115
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 128
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 0
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 192
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 256
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 127
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 0
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 0
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 222
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 128
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 164
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 128
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 129
18/06/26 03:26:44 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 0
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 0
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 128
18/06/26 03:26:44 INFO scheduler.RawMapStatus: 129
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 03:26:44 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 14.0 (TID 133) in 56202 ms on 10.0.1.2 (executor 0) (1/4)
18/06/26 03:26:44 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 14.0 (TID 134) in 56202 ms on 10.0.1.2 (executor 0) (2/4)
18/06/26 03:26:44 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 131) in 56203 ms on 10.0.1.2 (executor 0) (3/4)
18/06/26 03:26:44 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 14.0 (TID 132) in 56204 ms on 10.0.1.2 (executor 0) (4/4)
18/06/26 03:26:44 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/06/26 03:26:44 INFO scheduler.DAGScheduler: ResultStage 14 (processCmd at CliDriver.java:376) finished in 56.225 s
18/06/26 03:26:44 INFO scheduler.DAGScheduler: Job 8 finished: processCmd at CliDriver.java:376, took 125.602259 s
Time taken: 135.145 seconds, Fetched 100 row(s)
18/06/26 03:26:44 INFO thriftserver.SparkSQLCLIDriver: Time taken: 135.145 seconds, Fetched 100 row(s)
18/06/26 03:26:44 INFO server.AbstractConnector: Stopped Spark@64dc86c6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
18/06/26 03:26:44 INFO ui.SparkUI: Stopped Spark web UI at http://dc1master-lan1:4040
18/06/26 03:26:45 INFO cluster.StandaloneSchedulerBackend: Shutting down all executors
18/06/26 03:26:45 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
18/06/26 03:26:45 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/06/26 03:26:45 INFO memory.MemoryStore: MemoryStore cleared
18/06/26 03:26:45 INFO storage.BlockManager: BlockManager stopped
18/06/26 03:26:45 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
18/06/26 03:26:45 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/06/26 03:26:45 INFO spark.SparkContext: Successfully stopped SparkContext
18/06/26 03:26:45 INFO util.ShutdownHookManager: Shutdown hook called
18/06/26 03:26:45 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-f2e8484f-8855-4eed-96f2-d1252731f63f
18/06/26 03:26:45 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-6b91e090-666d-4dde-be49-621309cbf447
