2018-06-28 20:20:38 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-06-28 20:20:38 INFO  HiveMetaStore:589 - 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-06-28 20:20:38 INFO  ObjectStore:289 - ObjectStore, initialize called
2018-06-28 20:20:38 INFO  Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-06-28 20:20:38 INFO  Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-06-28 20:20:40 INFO  ObjectStore:370 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-06-28 20:20:40 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
2018-06-28 20:20:40 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
2018-06-28 20:20:40 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
2018-06-28 20:20:40 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
2018-06-28 20:20:40 INFO  Query:77 - Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
2018-06-28 20:20:40 INFO  MetaStoreDirectSql:139 - Using direct SQL, underlying DB is DERBY
2018-06-28 20:20:40 INFO  ObjectStore:272 - Initialized ObjectStore
2018-06-28 20:20:41 INFO  HiveMetaStore:663 - Added admin role in metastore
2018-06-28 20:20:41 INFO  HiveMetaStore:672 - Added public role in metastore
2018-06-28 20:20:41 INFO  HiveMetaStore:712 - No user is added in admin role, since config is empty
2018-06-28 20:20:41 INFO  HiveMetaStore:746 - 0: get_all_databases
2018-06-28 20:20:41 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_all_databases	
2018-06-28 20:20:41 INFO  HiveMetaStore:746 - 0: get_functions: db=default pat=*
2018-06-28 20:20:41 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
2018-06-28 20:20:41 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
2018-06-28 20:20:41 INFO  HiveMetaStore:746 - 0: get_functions: db=tpcds_text_10 pat=*
2018-06-28 20:20:41 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpcds_text_10 pat=*	
2018-06-28 20:20:41 INFO  HiveMetaStore:746 - 0: get_functions: db=tpcds_text_20 pat=*
2018-06-28 20:20:41 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpcds_text_20 pat=*	
2018-06-28 20:20:41 INFO  HiveMetaStore:746 - 0: get_functions: db=tpch_flat_orc_10 pat=*
2018-06-28 20:20:41 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpch_flat_orc_10 pat=*	
2018-06-28 20:20:41 INFO  HiveMetaStore:746 - 0: get_functions: db=tpch_flat_orc_20 pat=*
2018-06-28 20:20:41 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpch_flat_orc_20 pat=*	
2018-06-28 20:20:41 INFO  HiveMetaStore:746 - 0: get_functions: db=tpch_text_10 pat=*
2018-06-28 20:20:41 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpch_text_10 pat=*	
2018-06-28 20:20:41 INFO  HiveMetaStore:746 - 0: get_functions: db=tpch_text_20 pat=*
2018-06-28 20:20:41 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpch_text_20 pat=*	
2018-06-28 20:20:41 INFO  SessionState:641 - Created local directory: /tmp/60639419-a2ed-43e7-9f8f-53fe9a38a24e_resources
2018-06-28 20:20:41 INFO  SessionState:641 - Created HDFS directory: /tmp/hive/jimmyyou/60639419-a2ed-43e7-9f8f-53fe9a38a24e
2018-06-28 20:20:41 INFO  SessionState:641 - Created local directory: /tmp/jimmyyou/60639419-a2ed-43e7-9f8f-53fe9a38a24e
2018-06-28 20:20:41 INFO  SessionState:641 - Created HDFS directory: /tmp/hive/jimmyyou/60639419-a2ed-43e7-9f8f-53fe9a38a24e/_tmp_space.db
2018-06-28 20:20:41 INFO  SparkContext:54 - Running Spark version 2.3.1
2018-06-28 20:20:41 INFO  SparkContext:54 - Submitted application: SparkSQL::10.0.1.253
2018-06-28 20:20:41 INFO  SecurityManager:54 - Changing view acls to: jimmyyou
2018-06-28 20:20:41 INFO  SecurityManager:54 - Changing modify acls to: jimmyyou
2018-06-28 20:20:41 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-06-28 20:20:41 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-06-28 20:20:41 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jimmyyou); groups with view permissions: Set(); users  with modify permissions: Set(jimmyyou); groups with modify permissions: Set()
2018-06-28 20:20:41 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 38589.
2018-06-28 20:20:41 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-06-28 20:20:41 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-06-28 20:20:41 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-06-28 20:20:41 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-06-28 20:20:41 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-be34233c-82f0-4cc4-9d99-336d2855d80a
2018-06-28 20:20:41 INFO  MemoryStore:54 - MemoryStore started with capacity 2004.6 MB
2018-06-28 20:20:41 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-06-28 20:20:42 INFO  log:192 - Logging initialized @4523ms
2018-06-28 20:20:42 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-06-28 20:20:42 INFO  Server:414 - Started @4575ms
2018-06-28 20:20:42 INFO  AbstractConnector:278 - Started ServerConnector@2a1e034d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-06-28 20:20:42 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e6748ae{/jobs,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22f8adc2{/jobs/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69d103f0{/jobs/job,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74fb5b59{/jobs/job/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@130a6eb9{/stages,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@722531ab{/stages/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@8f57e4c{/stages/stage,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/stage/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e92c3b6{/stages/pool,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@207dd1b7{/storage,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baac4a7{/storage/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@23ad2d17{/storage/rdd,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bce4140{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@25f0c5e7{/environment,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5882b202{/environment/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@120df990{/executors,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b506ed0{/executors/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@282c4da0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f3e805{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18cf5c52{/static,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2450256f{/,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59918c8f{/api,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@71b97eeb{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2776fd8f{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://dc1master-lan1:4040
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://dc1master-lan1:7077...
2018-06-28 20:20:42 INFO  TransportClientFactory:267 - Successfully created connection to dc1master-lan1/10.0.1.253:7077 after 19 ms (0 ms spent in bootstraps)
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20180628202042-0119
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180628202042-0119/0 on worker-20180628164103-10.0.2.1-45032 (10.0.2.1:45032) with 8 core(s)
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180628202042-0119/0 on hostPort 10.0.2.1:45032 with 8 core(s), 4.0 GB RAM
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180628202042-0119/1 on worker-20180628164105-10.0.5.1-34262 (10.0.5.1:34262) with 8 core(s)
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180628202042-0119/1 on hostPort 10.0.5.1:34262 with 8 core(s), 4.0 GB RAM
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180628202042-0119/2 on worker-20180628164103-10.0.3.2-44865 (10.0.3.2:44865) with 8 core(s)
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180628202042-0119/2 on hostPort 10.0.3.2:44865 with 8 core(s), 4.0 GB RAM
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180628202042-0119/3 on worker-20180628164101-10.0.1.1-43445 (10.0.1.1:43445) with 8 core(s)
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180628202042-0119/3 on hostPort 10.0.1.1:43445 with 8 core(s), 4.0 GB RAM
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180628202042-0119/4 on worker-20180628164105-10.0.5.2-34633 (10.0.5.2:34633) with 8 core(s)
2018-06-28 20:20:42 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33589.
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180628202042-0119/4 on hostPort 10.0.5.2:34633 with 8 core(s), 4.0 GB RAM
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180628202042-0119/5 on worker-20180628164101-10.0.1.2-44652 (10.0.1.2:44652) with 8 core(s)
2018-06-28 20:20:42 INFO  NettyBlockTransferService:54 - Server created on dc1master-lan1:33589
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180628202042-0119/5 on hostPort 10.0.1.2:44652 with 8 core(s), 4.0 GB RAM
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180628202042-0119/6 on worker-20180628164103-10.0.3.1-36707 (10.0.3.1:36707) with 8 core(s)
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180628202042-0119/6 on hostPort 10.0.3.1:36707 with 8 core(s), 4.0 GB RAM
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180628202042-0119/7 on worker-20180628164103-10.0.4.1-44386 (10.0.4.1:44386) with 8 core(s)
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180628202042-0119/7 on hostPort 10.0.4.1:44386 with 8 core(s), 4.0 GB RAM
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180628202042-0119/8 on worker-20180628164103-10.0.2.2-43424 (10.0.2.2:43424) with 8 core(s)
2018-06-28 20:20:42 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180628202042-0119/8 on hostPort 10.0.2.2:43424 with 8 core(s), 4.0 GB RAM
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180628202042-0119/9 on worker-20180628164103-10.0.4.2-38139 (10.0.4.2:38139) with 8 core(s)
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180628202042-0119/9 on hostPort 10.0.4.2:38139 with 8 core(s), 4.0 GB RAM
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180628202042-0119/3 is now RUNNING
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180628202042-0119/5 is now RUNNING
2018-06-28 20:20:42 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, dc1master-lan1, 33589, None)
2018-06-28 20:20:42 INFO  BlockManagerMasterEndpoint:54 - Registering block manager dc1master-lan1:33589 with 2004.6 MB RAM, BlockManagerId(driver, dc1master-lan1, 33589, None)
2018-06-28 20:20:42 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, dc1master-lan1, 33589, None)
2018-06-28 20:20:42 INFO  BlockManager:54 - external shuffle service port = 7337
2018-06-28 20:20:42 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, dc1master-lan1, 33589, None)
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38732372{/metrics/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180628202042-0119/0 is now RUNNING
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180628202042-0119/8 is now RUNNING
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180628202042-0119/2 is now RUNNING
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180628202042-0119/6 is now RUNNING
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180628202042-0119/7 is now RUNNING
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180628202042-0119/9 is now RUNNING
2018-06-28 20:20:42 INFO  EventLoggingListener:54 - Logging events to hdfs://dc1master:9000/user/jimmyyou/spark-logs/app-20180628202042-0119
2018-06-28 20:20:42 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2018-06-28 20:20:42 INFO  SharedState:54 - loading hive config file: file:/users/jimmyyou/spark-2.3.1-bin-hadoop2.7/conf/hive-site.xml
2018-06-28 20:20:42 INFO  SharedState:54 - spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir ('/user/hive/warehouse').
2018-06-28 20:20:42 INFO  SharedState:54 - Warehouse path is '/user/hive/warehouse'.
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4eb63dc8{/SQL,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@402d6012{/SQL/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1573e8a5{/SQL/execution,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38022758{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@79d4ff58{/static/sql,null,AVAILABLE,@Spark}
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180628202042-0119/4 is now RUNNING
2018-06-28 20:20:42 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180628202042-0119/1 is now RUNNING
2018-06-28 20:20:42 INFO  HiveUtils:54 - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
2018-06-28 20:20:42 INFO  HiveClientImpl:54 - Warehouse location for Hive client (version 1.2.2) is /user/hive/warehouse
2018-06-28 20:20:42 INFO  HiveMetaStore:746 - 0: get_database: default
2018-06-28 20:20:42 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: default	
2018-06-28 20:20:43 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_database: global_temp
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: global_temp	
2018-06-28 20:20:43 WARN  ObjectStore:568 - Failed to get database global_temp, returning NoSuchObjectException
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store_sales
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store_sales	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=household_demographics
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=household_demographics	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=time_dim
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=time_dim	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store_sales
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store_sales	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=household_demographics
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=household_demographics	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=time_dim
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=time_dim	
2018-06-28 20:20:43 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.1.2:51014) with ID 5
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store_sales
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store_sales	
2018-06-28 20:20:43 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.1.1:47436) with ID 3
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=household_demographics
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=household_demographics	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=time_dim
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=time_dim	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store	
2018-06-28 20:20:43 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.1.2:40290 with 2004.6 MB RAM, BlockManagerId(5, 10.0.1.2, 40290, None)
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store_sales
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store_sales	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=household_demographics
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=household_demographics	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=time_dim
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=time_dim	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store	
2018-06-28 20:20:43 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.1.1:36138 with 2004.6 MB RAM, BlockManagerId(3, 10.0.1.1, 36138, None)
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store_sales
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store_sales	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=household_demographics
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=household_demographics	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=time_dim
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=time_dim	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store_sales
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store_sales	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=household_demographics
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=household_demographics	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=time_dim
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=time_dim	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store_sales
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store_sales	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=household_demographics
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=household_demographics	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=time_dim
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=time_dim	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store_sales
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store_sales	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=household_demographics
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=household_demographics	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=time_dim
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=time_dim	
2018-06-28 20:20:43 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=store
2018-06-28 20:20:43 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=store	
2018-06-28 20:20:44 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
2018-06-28 20:20:45 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.2:51736) with ID 8
2018-06-28 20:20:45 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.1:54266) with ID 0
2018-06-28 20:20:45 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.2.2:43048 with 2004.6 MB RAM, BlockManagerId(8, 10.0.2.2, 43048, None)
2018-06-28 20:20:45 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.2.1:39758 with 2004.6 MB RAM, BlockManagerId(0, 10.0.2.1, 39758, None)
2018-06-28 20:20:45 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.3.1:52720) with ID 6
2018-06-28 20:20:45 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.3.2:52402) with ID 2
2018-06-28 20:20:45 INFO  AbstractConnector:318 - Stopped Spark@2a1e034d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-06-28 20:20:45 INFO  SparkUI:54 - Stopped Spark web UI at http://dc1master-lan1:4040
2018-06-28 20:20:45 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.4.2:47330) with ID 9
2018-06-28 20:20:45 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.4.1:47372) with ID 7
2018-06-28 20:20:45 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.3.1:37929 with 2004.6 MB RAM, BlockManagerId(6, 10.0.3.1, 37929, None)
2018-06-28 20:20:45 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.3.2:43471 with 2004.6 MB RAM, BlockManagerId(2, 10.0.3.2, 43471, None)
2018-06-28 20:20:45 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.4.2:34062 with 2004.6 MB RAM, BlockManagerId(9, 10.0.4.2, 34062, None)
2018-06-28 20:20:45 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.4.1:34757 with 2004.6 MB RAM, BlockManagerId(7, 10.0.4.1, 34757, None)
2018-06-28 20:20:46 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.5.1:56468) with ID 1
2018-06-28 20:20:46 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.5.2:56642) with ID 4
2018-06-28 20:20:46 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.5.1:37146 with 2004.6 MB RAM, BlockManagerId(1, 10.0.5.1, 37146, None)
2018-06-28 20:20:47 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.5.2:32791 with 2004.6 MB RAM, BlockManagerId(4, 10.0.5.2, 32791, None)
2018-06-28 20:20:49 INFO  StandaloneSchedulerBackend:54 - Shutting down all executors
2018-06-28 20:20:49 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Asking each executor to shut down
2018-06-28 20:20:49 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-06-28 20:20:49 INFO  MemoryStore:54 - MemoryStore cleared
2018-06-28 20:20:49 INFO  BlockManager:54 - BlockManager stopped
2018-06-28 20:20:49 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-06-28 20:20:49 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-06-28 20:20:49 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-06-28 20:20:49 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-06-28 20:20:49 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-d79282b7-e63f-4452-86af-92d7b3adb600
2018-06-28 20:20:49 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-7f17c59d-dc01-4583-bf45-e5ef1efa59be
