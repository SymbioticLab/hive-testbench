2018-06-30 00:27:12 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-06-30 00:27:13 INFO  HiveMetaStore:589 - 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-06-30 00:27:13 INFO  ObjectStore:289 - ObjectStore, initialize called
2018-06-30 00:27:13 INFO  Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-06-30 00:27:13 INFO  Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-06-30 00:27:14 INFO  ObjectStore:370 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-06-30 00:27:15 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
2018-06-30 00:27:15 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
2018-06-30 00:27:15 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
2018-06-30 00:27:15 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
2018-06-30 00:27:15 INFO  Query:77 - Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
2018-06-30 00:27:15 INFO  MetaStoreDirectSql:139 - Using direct SQL, underlying DB is DERBY
2018-06-30 00:27:15 INFO  ObjectStore:272 - Initialized ObjectStore
2018-06-30 00:27:15 INFO  HiveMetaStore:663 - Added admin role in metastore
2018-06-30 00:27:15 INFO  HiveMetaStore:672 - Added public role in metastore
2018-06-30 00:27:15 INFO  HiveMetaStore:712 - No user is added in admin role, since config is empty
2018-06-30 00:27:15 INFO  HiveMetaStore:746 - 0: get_all_databases
2018-06-30 00:27:15 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_all_databases	
2018-06-30 00:27:15 INFO  HiveMetaStore:746 - 0: get_functions: db=default pat=*
2018-06-30 00:27:15 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
2018-06-30 00:27:15 INFO  Datastore:77 - The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
2018-06-30 00:27:15 INFO  HiveMetaStore:746 - 0: get_functions: db=tpcds_text_10 pat=*
2018-06-30 00:27:15 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpcds_text_10 pat=*	
2018-06-30 00:27:15 INFO  HiveMetaStore:746 - 0: get_functions: db=tpcds_text_20 pat=*
2018-06-30 00:27:15 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpcds_text_20 pat=*	
2018-06-30 00:27:15 INFO  HiveMetaStore:746 - 0: get_functions: db=tpch_flat_orc_10 pat=*
2018-06-30 00:27:15 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpch_flat_orc_10 pat=*	
2018-06-30 00:27:15 INFO  HiveMetaStore:746 - 0: get_functions: db=tpch_flat_orc_20 pat=*
2018-06-30 00:27:15 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpch_flat_orc_20 pat=*	
2018-06-30 00:27:15 INFO  HiveMetaStore:746 - 0: get_functions: db=tpch_text_10 pat=*
2018-06-30 00:27:15 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpch_text_10 pat=*	
2018-06-30 00:27:15 INFO  HiveMetaStore:746 - 0: get_functions: db=tpch_text_20 pat=*
2018-06-30 00:27:15 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_functions: db=tpch_text_20 pat=*	
2018-06-30 00:27:15 INFO  SessionState:641 - Created local directory: /tmp/748093a6-1409-48b5-b285-2e46c5c47586_resources
2018-06-30 00:27:15 INFO  SessionState:641 - Created HDFS directory: /tmp/hive/jimmyyou/748093a6-1409-48b5-b285-2e46c5c47586
2018-06-30 00:27:15 INFO  SessionState:641 - Created local directory: /tmp/jimmyyou/748093a6-1409-48b5-b285-2e46c5c47586
2018-06-30 00:27:15 INFO  SessionState:641 - Created HDFS directory: /tmp/hive/jimmyyou/748093a6-1409-48b5-b285-2e46c5c47586/_tmp_space.db
2018-06-30 00:27:16 INFO  SparkContext:54 - Running Spark version 2.3.1
2018-06-30 00:27:16 INFO  SparkContext:54 - Submitted application: SparkSQL::10.0.1.253
2018-06-30 00:27:16 INFO  SecurityManager:54 - Changing view acls to: jimmyyou
2018-06-30 00:27:16 INFO  SecurityManager:54 - Changing modify acls to: jimmyyou
2018-06-30 00:27:16 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-06-30 00:27:16 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-06-30 00:27:16 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jimmyyou); groups with view permissions: Set(); users  with modify permissions: Set(jimmyyou); groups with modify permissions: Set()
2018-06-30 00:27:16 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40553.
2018-06-30 00:27:16 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-06-30 00:27:16 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-06-30 00:27:16 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-06-30 00:27:16 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-06-30 00:27:16 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-5a3efdb9-fedc-4910-a6ed-b9e8d75c725a
2018-06-30 00:27:16 INFO  MemoryStore:54 - MemoryStore started with capacity 2004.6 MB
2018-06-30 00:27:16 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-06-30 00:27:16 INFO  log:192 - Logging initialized @4515ms
2018-06-30 00:27:16 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-06-30 00:27:16 INFO  Server:414 - Started @4566ms
2018-06-30 00:27:16 INFO  AbstractConnector:278 - Started ServerConnector@13516600{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-06-30 00:27:16 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ed18d80{/jobs,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@130a6eb9{/jobs/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@722531ab{/jobs/job,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26fadd98{/jobs/job/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66451058{/stages,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e92c3b6{/stages/stage,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baac4a7{/stages/stage/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@23ad2d17{/stages/pool,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bce4140{/stages/pool/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@25f0c5e7{/storage,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5882b202{/storage/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@120df990{/storage/rdd,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@282c4da0{/environment,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f3e805{/environment/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18cf5c52{/executors,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10618775{/executors/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5aea8994{/executors/threadDump,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20a3e10c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@426c0486{/static,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24197b13{/,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@71b97eeb{/api,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b89425{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59328218{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://dc1master-lan1:4040
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://dc1master-lan1:7077...
2018-06-30 00:27:16 INFO  TransportClientFactory:267 - Successfully created connection to dc1master-lan1/10.0.1.253:7077 after 20 ms (0 ms spent in bootstraps)
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20180630002716-0005
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180630002716-0005/0 on worker-20180630001956-10.0.2.2-42136 (10.0.2.2:42136) with 8 core(s)
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180630002716-0005/0 on hostPort 10.0.2.2:42136 with 8 core(s), 4.0 GB RAM
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180630002716-0005/1 on worker-20180630001956-10.0.2.1-46791 (10.0.2.1:46791) with 8 core(s)
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180630002716-0005/1 on hostPort 10.0.2.1:46791 with 8 core(s), 4.0 GB RAM
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180630002716-0005/2 on worker-20180630001956-10.0.1.2-38156 (10.0.1.2:38156) with 8 core(s)
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180630002716-0005/2 on hostPort 10.0.1.2:38156 with 8 core(s), 4.0 GB RAM
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180630002716-0005/3 on worker-20180630001956-10.0.5.2-36763 (10.0.5.2:36763) with 8 core(s)
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180630002716-0005/3 on hostPort 10.0.5.2:36763 with 8 core(s), 4.0 GB RAM
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180630002716-0005/4 on worker-20180630001956-10.0.5.1-40733 (10.0.5.1:40733) with 8 core(s)
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180630002716-0005/4 on hostPort 10.0.5.1:40733 with 8 core(s), 4.0 GB RAM
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180630002716-0005/5 on worker-20180630001956-10.0.1.1-36657 (10.0.1.1:36657) with 8 core(s)
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180630002716-0005/5 on hostPort 10.0.1.1:36657 with 8 core(s), 4.0 GB RAM
2018-06-30 00:27:16 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44181.
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180630002716-0005/6 on worker-20180630001956-10.0.3.2-37234 (10.0.3.2:37234) with 8 core(s)
2018-06-30 00:27:16 INFO  NettyBlockTransferService:54 - Server created on dc1master-lan1:44181
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180630002716-0005/6 on hostPort 10.0.3.2:37234 with 8 core(s), 4.0 GB RAM
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180630002716-0005/7 on worker-20180630001956-10.0.4.1-32880 (10.0.4.1:32880) with 8 core(s)
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180630002716-0005/7 on hostPort 10.0.4.1:32880 with 8 core(s), 4.0 GB RAM
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180630002716-0005/8 on worker-20180630001956-10.0.3.1-39652 (10.0.3.1:39652) with 8 core(s)
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180630002716-0005/8 on hostPort 10.0.3.1:39652 with 8 core(s), 4.0 GB RAM
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180630002716-0005/9 on worker-20180630001956-10.0.4.2-33064 (10.0.4.2:33064) with 8 core(s)
2018-06-30 00:27:16 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180630002716-0005/9 on hostPort 10.0.4.2:33064 with 8 core(s), 4.0 GB RAM
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180630002716-0005/0 is now RUNNING
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180630002716-0005/2 is now RUNNING
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180630002716-0005/1 is now RUNNING
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180630002716-0005/5 is now RUNNING
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180630002716-0005/6 is now RUNNING
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180630002716-0005/4 is now RUNNING
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180630002716-0005/3 is now RUNNING
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180630002716-0005/8 is now RUNNING
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180630002716-0005/9 is now RUNNING
2018-06-30 00:27:16 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180630002716-0005/7 is now RUNNING
2018-06-30 00:27:16 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, dc1master-lan1, 44181, None)
2018-06-30 00:27:16 INFO  BlockManagerMasterEndpoint:54 - Registering block manager dc1master-lan1:44181 with 2004.6 MB RAM, BlockManagerId(driver, dc1master-lan1, 44181, None)
2018-06-30 00:27:16 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, dc1master-lan1, 44181, None)
2018-06-30 00:27:16 INFO  BlockManager:54 - external shuffle service port = 7337
2018-06-30 00:27:16 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, dc1master-lan1, 44181, None)
2018-06-30 00:27:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6c6c2a73{/metrics/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:16 INFO  EventLoggingListener:54 - Logging events to hdfs://dc1master:9000/user/jimmyyou/spark-logs/app-20180630002716-0005
2018-06-30 00:27:16 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2018-06-30 00:27:16 INFO  SharedState:54 - loading hive config file: file:/users/jimmyyou/spark-2.3.1-bin-hadoop2.7/conf/hive-site.xml
2018-06-30 00:27:16 INFO  SharedState:54 - spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir ('/user/hive/warehouse').
2018-06-30 00:27:16 INFO  SharedState:54 - Warehouse path is '/user/hive/warehouse'.
2018-06-30 00:27:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e753289{/SQL,null,AVAILABLE,@Spark}
2018-06-30 00:27:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1573e8a5{/SQL/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7433ca19{/SQL/execution,null,AVAILABLE,@Spark}
2018-06-30 00:27:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5d221b20{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-06-30 00:27:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@78eafad{/static/sql,null,AVAILABLE,@Spark}
2018-06-30 00:27:17 INFO  HiveUtils:54 - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
2018-06-30 00:27:17 INFO  HiveClientImpl:54 - Warehouse location for Hive client (version 1.2.2) is /user/hive/warehouse
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_database: default
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: default	
2018-06-30 00:27:17 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_database: global_temp
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: global_temp	
2018-06-30 00:27:17 WARN  ObjectStore:568 - Failed to get database global_temp, returning NoSuchObjectException
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_database: tpcds_text_20
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_database: tpcds_text_20	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=catalog_sales
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=catalog_sales	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=date_dim
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=date_dim	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=customer_demographics
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=customer_demographics	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=item
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=item	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=customer
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=customer	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=customer_address
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=customer_address	
2018-06-30 00:27:17 INFO  HiveMetaStore:746 - 0: get_table : db=tpcds_text_20 tbl=customer_demographics
2018-06-30 00:27:17 INFO  audit:371 - ugi=jimmyyou	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_20 tbl=customer_demographics	
2018-06-30 00:27:17 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.1.2:44132) with ID 2
2018-06-30 00:27:17 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.2:37254) with ID 0
2018-06-30 00:27:17 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.3.1:54722) with ID 8
2018-06-30 00:27:17 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.1.1:55800) with ID 5
2018-06-30 00:27:17 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.5.2:36160) with ID 3
2018-06-30 00:27:17 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.2.1:46958) with ID 1
2018-06-30 00:27:17 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.4.1:45836) with ID 7
2018-06-30 00:27:17 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.5.1:54354) with ID 4
2018-06-30 00:27:17 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.4.2:50648) with ID 9
2018-06-30 00:27:17 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.3.2:44922) with ID 6
2018-06-30 00:27:17 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.1.2:35072 with 2004.6 MB RAM, BlockManagerId(2, 10.0.1.2, 35072, None)
2018-06-30 00:27:17 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.2.2:37599 with 2004.6 MB RAM, BlockManagerId(0, 10.0.2.2, 37599, None)
2018-06-30 00:27:17 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.5.2:33445 with 2004.6 MB RAM, BlockManagerId(3, 10.0.5.2, 33445, None)
2018-06-30 00:27:17 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.1.1:34454 with 2004.6 MB RAM, BlockManagerId(5, 10.0.1.1, 34454, None)
2018-06-30 00:27:17 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.3.1:43746 with 2004.6 MB RAM, BlockManagerId(8, 10.0.3.1, 43746, None)
2018-06-30 00:27:17 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.2.1:41047 with 2004.6 MB RAM, BlockManagerId(1, 10.0.2.1, 41047, None)
2018-06-30 00:27:17 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.4.1:44707 with 2004.6 MB RAM, BlockManagerId(7, 10.0.4.1, 44707, None)
2018-06-30 00:27:17 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.5.1:43497 with 2004.6 MB RAM, BlockManagerId(4, 10.0.5.1, 43497, None)
2018-06-30 00:27:18 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.4.2:39681 with 2004.6 MB RAM, BlockManagerId(9, 10.0.4.2, 39681, None)
2018-06-30 00:27:18 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.3.2:44656 with 2004.6 MB RAM, BlockManagerId(6, 10.0.3.2, 44656, None)
2018-06-30 00:27:18 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
2018-06-30 00:27:19 INFO  ContextCleaner:54 - Cleaned accumulator 1
2018-06-30 00:27:19 INFO  ContextCleaner:54 - Cleaned accumulator 2
2018-06-30 00:27:19 INFO  ContextCleaner:54 - Cleaned accumulator 0
2018-06-30 00:27:19 INFO  CodeGenerator:54 - Code generated in 272.564569 ms
2018-06-30 00:27:19 INFO  CodeGenerator:54 - Code generated in 19.243054 ms
2018-06-30 00:27:19 INFO  CodeGenerator:54 - Code generated in 19.293792 ms
2018-06-30 00:27:19 INFO  CodeGenerator:54 - Code generated in 21.454008 ms
2018-06-30 00:27:19 INFO  CodeGenerator:54 - Code generated in 22.783551 ms
2018-06-30 00:27:19 INFO  CodeGenerator:54 - Code generated in 26.019219 ms
2018-06-30 00:27:19 INFO  CodeGenerator:54 - Code generated in 78.303875 ms
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 291.3 KB, free 2003.2 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 290.9 KB, free 2003.2 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 290.7 KB, free 2003.2 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 291.1 KB, free 2003.2 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 291.3 KB, free 2003.2 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.1 KB, free 2003.1 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.9 KB, free 2003.1 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.1 KB, free 2003.1 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 25.0 KB, free 2003.1 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 25.0 KB, free 2003.1 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on dc1master-lan1:44181 (size: 25.1 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  SparkContext:54 - Created broadcast 0 from 
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on dc1master-lan1:44181 (size: 25.0 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  SparkContext:54 - Created broadcast 4 from 
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on dc1master-lan1:44181 (size: 25.1 KB, free: 2004.5 MB)
2018-06-30 00:27:20 INFO  SparkContext:54 - Created broadcast 1 from 
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on dc1master-lan1:44181 (size: 24.9 KB, free: 2004.5 MB)
2018-06-30 00:27:20 INFO  SparkContext:54 - Created broadcast 2 from 
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on dc1master-lan1:44181 (size: 25.0 KB, free: 2004.5 MB)
2018-06-30 00:27:20 INFO  SparkContext:54 - Created broadcast 3 from 
2018-06-30 00:27:20 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2018-06-30 00:27:20 INFO  FileInputFormat:249 - Total input paths to process : 1
2018-06-30 00:27:20 INFO  FileInputFormat:249 - Total input paths to process : 1
2018-06-30 00:27:20 INFO  FileInputFormat:249 - Total input paths to process : 1
2018-06-30 00:27:20 INFO  FileInputFormat:249 - Total input paths to process : 1
2018-06-30 00:27:20 INFO  FileInputFormat:249 - Total input paths to process : 20
2018-06-30 00:27:20 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-06-30 00:27:20 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-06-30 00:27:20 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-06-30 00:27:20 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-06-30 00:27:20 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1142
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Got job 3 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (run at ThreadPoolExecutor.java:1142)
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Missing parents: List()
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 14.5 KB, free 2003.0 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 2003.0 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on dc1master-lan1:44181 (size: 6.4 KB, free: 2004.5 MB)
2018-06-30 00:27:20 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[28] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 2 tasks
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Got job 1 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (run at ThreadPoolExecutor.java:1142)
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Missing parents: List()
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[25] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 12.2 KB, free 2003.0 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2003.0 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on dc1master-lan1:44181 (size: 6.0 KB, free: 2004.5 MB)
2018-06-30 00:27:20 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[25] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 2 tasks
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, 10.0.4.2, executor 9, partition 0, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, 10.0.1.2, executor 2, partition 1, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Got job 0 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (run at ThreadPoolExecutor.java:1142)
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Missing parents: List()
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[27] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 14.6 KB, free 2003.0 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.3 KB, free 2003.0 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on dc1master-lan1:44181 (size: 6.3 KB, free: 2004.5 MB)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 2, 10.0.5.2, executor 3, partition 0, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 3, 10.0.2.2, executor 0, partition 1, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[27] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 2 tasks
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Got job 2 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (run at ThreadPoolExecutor.java:1142)
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Missing parents: List()
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 4, 10.0.5.2, executor 3, partition 0, ANY, 7924 bytes)
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[29] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.0 in stage 2.0 (TID 5, 10.0.1.1, executor 5, partition 1, ANY, 7924 bytes)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 11.9 KB, free 2003.0 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2003.0 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on dc1master-lan1:44181 (size: 5.9 KB, free: 2004.5 MB)
2018-06-30 00:27:20 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[29] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 2 tasks
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Got job 4 (run at ThreadPoolExecutor.java:1142) with 20 output partitions
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (run at ThreadPoolExecutor.java:1142)
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Missing parents: List()
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 6, 10.0.4.1, executor 7, partition 0, ANY, 7912 bytes)
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[26] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 7, 10.0.3.1, executor 8, partition 1, ANY, 7912 bytes)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 10.9 KB, free 2003.0 MB)
2018-06-30 00:27:20 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KB, free 2003.0 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on dc1master-lan1:44181 (size: 5.5 KB, free: 2004.4 MB)
2018-06-30 00:27:20 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Submitting 20 missing tasks from ResultStage 4 (MapPartitionsRDD[26] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 20 tasks
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 8, 10.0.1.2, executor 2, partition 0, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 9, 10.0.5.1, executor 4, partition 1, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 10, 10.0.4.2, executor 9, partition 2, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 11, 10.0.1.1, executor 5, partition 3, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 4.0 in stage 4.0 (TID 12, 10.0.3.1, executor 8, partition 4, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 5.0 in stage 4.0 (TID 13, 10.0.2.2, executor 0, partition 5, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 6.0 in stage 4.0 (TID 14, 10.0.3.2, executor 6, partition 6, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 7.0 in stage 4.0 (TID 15, 10.0.4.1, executor 7, partition 7, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 8.0 in stage 4.0 (TID 16, 10.0.2.1, executor 1, partition 8, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 9.0 in stage 4.0 (TID 17, 10.0.5.2, executor 3, partition 9, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 10.0 in stage 4.0 (TID 18, 10.0.1.2, executor 2, partition 10, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 11.0 in stage 4.0 (TID 19, 10.0.5.1, executor 4, partition 11, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 12.0 in stage 4.0 (TID 20, 10.0.4.2, executor 9, partition 12, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 13.0 in stage 4.0 (TID 21, 10.0.1.1, executor 5, partition 13, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 14.0 in stage 4.0 (TID 22, 10.0.3.1, executor 8, partition 14, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 15.0 in stage 4.0 (TID 23, 10.0.2.2, executor 0, partition 15, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 16.0 in stage 4.0 (TID 24, 10.0.3.2, executor 6, partition 16, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 17.0 in stage 4.0 (TID 25, 10.0.4.1, executor 7, partition 17, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 18.0 in stage 4.0 (TID 26, 10.0.2.1, executor 1, partition 18, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 19.0 in stage 4.0 (TID 27, 10.0.5.2, executor 3, partition 19, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 10.0.5.2:33445 (size: 6.3 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.1.1:34454 (size: 5.5 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.4.2:39681 (size: 5.5 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.0.4.1:44707 (size: 5.9 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.1.2:35072 (size: 5.5 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.3.1:43746 (size: 5.5 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.0.2.2:37599 (size: 6.0 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.5.1:43497 (size: 5.5 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.2.1:41047 (size: 5.5 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.3.2:44656 (size: 5.5 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 10.0.1.1:34454 (size: 6.3 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.0.1.2:35072 (size: 6.4 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.0.4.2:39681 (size: 6.4 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.0.3.1:43746 (size: 5.9 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.4.1:44707 (size: 5.5 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.2.2:37599 (size: 5.5 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.5.2:33445 (size: 5.5 KB, free: 2004.6 MB)
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 0.0 in stage 2.0 (TID 4, 10.0.5.2, executor 3): java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 9.0 in stage 4.0 (TID 17, 10.0.5.2, executor 3): java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.0 in stage 2.0 (TID 5) on 10.0.1.1, executor 5: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 1]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 19.0 in stage 4.0 (TID 27) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 1]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 2.0 in stage 4.0 (TID 10) on 10.0.4.2, executor 9: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 2]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 12.0 in stage 4.0 (TID 20) on 10.0.4.2, executor 9: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 3]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.1 in stage 2.0 (TID 28, 10.0.5.1, executor 4, partition 1, ANY, 7924 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.1 in stage 2.0 (TID 29, 10.0.5.1, executor 4, partition 0, ANY, 7924 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 12.1 in stage 4.0 (TID 30, 10.0.5.1, executor 4, partition 12, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 2.1 in stage 4.0 (TID 31, 10.0.5.1, executor 4, partition 2, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 19.1 in stage 4.0 (TID 32, 10.0.5.1, executor 4, partition 19, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 9.1 in stage 4.0 (TID 33, 10.0.5.1, executor 4, partition 9, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 5.0 in stage 4.0 (TID 13) on 10.0.2.2, executor 0: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 4]
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 0.0 in stage 3.0 (TID 6, 10.0.4.1, executor 7): java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 3.0 in stage 4.0 (TID 11) on 10.0.1.1, executor 5: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 5]
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 0.0 in stage 0.0 (TID 0, 10.0.4.2, executor 9): java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.1 in stage 3.0 (TID 34, 10.0.5.1, executor 4, partition 0, ANY, 7912 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.1 in stage 0.0 (TID 35, 10.0.5.1, executor 4, partition 0, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 13.0 in stage 4.0 (TID 21) on 10.0.1.1, executor 5: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 6]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 15.0 in stage 4.0 (TID 23) on 10.0.2.2, executor 0: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 7]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 15.1 in stage 4.0 (TID 36, 10.0.2.1, executor 1, partition 15, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 13.1 in stage 4.0 (TID 37, 10.0.3.1, executor 8, partition 13, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 3.1 in stage 4.0 (TID 38, 10.0.3.2, executor 6, partition 3, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 5.1 in stage 4.0 (TID 39, 10.0.1.2, executor 2, partition 5, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 0.0 in stage 4.0 (TID 8) on 10.0.1.2, executor 2: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 8]
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.0.5.2:33445 (size: 6.0 KB, free: 2004.6 MB)
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 1.0 in stage 1.0 (TID 3, 10.0.2.2, executor 0): java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 7.0 in stage 4.0 (TID 15) on 10.0.4.1, executor 7: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 9]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 17.0 in stage 4.0 (TID 25) on 10.0.4.1, executor 7: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 10]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.1 in stage 1.0 (TID 40, 10.0.1.1, executor 5, partition 1, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 17.1 in stage 4.0 (TID 41, 10.0.1.1, executor 5, partition 17, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 7.1 in stage 4.0 (TID 42, 10.0.2.1, executor 1, partition 7, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.1 in stage 4.0 (TID 43, 10.0.3.2, executor 6, partition 0, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 10.0 in stage 4.0 (TID 18) on 10.0.1.2, executor 2: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 11]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.0 in stage 0.0 (TID 1) on 10.0.1.2, executor 2: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 1]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.0 in stage 3.0 (TID 7) on 10.0.3.1, executor 8: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 1]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 14.0 in stage 4.0 (TID 22) on 10.0.3.1, executor 8: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 12]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.1 in stage 3.0 (TID 44, 10.0.4.1, executor 7, partition 1, ANY, 7912 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 45, 10.0.4.1, executor 7, partition 1, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 14.1 in stage 4.0 (TID 46, 10.0.4.1, executor 7, partition 14, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 10.1 in stage 4.0 (TID 47, 10.0.2.1, executor 1, partition 10, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.0 in stage 4.0 (TID 9) on 10.0.5.1, executor 4: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 13]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 11.0 in stage 4.0 (TID 19) on 10.0.5.1, executor 4: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 14]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 4.0 in stage 4.0 (TID 12) on 10.0.3.1, executor 8: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 15]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 4.1 in stage 4.0 (TID 48, 10.0.1.2, executor 2, partition 4, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 11.1 in stage 4.0 (TID 49, 10.0.3.1, executor 8, partition 11, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.1 in stage 4.0 (TID 50, 10.0.5.2, executor 3, partition 1, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 8.0 in stage 4.0 (TID 16) on 10.0.2.1, executor 1: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 16]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 18.0 in stage 4.0 (TID 26) on 10.0.2.1, executor 1: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 17]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 18.1 in stage 4.0 (TID 51, 10.0.3.1, executor 8, partition 18, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 8.1 in stage 4.0 (TID 52, 10.0.3.1, executor 8, partition 8, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 13.1 in stage 4.0 (TID 37) on 10.0.3.1, executor 8: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 18]
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.0.4.1:44707 (size: 6.4 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 13.2 in stage 4.0 (TID 53, 10.0.5.2, executor 3, partition 13, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 0.0 in stage 1.0 (TID 2) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 1]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.1 in stage 1.0 (TID 54, 10.0.1.2, executor 2, partition 0, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 5.1 in stage 4.0 (TID 39) on 10.0.1.2, executor 2: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 19]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 5.2 in stage 4.0 (TID 55, 10.0.3.1, executor 8, partition 5, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 15.1 in stage 4.0 (TID 36) on 10.0.2.1, executor 1: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 20]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 15.2 in stage 4.0 (TID 56, 10.0.3.1, executor 8, partition 15, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 7.1 in stage 4.0 (TID 42) on 10.0.2.1, executor 1: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 21]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 16.0 in stage 4.0 (TID 24) on 10.0.3.2, executor 6: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 22]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 6.0 in stage 4.0 (TID 14) on 10.0.3.2, executor 6: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 23]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 6.1 in stage 4.0 (TID 57, 10.0.5.2, executor 3, partition 6, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 16.1 in stage 4.0 (TID 58, 10.0.3.1, executor 8, partition 16, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 7.2 in stage 4.0 (TID 59, 10.0.2.2, executor 0, partition 7, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 3.1 in stage 4.0 (TID 38) on 10.0.3.2, executor 6: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 24]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.1 in stage 3.0 (TID 44) on 10.0.4.1, executor 7: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 2]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 10.1 in stage 4.0 (TID 47) on 10.0.2.1, executor 1: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 25]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 0.1 in stage 4.0 (TID 43) on 10.0.3.2, executor 6: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 26]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.2 in stage 3.0 (TID 60, 10.0.5.2, executor 3, partition 1, ANY, 7912 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.2 in stage 4.0 (TID 61, 10.0.5.2, executor 3, partition 0, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 10.2 in stage 4.0 (TID 62, 10.0.5.2, executor 3, partition 10, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 3.2 in stage 4.0 (TID 63, 10.0.5.2, executor 3, partition 3, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.1 in stage 4.0 (TID 50) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 27]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 11.1 in stage 4.0 (TID 49) on 10.0.3.1, executor 8: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 28]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 11.2 in stage 4.0 (TID 64, 10.0.4.2, executor 9, partition 11, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.2 in stage 4.0 (TID 65, 10.0.3.2, executor 6, partition 1, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 4.1 in stage 4.0 (TID 48) on 10.0.1.2, executor 2: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 29]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 4.2 in stage 4.0 (TID 66, 10.0.4.2, executor 9, partition 4, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 13.2 in stage 4.0 (TID 53) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 30]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 13.3 in stage 4.0 (TID 67, 10.0.1.1, executor 5, partition 13, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 8.1 in stage 4.0 (TID 52) on 10.0.3.1, executor 8: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 31]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 14.1 in stage 4.0 (TID 46) on 10.0.4.1, executor 7: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 32]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 45) on 10.0.4.1, executor 7: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 2]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 68, 10.0.5.2, executor 3, partition 1, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 14.2 in stage 4.0 (TID 69, 10.0.5.2, executor 3, partition 14, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 8.2 in stage 4.0 (TID 70, 10.0.4.2, executor 9, partition 8, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 10.0.5.1:43497 (size: 6.3 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 18.1 in stage 4.0 (TID 51) on 10.0.3.1, executor 8: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 33]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 5.2 in stage 4.0 (TID 55) on 10.0.3.1, executor 8: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 34]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 5.3 in stage 4.0 (TID 71, 10.0.1.2, executor 2, partition 5, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 18.2 in stage 4.0 (TID 72, 10.0.4.2, executor 9, partition 18, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 15.2 in stage 4.0 (TID 56) on 10.0.3.1, executor 8: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 35]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 16.1 in stage 4.0 (TID 58) on 10.0.3.1, executor 8: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 36]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 6.1 in stage 4.0 (TID 57) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 37]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 6.2 in stage 4.0 (TID 73, 10.0.2.2, executor 0, partition 6, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 16.2 in stage 4.0 (TID 74, 10.0.2.2, executor 0, partition 16, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 15.3 in stage 4.0 (TID 75, 10.0.2.2, executor 0, partition 15, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 7.2 in stage 4.0 (TID 59) on 10.0.2.2, executor 0: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 38]
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.0.1.2:35072 (size: 6.0 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 7.3 in stage 4.0 (TID 76, 10.0.2.2, executor 0, partition 7, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.0.5.2:33445 (size: 5.9 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.0.1.1:34454 (size: 6.0 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.2 in stage 4.0 (TID 65) on 10.0.3.2, executor 6: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 39]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.3 in stage 4.0 (TID 77, 10.0.5.2, executor 3, partition 1, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 4.2 in stage 4.0 (TID 66) on 10.0.4.2, executor 9: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 40]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 4.3 in stage 4.0 (TID 78, 10.0.1.1, executor 5, partition 4, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 11.2 in stage 4.0 (TID 64) on 10.0.4.2, executor 9: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 41]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 11.3 in stage 4.0 (TID 79, 10.0.1.2, executor 2, partition 11, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 8.2 in stage 4.0 (TID 70) on 10.0.4.2, executor 9: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 42]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.1 in stage 2.0 (TID 28) on 10.0.5.1, executor 4: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 2]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.2 in stage 2.0 (TID 80, 10.0.4.2, executor 9, partition 1, ANY, 7924 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 8.3 in stage 4.0 (TID 81, 10.0.4.2, executor 9, partition 8, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 18.2 in stage 4.0 (TID 72) on 10.0.4.2, executor 9: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 43]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 18.3 in stage 4.0 (TID 82, 10.0.2.2, executor 0, partition 18, ANY, 7929 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.2 in stage 3.0 (TID 60) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 3]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.3 in stage 3.0 (TID 83, 10.0.2.1, executor 1, partition 1, ANY, 7912 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 6.2 in stage 4.0 (TID 73) on 10.0.2.2, executor 0: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 44]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 0.1 in stage 1.0 (TID 54) on 10.0.1.2, executor 2: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 2]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 5.3 in stage 4.0 (TID 71) on 10.0.1.2, executor 2: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 45]
2018-06-30 00:27:20 ERROR TaskSetManager:70 - Task 5 in stage 4.0 failed 4 times; aborting job
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.0.5.2:33445 (size: 6.4 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 0.2 in stage 1.0 (TID 84, 10.0.3.1, executor 8, partition 0, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 15.3 in stage 4.0 (TID 75) on 10.0.2.2, executor 0: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 46]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 16.2 in stage 4.0 (TID 74) on 10.0.2.2, executor 0: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 47]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 13.3 in stage 4.0 (TID 67) on 10.0.1.1, executor 5: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 48]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 11.3 in stage 4.0 (TID 79) on 10.0.1.2, executor 2: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 49]
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Cancelling stage 4
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Stage 4 was cancelled
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 4.3 in stage 4.0 (TID 78) on 10.0.1.1, executor 5: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 50]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.1 in stage 1.0 (TID 40) on 10.0.1.1, executor 5: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 3]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 7.3 in stage 4.0 (TID 76) on 10.0.2.2, executor 0: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 51]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 17.1 in stage 4.0 (TID 41) on 10.0.1.1, executor 5: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 52]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 18.3 in stage 4.0 (TID 82) on 10.0.2.2, executor 0: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 53]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.2 in stage 1.0 (TID 85, 10.0.1.2, executor 2, partition 1, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  DAGScheduler:54 - ResultStage 4 (run at ThreadPoolExecutor.java:1142) failed in 0.312 s due to Job aborted due to stage failure: Task 5 in stage 4.0 failed 4 times, most recent failure: Lost task 5.3 in stage 4.0 (TID 71, 10.0.1.2, executor 2): java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.2 in stage 0.0 (TID 68) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 3]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.3 in stage 0.0 (TID 86, 10.0.4.2, executor 9, partition 1, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 14.2 in stage 4.0 (TID 69) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 54]
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Job 4 failed: run at ThreadPoolExecutor.java:1142, took 0.396538 s
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.2 in stage 1.0 (TID 85) on 10.0.1.2, executor 2: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 4]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 0.2 in stage 4.0 (TID 61) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 55]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.3 in stage 1.0 (TID 87, 10.0.5.2, executor 3, partition 1, ANY, 7916 bytes)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.3 in stage 4.0 (TID 77) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 56]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 3.2 in stage 4.0 (TID 63) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 57]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 10.2 in stage 4.0 (TID 62) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 58]
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 10.0.4.2:39681 (size: 6.3 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.3 in stage 1.0 (TID 87) on 10.0.5.2, executor 3: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 5]
2018-06-30 00:27:20 ERROR TaskSetManager:70 - Task 1 in stage 1.0 failed 4 times; aborting job
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Cancelling stage 1
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Stage 1 was cancelled
2018-06-30 00:27:20 INFO  DAGScheduler:54 - ResultStage 1 (run at ThreadPoolExecutor.java:1142) failed in 0.350 s due to Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 87, 10.0.5.2, executor 3): java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.0.2.1:41047 (size: 5.9 KB, free: 2004.6 MB)
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Job 1 failed: run at ThreadPoolExecutor.java:1142, took 0.404648 s
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 86) on 10.0.4.2, executor 9: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 4]
2018-06-30 00:27:20 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.2 in stage 2.0 (TID 80) on 10.0.4.2, executor 9: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 3]
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Starting task 1.3 in stage 2.0 (TID 88, 10.0.4.2, executor 9, partition 1, ANY, 7924 bytes)
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Cancelling stage 0
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Stage 0 was cancelled
2018-06-30 00:27:20 INFO  DAGScheduler:54 - ResultStage 0 (run at ThreadPoolExecutor.java:1142) failed in 0.384 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 86, 10.0.4.2, executor 9): java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Job 3 failed: run at ThreadPoolExecutor.java:1142, took 0.412720 s
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.0.5.1:43497 (size: 6.4 KB, free: 2004.6 MB)
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 8.3 in stage 4.0 (TID 81, 10.0.4.2, executor 9): UnknownReason
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.3 in stage 3.0 (TID 83) on 10.0.2.1, executor 1: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 4]
2018-06-30 00:27:20 ERROR TaskSetManager:70 - Task 1 in stage 3.0 failed 4 times; aborting job
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Cancelling stage 3
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Stage 3 was cancelled
2018-06-30 00:27:20 INFO  TaskSetManager:54 - Lost task 1.3 in stage 2.0 (TID 88) on 10.0.4.2, executor 9: java.io.InvalidClassException (org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292) [duplicate 4]
2018-06-30 00:27:20 INFO  DAGScheduler:54 - ResultStage 3 (run at ThreadPoolExecutor.java:1142) failed in 0.343 s due to Job aborted due to stage failure: Task 1 in stage 3.0 failed 4 times, most recent failure: Lost task 1.3 in stage 3.0 (TID 83, 10.0.2.1, executor 1): java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-06-30 00:27:20 ERROR TaskSetManager:70 - Task 1 in stage 2.0 failed 4 times; aborting job
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Job 2 failed: run at ThreadPoolExecutor.java:1142, took 0.416483 s
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Cancelling stage 2
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Stage 2 was cancelled
2018-06-30 00:27:20 INFO  DAGScheduler:54 - ResultStage 2 (run at ThreadPoolExecutor.java:1142) failed in 0.349 s due to Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task 1.3 in stage 2.0 (TID 88, 10.0.4.2, executor 9): java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-06-30 00:27:20 INFO  DAGScheduler:54 - Job 0 failed: run at ThreadPoolExecutor.java:1142, took 0.417734 s
2018-06-30 00:27:20 ERROR SparkSQLDriver:91 - Failed in [select  i_item_id,
        ca_country,
        ca_state, 
        ca_county,
        avg( cast(cs_quantity as decimal(12,2))) agg1,
        avg( cast(cs_list_price as decimal(12,2))) agg2,
        avg( cast(cs_coupon_amt as decimal(12,2))) agg3,
        avg( cast(cs_sales_price as decimal(12,2))) agg4,
        avg( cast(cs_net_profit as decimal(12,2))) agg5,
        avg( cast(c_birth_year as decimal(12,2))) agg6,
        avg( cast(cd1.cd_dep_count as decimal(12,2))) agg7
 from catalog_sales, date_dim, customer_demographics cd1, item, customer, customer_address, 
      customer_demographics cd2
 where catalog_sales.cs_sold_date_sk = date_dim.d_date_sk and
       catalog_sales.cs_item_sk = item.i_item_sk and
       catalog_sales.cs_bill_cdemo_sk = cd1.cd_demo_sk and
       catalog_sales.cs_bill_customer_sk = customer.c_customer_sk and
       cd1.cd_gender = 'M' and 
       cd1.cd_education_status = 'College' and
       customer.c_current_cdemo_sk = cd2.cd_demo_sk and
       customer.c_current_addr_sk = customer_address.ca_address_sk and
       c_birth_month in (9,5,12,4,1,10) and
       d_year = 2001 and
       ca_state in ('ND','WI','AL'
                   ,'NC','OK','MS','TN')
 group by i_item_id, ca_country, ca_state, ca_county with rollup
 order by ca_country,
        ca_state, 
        ca_county,
	i_item_id
 limit 100]
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:205)
	at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:136)
	at org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:367)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:144)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:140)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:140)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:135)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenInner(BroadcastHashJoinExec.scala:232)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:102)
	at org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:181)
	at org.apache.spark.sql.execution.ProjectExec.consume(basicPhysicalOperators.scala:35)
	at org.apache.spark.sql.execution.ProjectExec.doConsume(basicPhysicalOperators.scala:65)
	at org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:181)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec.consume(SortMergeJoinExec.scala:36)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec.doProduce(SortMergeJoinExec.scala:633)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.joins.SortMergeJoinExec.produce(SortMergeJoinExec.scala:36)
	at org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:97)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:39)
	at org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:97)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:39)
	at org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:97)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:39)
	at org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:97)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:39)
	at org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)
	at org.apache.spark.sql.execution.ExpandExec.doProduce(ExpandExec.scala:93)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.ExpandExec.produce(ExpandExec.scala:36)
	at org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduceWithKeys(HashAggregateExec.scala:641)
	at org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduce(HashAggregateExec.scala:165)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)
	at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)
	at org.apache.spark.sql.execution.aggregate.HashAggregateExec.produce(HashAggregateExec.scala:39)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:524)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:576)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)
	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)
	at org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:150)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:135)
	at org.apache.spark.sql.execution.SparkPlan.executeCollectPublic(SparkPlan.scala:324)
	at org.apache.spark.sql.execution.QueryExecution.hiveResultString(QueryExecution.scala:122)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLDriver$$anonfun$run$1.apply(SparkSQLDriver.scala:64)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLDriver$$anonfun$run$1.apply(SparkSQLDriver.scala:64)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLDriver.run(SparkSQLDriver.scala:63)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:364)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:311)
	at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:409)
	at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:425)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:198)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3.0 failed 4 times, most recent failure: Lost task 1.3 in stage 3.0 (TID 83, 10.0.2.1, executor 1): java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:938)
	at org.apache.spark.sql.execution.SparkPlan.executeCollectIterator(SparkPlan.scala:304)
	at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1$$anonfun$apply$1.apply(BroadcastExchangeExec.scala:76)
	at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1$$anonfun$apply$1.apply(BroadcastExchangeExec.scala:73)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionId(SQLExecution.scala:97)
	at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1.apply(BroadcastExchangeExec.scala:72)
	at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1.apply(BroadcastExchangeExec.scala:72)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.InvalidClassException: org.apache.spark.rdd.HadoopRDD; local class incompatible: stream classdesc serialVersionUID = 4698308104784017115, local class serialVersionUID = 47165080173784292
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:616)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1843)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
	... 3 more
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.0.5.1:43497 (size: 5.9 KB, free: 2004.6 MB)
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 0.1 in stage 0.0 (TID 35, 10.0.5.1, executor 4): UnknownReason
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-06-30 00:27:20 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.0.3.1:43746 (size: 6.0 KB, free: 2004.6 MB)
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 0.1 in stage 3.0 (TID 34, 10.0.5.1, executor 4): UnknownReason
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 0.1 in stage 2.0 (TID 29, 10.0.5.1, executor 4): UnknownReason
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 9.1 in stage 4.0 (TID 33, 10.0.5.1, executor 4): UnknownReason
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 2.1 in stage 4.0 (TID 31, 10.0.5.1, executor 4): UnknownReason
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 12.1 in stage 4.0 (TID 30, 10.0.5.1, executor 4): UnknownReason
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 19.1 in stage 4.0 (TID 32, 10.0.5.1, executor 4): UnknownReason
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-06-30 00:27:20 WARN  TaskSetManager:66 - Lost task 0.2 in stage 1.0 (TID 84, 10.0.3.1, executor 8): UnknownReason
2018-06-30 00:27:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-06-30 00:27:20 INFO  AbstractConnector:318 - Stopped Spark@13516600{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-06-30 00:27:20 INFO  SparkUI:54 - Stopped Spark web UI at http://dc1master-lan1:4040
2018-06-30 00:27:21 INFO  StandaloneSchedulerBackend:54 - Shutting down all executors
2018-06-30 00:27:21 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Asking each executor to shut down
2018-06-30 00:27:21 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-06-30 00:27:21 INFO  MemoryStore:54 - MemoryStore cleared
2018-06-30 00:27:21 INFO  BlockManager:54 - BlockManager stopped
2018-06-30 00:27:21 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-06-30 00:27:21 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-06-30 00:27:21 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-06-30 00:27:21 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-06-30 00:27:21 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-ab13355c-1ed3-40dd-b726-3d90bc893fa7
2018-06-30 00:27:21 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-ccdf67ad-8839-43c3-b496-ada72b0d5c2c
