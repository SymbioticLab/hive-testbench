18/06/26 02:18:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/06/26 02:18:49 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/06/26 02:18:49 INFO metastore.ObjectStore: ObjectStore, initialize called
18/06/26 02:18:49 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/06/26 02:18:49 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/06/26 02:18:51 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/06/26 02:18:52 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/06/26 02:18:52 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/06/26 02:18:52 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/06/26 02:18:52 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/06/26 02:18:52 INFO DataNucleus.Query: Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
18/06/26 02:18:52 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/06/26 02:18:52 INFO metastore.ObjectStore: Initialized ObjectStore
18/06/26 02:18:52 INFO metastore.HiveMetaStore: Added admin role in metastore
18/06/26 02:18:52 INFO metastore.HiveMetaStore: Added public role in metastore
18/06/26 02:18:52 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
18/06/26 02:18:52 INFO metastore.HiveMetaStore: 0: get_all_databases
18/06/26 02:18:52 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_all_databases	
18/06/26 02:18:52 INFO metastore.HiveMetaStore: 0: get_functions: db=default pat=*
18/06/26 02:18:52 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/06/26 02:18:52 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/06/26 02:18:53 INFO metastore.HiveMetaStore: 0: get_functions: db=tpcds_text_2 pat=*
18/06/26 02:18:53 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_functions: db=tpcds_text_2 pat=*	
18/06/26 02:18:53 INFO session.SessionState: Created local directory: /tmp/91c2fa28-a90f-483e-bc5f-dfa118d901a7_resources
18/06/26 02:18:53 INFO session.SessionState: Created HDFS directory: /tmp/hive/wentingt/91c2fa28-a90f-483e-bc5f-dfa118d901a7
18/06/26 02:18:53 INFO session.SessionState: Created local directory: /tmp/wentingt/91c2fa28-a90f-483e-bc5f-dfa118d901a7
18/06/26 02:18:53 INFO session.SessionState: Created HDFS directory: /tmp/hive/wentingt/91c2fa28-a90f-483e-bc5f-dfa118d901a7/_tmp_space.db
18/06/26 02:18:53 INFO spark.SparkContext: Running Spark version 2.4.0-SNAPSHOT
18/06/26 02:18:53 INFO spark.SparkContext: Submitted application: SparkSQL::10.0.1.253
18/06/26 02:18:53 INFO spark.SecurityManager: Changing view acls to: wentingt
18/06/26 02:18:53 INFO spark.SecurityManager: Changing modify acls to: wentingt
18/06/26 02:18:53 INFO spark.SecurityManager: Changing view acls groups to: 
18/06/26 02:18:53 INFO spark.SecurityManager: Changing modify acls groups to: 
18/06/26 02:18:53 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wentingt); groups with view permissions: Set(); users  with modify permissions: Set(wentingt); groups with modify permissions: Set()
18/06/26 02:18:54 INFO util.Utils: Successfully started service 'sparkDriver' on port 33782.
18/06/26 02:18:54 INFO spark.SparkEnv: Registering MapOutputTracker
18/06/26 02:18:54 INFO spark.SparkEnv: Registering BlockManagerMaster
18/06/26 02:18:54 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/06/26 02:18:54 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/06/26 02:18:54 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-3c57b9a9-3198-4268-a225-6175a0e404ac
18/06/26 02:18:54 INFO memory.MemoryStore: MemoryStore started with capacity 369.3 MB
18/06/26 02:18:54 INFO spark.SparkEnv: Registering OutputCommitCoordinator
18/06/26 02:18:54 INFO util.log: Logging initialized @7272ms
18/06/26 02:18:54 INFO server.Server: jetty-9.3.z-SNAPSHOT
18/06/26 02:18:54 INFO server.Server: Started @7347ms
18/06/26 02:18:54 INFO server.AbstractConnector: Started ServerConnector@59d5a6fd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
18/06/26 02:18:54 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@120350eb{/jobs,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1b1252c8{/jobs/json,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@19d53ab4{/jobs/job,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51fe7f15{/jobs/job/json,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5873f3f0{/stages,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@684372d0{/stages/json,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@63dda940{/stages/stage,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7574d4ad{/stages/stage/json,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7bede4ea{/stages/pool,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@713999c2{/stages/pool/json,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6060146b{/storage,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@33627576{/storage/json,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@27bc1d44{/storage/rdd,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1af677f8{/storage/rdd/json,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a55fb81{/environment,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a3cf878{/environment/json,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1d2d8846{/executors,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@34cd65ac{/executors/json,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@61911947{/executors/threadDump,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c53c235{/executors/threadDump/json,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2dcd0e41{/static,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@28554ac8{/,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@72224107{/api,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@52bba91a{/jobs/job/kill,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1689527c{/stages/stage/kill,null,AVAILABLE,@Spark}
18/06/26 02:18:54 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://dc1master-lan1:4040
18/06/26 02:18:54 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 0
18/06/26 02:18:54 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:18:54 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://dc1master-lan1:7077...
18/06/26 02:18:54 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 0
18/06/26 02:18:54 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:18:55 INFO client.TransportClientFactory: Successfully created connection to dc1master-lan1/10.0.1.253:7077 after 48 ms (0 ms spent in bootstraps)
18/06/26 02:18:55 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20180626021855-0028
18/06/26 02:18:55 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20180626021855-0028/0 on worker-20180626004527-10.0.1.2-38332 (10.0.1.2:38332) with 10 core(s)
18/06/26 02:18:55 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20180626021855-0028/0 on hostPort 10.0.1.2:38332 with 10 core(s), 2.0 GB RAM
18/06/26 02:18:55 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20180626021855-0028/1 on worker-20180626004527-10.0.1.1-34053 (10.0.1.1:34053) with 10 core(s)
18/06/26 02:18:55 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20180626021855-0028/1 on hostPort 10.0.1.1:34053 with 10 core(s), 2.0 GB RAM
18/06/26 02:18:55 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41987.
18/06/26 02:18:55 INFO netty.NettyBlockTransferService: Server created on dc1master-lan1:41987
18/06/26 02:18:55 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/06/26 02:18:55 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20180626021855-0028/1 is now RUNNING
18/06/26 02:18:55 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20180626021855-0028/0 is now RUNNING
18/06/26 02:18:55 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, dc1master-lan1, 41987, None)
18/06/26 02:18:55 INFO storage.BlockManagerMasterEndpoint: Registering block manager dc1master-lan1:41987 with 369.3 MB RAM, BlockManagerId(driver, dc1master-lan1, 41987, None)
18/06/26 02:18:55 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, dc1master-lan1, 41987, None)
18/06/26 02:18:55 INFO storage.BlockManager: external shuffle service port = 7337
18/06/26 02:18:55 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, dc1master-lan1, 41987, None)
18/06/26 02:18:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2712e8f4{/metrics/json,null,AVAILABLE,@Spark}
18/06/26 02:18:55 INFO scheduler.EventLoggingListener: Logging events to hdfs://dc1master:9000/user/wentingt/spark-logs/app-20180626021855-0028
18/06/26 02:18:55 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
18/06/26 02:18:55 INFO internal.SharedState: loading hive config file: file:/users/wentingt/spark-terra/conf/hive-site.xml
18/06/26 02:18:55 INFO internal.SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir ('/user/hive/warehouse').
18/06/26 02:18:55 INFO internal.SharedState: Warehouse path is '/user/hive/warehouse'.
18/06/26 02:18:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@769b0752{/SQL,null,AVAILABLE,@Spark}
18/06/26 02:18:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@dae5e0{/SQL/json,null,AVAILABLE,@Spark}
18/06/26 02:18:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65db548{/SQL/execution,null,AVAILABLE,@Spark}
18/06/26 02:18:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@150f41b9{/SQL/execution/json,null,AVAILABLE,@Spark}
18/06/26 02:18:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1a7d0c9f{/static/sql,null,AVAILABLE,@Spark}
18/06/26 02:18:55 INFO hive.HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/06/26 02:18:55 INFO client.HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is /user/hive/warehouse
18/06/26 02:18:55 INFO metastore.HiveMetaStore: 0: get_database: default
18/06/26 02:18:55 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: default	
18/06/26 02:18:55 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 0
18/06/26 02:18:55 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:18:55 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 0
18/06/26 02:18:55 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:18:56 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/06/26 02:18:56 INFO metastore.HiveMetaStore: 0: get_database: global_temp
18/06/26 02:18:56 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/06/26 02:18:56 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/06/26 02:18:56 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 02:18:56 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 02:18:56 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 02:18:56 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 02:18:56 INFO metastore.HiveMetaStore: 0: get_database: tpcds_text_2
18/06/26 02:18:56 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_database: tpcds_text_2	
18/06/26 02:18:56 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=inventory
18/06/26 02:18:56 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=inventory	
18/06/26 02:18:56 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 0
18/06/26 02:18:56 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:18:56 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 0
18/06/26 02:18:56 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:18:57 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.1.1:37636) with ID 1
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:18:57 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.1.2:40488) with ID 0
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:18:57 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=warehouse
18/06/26 02:18:57 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=warehouse	
18/06/26 02:18:57 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.1.1:43971 with 912.3 MB RAM, BlockManagerId(1, 10.0.1.1, 43971, None)
18/06/26 02:18:57 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=item
18/06/26 02:18:57 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=item	
18/06/26 02:18:57 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.1.2:37344 with 912.3 MB RAM, BlockManagerId(0, 10.0.1.2, 37344, None)
18/06/26 02:18:57 INFO metastore.HiveMetaStore: 0: get_table : db=tpcds_text_2 tbl=date_dim
18/06/26 02:18:57 INFO HiveMetaStore.audit: ugi=wentingt	ip=unknown-ip-addr	cmd=get_table : db=tpcds_text_2 tbl=date_dim	
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:18:57 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:18:58 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:18:58 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:18:58 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:18:58 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:18:58 WARN util.Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
18/06/26 02:18:59 INFO spark.ContextCleaner: Cleaned accumulator 0
18/06/26 02:18:59 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:18:59 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:18:59 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:18:59 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:00 INFO codegen.CodeGenerator: Code generated in 289.045838 ms
18/06/26 02:19:00 INFO codegen.CodeGenerator: Code generated in 36.325784 ms
18/06/26 02:19:00 INFO codegen.CodeGenerator: Code generated in 38.112002 ms
18/06/26 02:19:00 INFO codegen.CodeGenerator: Code generated in 44.097916 ms
18/06/26 02:19:00 INFO codegen.CodeGenerator: Code generated in 72.461898 ms
18/06/26 02:19:00 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 290.7 KB, free 368.4 MB)
18/06/26 02:19:00 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 290.9 KB, free 368.4 MB)
18/06/26 02:19:00 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 291.1 KB, free 368.4 MB)
18/06/26 02:19:00 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 368.4 MB)
18/06/26 02:19:00 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.0 KB, free 368.4 MB)
18/06/26 02:19:00 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 25.0 KB, free 368.4 MB)
18/06/26 02:19:00 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on dc1master-lan1:41987 (size: 24.8 KB, free: 369.3 MB)
18/06/26 02:19:00 INFO spark.SparkContext: Created broadcast 0 from 
18/06/26 02:19:00 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on dc1master-lan1:41987 (size: 25.0 KB, free: 369.3 MB)
18/06/26 02:19:00 INFO spark.SparkContext: Created broadcast 1 from 
18/06/26 02:19:00 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on dc1master-lan1:41987 (size: 25.0 KB, free: 369.2 MB)
18/06/26 02:19:00 INFO spark.SparkContext: Created broadcast 2 from 
18/06/26 02:19:00 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 02:19:00 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 02:19:00 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/26 02:19:00 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:00 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:00 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:00 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:00 INFO spark.SparkContext: Starting job: run at ThreadPoolExecutor.java:1142
18/06/26 02:19:00 INFO spark.SparkContext: Starting job: run at ThreadPoolExecutor.java:1142
18/06/26 02:19:00 INFO spark.SparkContext: Starting job: run at ThreadPoolExecutor.java:1142
18/06/26 02:19:00 INFO scheduler.DAGScheduler: Got job 0 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
18/06/26 02:19:00 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (run at ThreadPoolExecutor.java:1142)
18/06/26 02:19:00 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/06/26 02:19:00 INFO scheduler.DAGScheduler: Missing parents: List()
18/06/26 02:19:00 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[16] at run at ThreadPoolExecutor.java:1142), which has no missing parents
18/06/26 02:19:01 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.1 KB, free 368.4 MB)
18/06/26 02:19:01 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.0 KB, free 368.4 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on dc1master-lan1:41987 (size: 6.0 KB, free: 369.2 MB)
18/06/26 02:19:01 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1074
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[16] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Got job 2 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (run at ThreadPoolExecutor.java:1142)
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Missing parents: List()
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[17] at run at ThreadPoolExecutor.java:1142), which has no missing parents
18/06/26 02:19:01 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.0 KB, free 368.3 MB)
18/06/26 02:19:01 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.4 KB, free 368.3 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on dc1master-lan1:41987 (size: 6.4 KB, free: 369.2 MB)
18/06/26 02:19:01 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1074
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[17] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
18/06/26 02:19:01 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 10.0.1.2, executor 0, partition 0, ANY, 7915 bytes)
18/06/26 02:19:01 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 10.0.1.1, executor 1, partition 1, ANY, 7915 bytes)
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Got job 1 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (run at ThreadPoolExecutor.java:1142)
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Missing parents: List()
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at run at ThreadPoolExecutor.java:1142), which has no missing parents
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:01 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.3 KB, free 368.3 MB)
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:01 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, 10.0.1.1, executor 1, partition 0, ANY, 7911 bytes)
18/06/26 02:19:01 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, 10.0.1.2, executor 0, partition 1, ANY, 7911 bytes)
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 02:19:01 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 368.3 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on dc1master-lan1:41987 (size: 5.7 KB, free: 369.2 MB)
18/06/26 02:19:01 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1074
18/06/26 02:19:01 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:01 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, 10.0.1.2, executor 0, partition 0, ANY, 7916 bytes)
18/06/26 02:19:01 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 10.0.1.1, executor 1, partition 1, ANY, 7916 bytes)
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 2
18/06/26 02:19:01 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 0
18/06/26 02:19:01 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 0
18/06/26 02:19:01 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 1
18/06/26 02:19:01 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 1
18/06/26 02:19:01 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 2
18/06/26 02:19:01 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 2
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.1.1:43971 (size: 6.0 KB, free: 912.3 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.1.2:37344 (size: 6.4 KB, free: 912.3 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.1.1:43971 (size: 5.7 KB, free: 912.3 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.1.2:37344 (size: 6.0 KB, free: 912.3 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.1.1:43971 (size: 6.4 KB, free: 912.3 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.1.2:37344 (size: 5.7 KB, free: 912.3 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.1:43971 (size: 24.8 KB, free: 912.3 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.1.2:37344 (size: 25.0 KB, free: 912.3 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.1.1:43971 (size: 25.0 KB, free: 912.2 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.1.1:43971 (size: 25.0 KB, free: 912.2 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.2:37344 (size: 24.8 KB, free: 912.2 MB)
18/06/26 02:19:01 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.1.2:37344 (size: 25.0 KB, free: 912.2 MB)
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:01 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:02 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:02 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:02 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:02 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 2200 ms on 10.0.1.1 (executor 1) (1/2)
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 2247 ms on 10.0.1.2 (executor 0) (2/2)
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/06/26 02:19:03 INFO scheduler.DAGScheduler: ResultStage 2 (run at ThreadPoolExecutor.java:1142) finished in 2.258 s
18/06/26 02:19:03 INFO scheduler.DAGScheduler: Job 1 finished: run at ThreadPoolExecutor.java:1142, took 2.420964 s
18/06/26 02:19:03 INFO codegen.CodeGenerator: Code generated in 15.80965 ms
18/06/26 02:19:03 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 1024.1 KB, free 367.3 MB)
18/06/26 02:19:03 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 371.0 B, free 367.3 MB)
18/06/26 02:19:03 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on dc1master-lan1:41987 (size: 371.0 B, free: 369.2 MB)
18/06/26 02:19:03 INFO spark.SparkContext: Created broadcast 6 from run at ThreadPoolExecutor.java:1142
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 2326 ms on 10.0.1.1 (executor 1) (1/2)
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2359 ms on 10.0.1.1 (executor 1) (1/2)
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 2376 ms on 10.0.1.2 (executor 0) (2/2)
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/06/26 02:19:03 INFO scheduler.DAGScheduler: ResultStage 1 (run at ThreadPoolExecutor.java:1142) finished in 2.410 s
18/06/26 02:19:03 INFO scheduler.DAGScheduler: Job 2 finished: run at ThreadPoolExecutor.java:1142, took 2.535718 s
18/06/26 02:19:03 INFO codegen.CodeGenerator: Code generated in 10.190314 ms
18/06/26 02:19:03 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1088.0 KB, free 366.3 MB)
18/06/26 02:19:03 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 34.0 KB, free 366.2 MB)
18/06/26 02:19:03 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on dc1master-lan1:41987 (size: 34.0 KB, free: 369.2 MB)
18/06/26 02:19:03 INFO spark.SparkContext: Created broadcast 7 from run at ThreadPoolExecutor.java:1142
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2447 ms on 10.0.1.2 (executor 0) (2/2)
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/06/26 02:19:03 INFO scheduler.DAGScheduler: ResultStage 0 (run at ThreadPoolExecutor.java:1142) finished in 2.499 s
18/06/26 02:19:03 INFO scheduler.DAGScheduler: Job 0 finished: run at ThreadPoolExecutor.java:1142, took 2.575865 s
18/06/26 02:19:03 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1024.5 KB, free 365.2 MB)
18/06/26 02:19:03 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 1083.0 B, free 365.2 MB)
18/06/26 02:19:03 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on dc1master-lan1:41987 (size: 1083.0 B, free: 369.2 MB)
18/06/26 02:19:03 INFO spark.SparkContext: Created broadcast 8 from run at ThreadPoolExecutor.java:1142
18/06/26 02:19:03 INFO codegen.CodeGenerator: Code generated in 107.580894 ms
18/06/26 02:19:03 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 290.4 KB, free 364.9 MB)
18/06/26 02:19:03 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 24.8 KB, free 364.9 MB)
18/06/26 02:19:03 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on dc1master-lan1:41987 (size: 24.8 KB, free: 369.2 MB)
18/06/26 02:19:03 INFO spark.SparkContext: Created broadcast 9 from 
18/06/26 02:19:03 INFO mapred.FileInputFormat: Total input paths to process : 2
18/06/26 02:19:03 INFO spark.SparkContext: Starting job: processCmd at CliDriver.java:376
18/06/26 02:19:03 INFO scheduler.DAGScheduler: Registering RDD 23 (processCmd at CliDriver.java:376)
18/06/26 02:19:03 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerShuffle id:0
18/06/26 02:19:03 INFO scheduler.DAGScheduler: Got job 3 (processCmd at CliDriver.java:376) with 4 output partitions
18/06/26 02:19:03 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (processCmd at CliDriver.java:376)
18/06/26 02:19:03 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/06/26 02:19:03 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/06/26 02:19:03 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[23] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 02:19:03 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 62.9 KB, free 364.9 MB)
18/06/26 02:19:03 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 25.5 KB, free 364.8 MB)
18/06/26 02:19:03 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on dc1master-lan1:41987 (size: 25.5 KB, free: 369.1 MB)
18/06/26 02:19:03 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1074
18/06/26 02:19:03 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[23] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, 10.0.1.1, executor 1, partition 0, ANY, 7905 bytes)
18/06/26 02:19:03 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 3
18/06/26 02:19:03 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, 10.0.1.2, executor 0, partition 1, ANY, 7905 bytes)
18/06/26 02:19:03 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 3
18/06/26 02:19:03 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, 10.0.1.1, executor 1, partition 2, ANY, 7905 bytes)
18/06/26 02:19:03 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 3
18/06/26 02:19:03 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, 10.0.1.2, executor 0, partition 3, ANY, 7905 bytes)
18/06/26 02:19:03 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 3
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 4
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:03 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:03 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.1.2:37344 (size: 25.5 KB, free: 912.2 MB)
18/06/26 02:19:03 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.1.1:43971 (size: 25.5 KB, free: 912.2 MB)
18/06/26 02:19:04 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.1.2:37344 (size: 24.8 KB, free: 912.2 MB)
18/06/26 02:19:04 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.1.1:43971 (size: 24.8 KB, free: 912.2 MB)
18/06/26 02:19:04 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.1.2:37344 (size: 371.0 B, free: 912.2 MB)
18/06/26 02:19:04 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.1.2:37344 (size: 34.0 KB, free: 912.1 MB)
18/06/26 02:19:04 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.1.2:37344 (size: 1083.0 B, free: 912.1 MB)
18/06/26 02:19:04 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.1.1:43971 (size: 371.0 B, free: 912.2 MB)
18/06/26 02:19:04 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.1.1:43971 (size: 34.0 KB, free: 912.1 MB)
18/06/26 02:19:04 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.1.1:43971 (size: 1083.0 B, free: 912.1 MB)
18/06/26 02:19:04 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:04 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:04 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:04 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:05 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:05 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:05 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:05 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:06 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 2160 ms on 10.0.1.2 (executor 0) (1/4)
18/06/26 02:19:06 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 02:19:06 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/29/shuffle_0_3_0.data
18/06/26 02:19:06 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/0d/shuffle_0_3_0.index
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:06 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 2183 ms on 10.0.1.2 (executor 0) (2/4)
18/06/26 02:19:06 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(0, 10.0.1.2, 7337, None)
18/06/26 02:19:06 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/15/shuffle_0_1_0.data
18/06/26 02:19:06 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/0f/shuffle_0_1_0.index
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:06 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:07 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:07 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:07 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:07 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:08 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:08 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:08 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:08 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:09 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:09 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:09 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:09 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:10 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 6267 ms on 10.0.1.1 (executor 1) (3/4)
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-3ce8d978-ea4a-42b3-a215-fdc5ba75fa96/blockmgr-913b7eae-8526-4c4f-9058-bd081dd723f2/0c/shuffle_0_0_0.data
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-3ce8d978-ea4a-42b3-a215-fdc5ba75fa96/blockmgr-913b7eae-8526-4c4f-9058-bd081dd723f2/30/shuffle_0_0_0.index
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:10 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 6366 ms on 10.0.1.1 (executor 1) (4/4)
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.location.toString: BlockManagerId(1, 10.0.1.1, 7337, None)
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getDataFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-3ce8d978-ea4a-42b3-a215-fdc5ba75fa96/blockmgr-913b7eae-8526-4c4f-9058-bd081dd723f2/36/shuffle_0_2_0.data
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: MapOutputTracker.registerMapOutput status.getIndexFile: /tmp/spark-70f7e7c2-3be3-4eeb-8a73-612cf7e61654/executor-3ce8d978-ea4a-42b3-a215-fdc5ba75fa96/blockmgr-913b7eae-8526-4c4f-9058-bd081dd723f2/32/shuffle_0_2_0.index
18/06/26 02:19:10 INFO scheduler.DAGScheduler: ShuffleMapStage 3 (processCmd at CliDriver.java:376) finished in 6.388 s
18/06/26 02:19:10 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/06/26 02:19:10 INFO scheduler.DAGScheduler: running: Set()
18/06/26 02:19:10 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 4)
18/06/26 02:19:10 INFO scheduler.DAGScheduler: failed: Set()
18/06/26 02:19:10 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[27] at processCmd at CliDriver.java:376), which has no missing parents
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 16965
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 16965
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17773
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17773
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17450
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17450
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17058
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17058
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 48.8 KB, free 364.8 MB)
18/06/26 02:19:10 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.9 KB, free 364.8 MB)
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 118
18/06/26 02:19:10 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on dc1master-lan1:41987 (size: 20.9 KB, free: 369.1 MB)
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 72
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 87
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 95
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 78
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 69
18/06/26 02:19:10 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1074
18/06/26 02:19:10 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[27] at processCmd at CliDriver.java:376) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: Adding task set 4.0 with 4 tasks
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:10 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, 10.0.1.1, executor 1, partition 0, NODE_LOCAL, 7758 bytes)
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 4
18/06/26 02:19:10 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 11, 10.0.1.1, executor 1, partition 1, NODE_LOCAL, 7758 bytes)
18/06/26 02:19:10 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 4.0 (TID 12, 10.0.1.1, executor 1, partition 2, NODE_LOCAL, 7758 bytes)
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 3
18/06/26 02:19:10 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 4.0 (TID 13, 10.0.1.1, executor 1, partition 3, NODE_LOCAL, 7758 bytes)
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 4
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626021855-0028
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 4
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 3
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626021855-0028
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 4
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 3
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626021855-0028
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::stageId: 4
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::parentStageId: 3
18/06/26 02:19:10 INFO scheduler.DAGScheduler: handleBeginEvent::parentShuffleMapStage
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.shuffleId: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.numReduces: 4
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceId: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceHost: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.reduceExecutorId: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: onTaskStart.appId: app-20180626021855-0028
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 0
18/06/26 02:19:10 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on dc1master-lan1:41987 in memory (size: 5.7 KB, free: 369.1 MB)
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle not finished !!!
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop take shuffleId: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop reduceId: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: TerraLoop shuffle finished !!!
18/06/26 02:19:10 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.1.2:37344 in memory (size: 5.7 KB, free: 912.1 MB)
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 16965
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 16965
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 16965
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 16965
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17773
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17773
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 16965
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 16965
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17773
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17773
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17450
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17450
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 16965
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 16965
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17773
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17773
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17450
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17450
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17058
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17058
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:10 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ terraClient.submitShuffleInfo $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ appId: app-20180626021855-0028
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ shuffleId: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ mappersIP: Map(0 -> 10.0.1.1, 1 -> 10.0.1.2, 2 -> 10.0.1.1, 3 -> 10.0.1.2)
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ reducersIP: Map(0 -> 10.0.1.1, 1 -> 10.0.1.1, 2 -> 10.0.1.1, 3 -> 10.0.1.1)
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_2_redundant
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/0d/shuffle_0_3_0.index
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/15/shuffle_0_1_0.data
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_1_redundant
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/0d/shuffle_0_3_0.index
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/15/shuffle_0_1_0.data
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/15/shuffle_0_1_0.data
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/29/shuffle_0_3_0.data
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/15/shuffle_0_1_0.data
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/29/shuffle_0_3_0.data
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/29/shuffle_0_3_0.data
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_3_redundant
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/0f/shuffle_0_1_0.index
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/29/shuffle_0_3_0.data
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_3_redundant
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/0d/shuffle_0_3_0.index
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_0_redundant
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/0f/shuffle_0_1_0.index
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_1_redundant
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/0f/shuffle_0_1_0.index
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 1_2_redundant
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/0f/shuffle_0_1_0.index
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ filename: 3_0_redundant
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapID: 3
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceAttemptID: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getDataFilename: /tmp/spark-6e3b625e-cea2-4464-8d6f-907283947a20/executor-e68f366a-2de3-4f13-8e88-3a1bfd70ec96/blockmgr-27c20280-b001-4027-8d0a-6e679fd9c412/0d/shuffle_0_3_0.index
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getStartOffset: 0
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getShuffleSize_byte: 9223372036854775807
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getMapIP: 10.0.1.2
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$ flowInfo.getReduceIP: 10.0.1.1
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: $$$
18/06/26 02:19:10 INFO gaialib.GaiaClient: NEW! Try to submit ShuffleInfo to controller
18/06/26 02:19:10 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.1.1:43971 in memory (size: 5.7 KB, free: 912.1 MB)
18/06/26 02:19:10 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.1.1:43971 (size: 20.9 KB, free: 912.1 MB)
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 80
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 48
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 64
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 55
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 103
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 46
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 114
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 108
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 84
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 47
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 70
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 50
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 51
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 65
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 89
18/06/26 02:19:10 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on dc1master-lan1:41987 in memory (size: 6.0 KB, free: 369.1 MB)
18/06/26 02:19:10 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.1.1:43971 in memory (size: 6.0 KB, free: 912.1 MB)
18/06/26 02:19:10 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.1.2:37344 in memory (size: 6.0 KB, free: 912.1 MB)
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 97
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 92
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 75
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 67
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 99
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 85
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 91
18/06/26 02:19:10 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on dc1master-lan1:41987 in memory (size: 6.4 KB, free: 369.1 MB)
18/06/26 02:19:10 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.1.1:43971 in memory (size: 6.4 KB, free: 912.1 MB)
18/06/26 02:19:10 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.1.2:37344 in memory (size: 6.4 KB, free: 912.1 MB)
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 94
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 60
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 104
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 82
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 102
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 112
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 61
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 107
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 86
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 77
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 101
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 54
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 81
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 83
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 113
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 105
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 45
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 76
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 116
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 110
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 88
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 58
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 59
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 73
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 66
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 106
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 57
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 62
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 98
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 52
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 56
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 115
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 111
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 90
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 96
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 79
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 93
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 117
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 53
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 71
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 44
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 63
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 100
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 49
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 109
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 68
18/06/26 02:19:10 INFO spark.ContextCleaner: Cleaned accumulator 74
18/06/26 02:19:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:10 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:10 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:11 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:11 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:11 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:11 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:11 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:11 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:12 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:12 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:12 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:12 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:12 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:12 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:12 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:12 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:12 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:12 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:12 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:12 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:13 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:13 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:13 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:13 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:13 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:13 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:13 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:13 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:13 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:13 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:13 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:13 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:13 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:13 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:13 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:13 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:14 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:14 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:14 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:14 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:14 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:14 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:14 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:14 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:14 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:14 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:14 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:14 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:14 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:14 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:14 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:14 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:15 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:15 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:15 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:15 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:15 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:15 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:15 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:15 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:15 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:15 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:15 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:15 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:15 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:15 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:15 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:15 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:16 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:16 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:16 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:16 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:16 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:17 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:17 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:17 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:17 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:17 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:17 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:17 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:17 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:17 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:17 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:17 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:18 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:18 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:18 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:18 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:18 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:18 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:18 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:18 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:18 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:18 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:18 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:18 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:18 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:18 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:19 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:19 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:19 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:19 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:19 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:19 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:19 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:19 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:19 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:19 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:19 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:19 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:19 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:19 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:19 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:19 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:20 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:20 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:20 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:20 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:20 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:20 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:20 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:20 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:20 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:20 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:20 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:20 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:20 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:20 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:21 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:21 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:21 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:21 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:21 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:21 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:21 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:21 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:21 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:21 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:21 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:21 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:21 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:21 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:22 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:22 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:22 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:22 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:22 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:22 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:22 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:22 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:22 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:22 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:22 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:22 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### false
18/06/26 02:19:22 INFO gaialib.GaiaClient: Gaia controller returned: Request Complete
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 16965
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 16965
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17773
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17773
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17450
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17450
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 17058
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 17058
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 1
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 2
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock reduceId: 3
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock compressedSizes(reduceId): 0
18/06/26 02:19:22 INFO scheduler.RawMapStatus: getSizeForBlock MapStatus.decompressSize(compressedSizes(reduceId)): 0
18/06/26 02:19:22 INFO spark.MapOutputTrackerMaster: @@@ totalSize @@@ 69246
18/06/26 02:19:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:22 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:22 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:23 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:23 INFO spark.MapOutputTrackerMaster: Handling request to send terra finished for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:23 INFO spark.MapOutputTrackerMaster: MessageLoop reply ### true
18/06/26 02:19:23 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:23 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:23 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:23 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:24 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.1.1:37636
18/06/26 02:19:24 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 16965
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 17773
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 17450
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 17058
18/06/26 02:19:24 INFO scheduler.RawMapStatus: WriteExternal compressedSizes
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.RawMapStatus: 0
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:24 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 14390 ms on 10.0.1.1 (executor 1) (1/4)
18/06/26 02:19:24 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 11) in 14389 ms on 10.0.1.1 (executor 1) (2/4)
18/06/26 02:19:24 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 4.0 (TID 13) in 14388 ms on 10.0.1.1 (executor 1) (3/4)
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 1
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 1
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:24 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 4.0 (TID 12) in 14404 ms on 10.0.1.1 (executor 1) (4/4)
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/06/26 02:19:24 INFO scheduler.DAGScheduler: ResultStage 4 (processCmd at CliDriver.java:376) finished in 14.453 s
18/06/26 02:19:24 INFO scheduler.DAGScheduler: Job 3 finished: processCmd at CliDriver.java:376, took 20.871054 s
Time taken: 28.395 seconds, Fetched 100 row(s)
18/06/26 02:19:24 INFO thriftserver.SparkSQLCLIDriver: Time taken: 28.395 seconds, Fetched 100 row(s)
18/06/26 02:19:24 INFO server.AbstractConnector: Stopped Spark@59d5a6fd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
18/06/26 02:19:24 INFO ui.SparkUI: Stopped Spark web UI at http://dc1master-lan1:4040
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.size ### 2
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers initialized tasks.flatten.size ### 0
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.size ### 2
18/06/26 02:19:24 INFO scheduler.TaskSchedulerImpl: resourceOffers returned tasks.flatten.size ### 0
18/06/26 02:19:25 INFO cluster.StandaloneSchedulerBackend: Shutting down all executors
18/06/26 02:19:25 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
18/06/26 02:19:25 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/06/26 02:19:25 INFO memory.MemoryStore: MemoryStore cleared
18/06/26 02:19:25 INFO storage.BlockManager: BlockManager stopped
18/06/26 02:19:25 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
18/06/26 02:19:25 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/06/26 02:19:25 INFO spark.SparkContext: Successfully stopped SparkContext
18/06/26 02:19:25 INFO util.ShutdownHookManager: Shutdown hook called
18/06/26 02:19:25 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-1f35b60a-33d1-48b7-9a5c-bfede17ea633
18/06/26 02:19:25 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-6f26b5dc-8a49-4514-8bea-141446a399fa
